{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobmrCuzzins/Machine-DeepLearning-/blob/main/TransferLearning_using_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVDcdZVVIswy"
      },
      "source": [
        "# Classifying Images Using CNN and Transfer Learning\n",
        "This Notebook contains the exploration of the effectiveness of training a CNN using the combination of transfer learning specifically VGG16 CNN.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqR-k4UDDltb",
        "outputId": "9e37a442-666b-425f-8e9d-cce9df07f136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s7DsaxDI2im"
      },
      "source": [
        "## Functions to work with CIFAR\n",
        "\n",
        "The functions below help with access to the CIFAR-10 data the you have downloaded.\n",
        "\n",
        "**NOTE:** This is different from previous notebooks to handle the input that the imagenet trained networks expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUSVhQr5KDv1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_CIFAR_batch(filename, flatten=True, categorical=True):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X = datadict[b'data']\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
        "        if (flatten):\n",
        "          X = X.reshape(10000, 3072)\n",
        "        X = X.astype('float32')\n",
        "        # need to keep the data in 0-255 range\n",
        "        #X /= 255\n",
        "\n",
        "        y = datadict[b'labels']\n",
        "        y = np.array(y)\n",
        "        if (categorical):\n",
        "          y = pd.get_dummies(y).values\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def load_CIFAR_meta(filename):\n",
        "  with open(filename,'rb') as f:\n",
        "    metadict = pickle.load(f, encoding='bytes')\n",
        "\n",
        "    class_labels = [ val.decode() for val in metadict.get(b'label_names') ]\n",
        "    return class_labels\n",
        "\n",
        "def get_image(X, index, nchans=3, size=32):\n",
        "  xi = np.copy(X[index,:])\n",
        "  # now rescale for image display\n",
        "  xi /= 255\n",
        "  img = xi.reshape(size, size, nchans)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SudeLpyHCd-X",
        "outputId": "b6096a1f-80d2-42d8-c5fd-e28b177c888b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 50000 instances of images\n"
          ]
        }
      ],
      "source": [
        "flatten = False\n",
        "categorical = True\n",
        "\n",
        "# load only the first batch\n",
        "#X1, y1 = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_1',flatten=flatten,categorical=categorical)\n",
        "\n",
        "# load only the second batch\n",
        "#X2, y2 = load_CIFAR_batch('/content/drive/My Drive/COMP2712/data/cifar-10-batches-py/data_batch_2',flatten=flatten,categorical=categorical)\n",
        "\n",
        "# Load the first batch from CIFAR-10\n",
        "X, y = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_1',flatten= False ,categorical=categorical)\n",
        "\n",
        "# iterate over 2 to 5\n",
        "for bi in range(2,6):\n",
        "  # load the next data set 'bi'\n",
        "  X2, y2 = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_{}'.format(bi),flatten=flatten,categorical=categorical)\n",
        "\n",
        "  # concatenate/stack the dataest together\n",
        "  X = np.vstack([X, X2])\n",
        "  y = np.vstack([y, y2])\n",
        "\n",
        " #Load the test data into test variables\n",
        "Xtest, ytest = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/test_batch', flatten=False)\n",
        "\n",
        "# Create 1d version for testing accuracy\n",
        "ytrain_1d = np.argmax(y, axis=1)\n",
        "ytest_1d = np.argmax(ytest, axis=1)\n",
        "\n",
        "print('We have {} instances of images'.format(y.shape[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUnAt_YKPjp"
      },
      "source": [
        "The number of instances/examples for all the different classes.  There are 10 different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-uX5AZmQG9N",
        "outputId": "20b37c1a-6ce2-4763-f1bb-5e8a9b169ace"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "[np.sum(np.argmax(y, axis=1) == i) for i in range(0,10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_HIgldKlsd"
      },
      "source": [
        "The labels for the classes are stored in the `batches.meta` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HKjGtxStmcz",
        "outputId": "8a614cde-f7aa-4c0a-a6ed-543f23fa3a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "class_labels = load_CIFAR_meta('/content/drive/My Drive/cifar-10-batches-py/batches.meta')\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1M8hm3x2tt_"
      },
      "source": [
        "**START WITH THE ARNIE!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built the Base Model using VGG16 (Arnie) and added a custom classification layer (The Mr Bean)"
      ],
      "metadata": {
        "id": "ATdQFRDZPPK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmwiDznA2udl",
        "outputId": "afe35f17-57b0-4c28-b488-0cdbe253443f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14848586 (56.64 MB)\n",
            "Trainable params: 133898 (523.04 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data() #Issues trying to load the dataset from my drive so imported from Keras datasets\n",
        "\n",
        "# Preprocess data/Normalization\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3)) #THE ARNIE!!\n",
        "\n",
        "base_model.trainable = False #Make the base model Untrainable\n",
        "# Create a new model on top of the pre-trained base model\n",
        "\n",
        "model = Sequential([ # Custom classification layer #THE Mr Bean!!!\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),     # Included a dropout layer for regularization\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained the model!"
      ],
      "metadata": {
        "id": "EYaNATw-Pwpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJcIKpPe2Ty4",
        "outputId": "81e8674f-7910-4e0c-c2b4-bb1d32e590e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 26s 14ms/step - loss: 1.7796 - accuracy: 0.2940 - val_loss: 1.4706 - val_accuracy: 0.4175\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.3049 - accuracy: 0.5068 - val_loss: 1.1658 - val_accuracy: 0.5629\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0201 - accuracy: 0.6342 - val_loss: 0.9358 - val_accuracy: 0.6596\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8382 - accuracy: 0.7073 - val_loss: 0.9272 - val_accuracy: 0.6911\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 23s 14ms/step - loss: 0.7396 - accuracy: 0.7442 - val_loss: 0.8499 - val_accuracy: 0.7139\n",
            "Test Accuracy: 71.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENABLE THE BUFF DOGE!**"
      ],
      "metadata": {
        "id": "sZ4xG8KyP1G9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IJ4-f1iDDOD",
        "outputId": "6ed55622-1fa5-42b5-972e-fac9ab26b001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14848586 (56.64 MB)\n",
            "Trainable params: 14848586 (56.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 24s 13ms/step - loss: 0.5178 - accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4701 - accuracy: 0.8388\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4476 - accuracy: 0.8466\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4315 - accuracy: 0.8522\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.4183 - accuracy: 0.8573\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.4065 - accuracy: 0.8615\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3955 - accuracy: 0.8656\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 0.3857 - accuracy: 0.8696\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3761 - accuracy: 0.8735\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.3669 - accuracy: 0.8775\n",
            "Test Accuracy: 78.73%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "base_model.trainable = True  #ENABLE THE BUFF DOGE!!\n",
        "model.summary()\n",
        "\n",
        "learning_rate = 1e-5\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=keras.losses.categorical_crossentropy,\n",
        "    metrics=(['accuracy'])\n",
        ")\n",
        "\n",
        "epochs = 10 #Extend epochs to 10 allow for longer training\n",
        "model.fit(X_train,y_train, epochs=epochs)\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kfold Evaluation Allow the model to train for longer averaging the scores**"
      ],
      "metadata": {
        "id": "RWVb8zIdQC8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have your features in X and labels in y\n",
        "\n",
        "# Initialize a KFold object with 3 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Assuming you have trained your model and obtained predictions\n",
        "    model.fit(X_train, y_train, epochs=10, verbose=1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Calculate accuracy for this fold\n",
        "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Print metrics for this fold\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Calculate the average accuracy over all folds\n",
        "average_accuracy = np.mean(accuracy_scores) * 100\n",
        "print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fczTxv9awXyL",
        "outputId": "25f2b10f-d984-4b72-bea1-478d5aeeb8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 9.9997 - accuracy: 0.6451\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 1.9810 - accuracy: 0.6392\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 1.2458 - accuracy: 0.6424\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 1.0157 - accuracy: 0.6809\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.8828 - accuracy: 0.7164\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.7878 - accuracy: 0.7451\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.7095 - accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.6494 - accuracy: 0.7851\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6033 - accuracy: 0.7969\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.5671 - accuracy: 0.8075\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Fold 1 - Accuracy: 79.94%\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.5699 - accuracy: 0.8121\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.5341 - accuracy: 0.8198\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.5100 - accuracy: 0.8267\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4886 - accuracy: 0.8334\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4696 - accuracy: 0.8395\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4526 - accuracy: 0.8434\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.4372 - accuracy: 0.8488\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4220 - accuracy: 0.8537\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.4085 - accuracy: 0.8583\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.3954 - accuracy: 0.8627\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "Fold 2 - Accuracy: 82.75%\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.4184 - accuracy: 0.8578\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4005 - accuracy: 0.8627\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3869 - accuracy: 0.8668\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 14s 12ms/step - loss: 0.3754 - accuracy: 0.8705\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3632 - accuracy: 0.8751\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.3524 - accuracy: 0.8786\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3414 - accuracy: 0.8827\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3310 - accuracy: 0.8860\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3215 - accuracy: 0.8898\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3118 - accuracy: 0.8931\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Fold 3 - Accuracy: 85.89%\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 15s 11ms/step - loss: 0.3377 - accuracy: 0.8834\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3222 - accuracy: 0.8893\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3113 - accuracy: 0.8938\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3016 - accuracy: 0.8955\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2924 - accuracy: 0.8988\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2823 - accuracy: 0.9030\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2737 - accuracy: 0.9054\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2650 - accuracy: 0.9088\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2569 - accuracy: 0.9118\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2484 - accuracy: 0.9159\n",
            "313/313 [==============================] - 1s 5ms/step\n",
            "Fold 4 - Accuracy: 89.62%\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2642 - accuracy: 0.9107\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2497 - accuracy: 0.9161\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2404 - accuracy: 0.9191\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2320 - accuracy: 0.9219\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2240 - accuracy: 0.9258\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2168 - accuracy: 0.9284\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2083 - accuracy: 0.9308\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.2004 - accuracy: 0.9339\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.1934 - accuracy: 0.9354\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.1861 - accuracy: 0.9390\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Fold 5 - Accuracy: 91.27%\n",
            "Average Accuracy: 85.89%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}