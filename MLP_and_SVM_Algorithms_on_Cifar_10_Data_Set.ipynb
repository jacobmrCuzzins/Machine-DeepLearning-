{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVDcdZVVIswy"
      },
      "source": [
        "# **Classifying Images Using MLP and SVM Algorithms**\n",
        "This notebook is to explore the concepts of training and evaluating classifiers such as the Multi-layer Perceptron (MLP) and Support Vector Machines (SVM) using the CIFAR-10 Data set.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEHloSne7FtE",
        "outputId": "d5c9d958-ff2c-4075-d42a-32c2c67a9ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6-0Jo9BRmNy"
      },
      "outputs": [],
      "source": [
        "# uncomment the below to mount the google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s7DsaxDI2im"
      },
      "source": [
        "## Functions to work with CIFAR\n",
        "\n",
        "The functions below help with access to the CIFAR-10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUSVhQr5KDv1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_CIFAR_batch(filename, flatten=True, categorical=True):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X = datadict[b'data']\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
        "        if (flatten):\n",
        "          X = X.reshape(10000, 3072)\n",
        "        X = X.astype('float32')\n",
        "        X /= 255\n",
        "\n",
        "        y = datadict[b'labels']\n",
        "        y = np.array(y)\n",
        "        if (categorical):\n",
        "          y = pd.get_dummies(y).values\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def load_CIFAR_meta(filename):\n",
        "  with open(filename,'rb') as f:\n",
        "    metadict = pickle.load(f, encoding='bytes')\n",
        "\n",
        "    class_labels = [ val.decode() for val in metadict.get(b'label_names') ]\n",
        "    return class_labels\n",
        "\n",
        "def get_image(X, index, nchans=3, size=32):\n",
        "  xi = X[index,:]\n",
        "  img = xi.reshape(32, 32, 3)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axqceDnNJVss"
      },
      "source": [
        "## Load the CIFAR data\n",
        "\n",
        "The CIFAR data has 5 batches of data and 1 test data set. Each batch is labelled\n",
        "- `data_batch_1`\n",
        "- `data_batch_2`\n",
        "- `data_batch_3`\n",
        "- `data_batch_4`\n",
        "- `data_batch_5`\n",
        "\n",
        "and a test set labelled\n",
        "- `test_batch`\n",
        "\n",
        "each batch has 10,000 images, so 50,000 training and 10,000 test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2X0_Oz_SkHi"
      },
      "source": [
        "Below is example of loading the first batch of training data labelled as `data_batch_1`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tuyy6hKKFhx"
      },
      "outputs": [],
      "source": [
        "X, y = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn6uyLsqA4Fy"
      },
      "source": [
        "**SPLIT THE DATA INTO TRAIN AND TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-8WdWSGA3qd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# split into train and test\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL0uD1HMBFIF"
      },
      "source": [
        "***NOMALIZE THE DATA USING Z-SCORE STANDARD SCALER***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InmglOQJBEXI"
      },
      "outputs": [],
      "source": [
        "# Initialize the StandardScaler I AM USING Z-Score STANDARDIZATION\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#transform training data\n",
        "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
        "\n",
        "#transform testing data\n",
        "Xtest_scaled = scaler.transform(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpu5s_CP5aAL"
      },
      "source": [
        "**PCA INVESTIGATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "UIcN-uPRNiVj",
        "outputId": "74c46e81-9e09-4158-9d02-229c4971be4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratios: [2.7043769e-01 1.1415476e-01 7.1536444e-02 ... 3.4262699e-09 3.3321039e-09\n",
            " 3.1467868e-09]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABp5klEQVR4nO3deVxUVf8H8M/MyAzrAMoqIrjiDoob7guGSy5tYlkKpj3lUoZWYiouJW0/0gyzzaV6UrMsfVJRQ81UTEVxScUlFDMBEVmVbeb8/sAZHQFldOAy4+f9es3Lufeee+93DgP367nnnCsTQggQERERWQi51AEQERERmRKTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8LkhoiIiCwKkxt6ILt27YJMJsOuXbukDsVshYWFwdfX94H29fX1RVhYmEnjqaqHiftRNnfuXMhkMmRmZkodSpUcPHgQ3bp1g52dHWQyGZKSkqQOiajKmNxYiGHDhsHW1hZ5eXmVlhk9ejSUSiWuXbtWg5HVbitXroRMJqv0tX//fqlDJCOEhYVBJpOhXbt2qOjJMjKZDJMnT5YgMvNSUlKCZ555BllZWfj444/x7bffwsfH5577pKenY/r06WjRogVsbW1hZ2eHwMBAvPPOO8jOzq6ZwC3Y5s2bMXfuXKnDMBt1pA6ATGP06NH43//+h59//hljxowpt/3GjRvYsGEDBg4ciHr16j30+Xr16oWbN29CqVQ+9LFqg/nz56NRo0bl1jdt2lSCaO4vOTkZcjn/b1KZ48ePY/369XjqqaekDsUsnT9/HhcvXsSXX36J8ePH37f8wYMHMXjwYOTn5+P5559HYGAgAODQoUN47733sHv3bmzbtq26w7ZomzdvRmxsLBOcKmJyYyGGDRsGBwcHfP/99xUmNxs2bEBBQQFGjx79UOcpLCyEUqmEXC6HtbX1Qx2rNhk0aBA6duwodRhVplKppA6h1rKxsYG3tzfmz5+PJ598EjKZTOqQatSNGzdga2v7UMfIyMgAADg5Od23bHZ2Np544gkoFAocOXIELVq0MNj+7rvv4ssvv3yoeIiMxf/6WQgbGxs8+eSTiI+P1/9hutP3338PBwcHDBs2DFlZWZg+fTratm0Le3t7qNVqDBo0CEePHjXYR9evZs2aNZg1axa8vLxga2uL3NzcCvvc/PHHH3jmmWfQsGFDqFQqeHt74/XXX8fNmzcNjhsWFgZ7e3tcvnwZI0aMgL29PVxdXTF9+nRoNBqDslqtFosXL0bbtm1hbW0NV1dXDBw4EIcOHTIo99133yEwMBA2NjaoW7cuRo0ahUuXLj1krd4WFRUFuVyO+Ph4g/UvvfQSlEqlvu509bJ27VrMnDkTHh4esLOzw7Bhw6oUz0cffYRu3bqhXr16sLGxQWBgIH788cdy5e7uc6O7vbZ3715ERETA1dUVdnZ2eOKJJ3D16tVy+2/ZsgU9e/aEnZ0dHBwcMGTIEPz111/lyv3yyy9o06YNrK2t0aZNG/z888/3/QwA8Pjjj6Nx48YVbgsKCjJIJLdv344ePXrAyckJ9vb28PPzw8yZM6t0norI5XLMmjULx44du2+8unq7cOGCwfqKvt99+vRBmzZtcOzYMfTu3Ru2trZo2rSp/ufz+++/o0uXLrCxsYGfnx9+++23Cs+ZmZmJkSNHQq1Wo169enjttddQWFhYrlxVvtO6mBITE9GrVy/Y2tret+527Nih/9k7OTlh+PDhOHXqlH57WFgYevfuDQB45plnIJPJ0KdPn0qP9/nnn+Py5cuIiYkpl9gAgLu7O2bNmmWwbunSpWjdujVUKhXq16+PSZMmlbt19bD1revjdPr06fvWd2lpKRYsWIAmTZpApVLB19cXM2fORFFRkUE5X19fPP7449izZw86d+4Ma2trNG7cGN988025z52dnY2pU6fC29sbKpUKTZs2xfvvvw+tVqsvc+HCBchkMnz00Uf44osv9Ofv1KkTDh48qC8XFhaG2NhYADC4ba6zZs0aBAYGwsHBAWq1Gm3btsXixYvLxfRIEWQxtm3bJgCIJUuWGKy/du2asLKyEmPGjBFCCHHw4EHRpEkTMWPGDPH555+L+fPnCy8vL+Ho6CguX76s32/nzp0CgGjVqpUICAgQMTExIjo6WhQUFOi37dy5U19+ypQpYvDgwWLhwoXi888/Fy+++KJQKBTi6aefNohn7NixwtraWrRu3VqMGzdOfPbZZ+Kpp54SAMTSpUsNyoaFhQkAYtCgQWLRokXio48+EsOHDzf4jO+8846QyWQiNDRULF26VMybN0+4uLgIX19fcf369XvW2YoVKwQA8dtvv4mrV68avDIzM/XliouLRfv27YWPj4/Izc0VQggRFxcnAIgFCxaUq7O2bduKdu3aiZiYGDFjxgxhbW0tmjdvLm7cuGFQDz4+PgbxNGjQQEycOFF8+umnIiYmRnTu3FkAEL/++qtBOR8fHzF27Nhyn6N9+/aiX79+YsmSJWLatGlCoVCIkSNHGuz7zTffCJlMJgYOHCiWLFki3n//feHr6yucnJxESkqKvtzWrVuFXC4Xbdq0ETExMeLtt98Wjo6OonXr1uXivts333wjAIgDBw4YrL9w4YIAID788EMhhBAnTpwQSqVSdOzYUSxevFgsW7ZMTJ8+XfTq1euex6/M2LFjhZ2dnSgtLRXNmjUT/v7+QqvV6rcDEJMmTSpXb3d+biFEhd/v3r17i/r16wtvb2/xxhtviCVLlohWrVoJhUIh1qxZIzw8PMTcuXPFokWL9L9Puu+KEEJERUXpvxtDhw4Vn376qXj++ecFAPHCCy8YnL+q3+nevXsLDw8P4erqKqZMmSI+//xz8csvv1RaP9u3bxd16tQRzZs3Fx988IH+uM7Ozvo62Ldvn5g5c6YAIF599VXx7bffim3btlV6zG7dugkbGxtRVFRUaZk76eohODhYLFmyREyePFkoFArRqVMnUVxcLEl9jx07VgAQTz/9tIiNjRVjxowRAMSIESMMyvn4+Ag/Pz/h7u4uZs6cKT799FPRoUMHIZPJxIkTJ/TlCgoKRLt27US9evXEzJkzxbJly8SYMWOETCYTr732mr5cSkqK/ve2adOm4v333xcffPCBcHFxEQ0aNNDXx759+8SAAQMEAPHtt9/qX0Lc/rvfv39/ERsbK2JjY8XkyZPFM888U6Wfh6VicmNBSktLhaenpwgKCjJYv2zZMgFAbN26VQghRGFhodBoNAZlUlJShEqlEvPnz9ev0/2Bb9y4scFF+c5td/7xv7uMEEJER0cLmUwmLl68qF+n+0Ny57mEEKJ9+/YiMDBQv7xjxw79H9i76S5YFy5cEAqFQrz77rsG248fPy7q1KlTbv3ddBe3il4qlarcMZVKpRg/fry4fv268PLyEh07dhQlJSXl6sXLy8vgD+0PP/wgAIjFixcb1MPdScLddVhcXCzatGkj+vXrZ7C+suQmODjY4GL++uuvC4VCIbKzs4UQQuTl5QknJycxYcIEg+OlpaUJR0dHg/UBAQHC09NTv68Qt/+Q3i+5ycnJESqVSkybNs1g/QcffGDwffj4448FAHH16tV7Hq+qdMmNEEKsWrVKABDr16/Xb3/Y5AaA+P777/XrTp8+LQAIuVwu9u/fr1+/detWAUCsWLFCv053sR02bJjBuSZOnCgAiKNHjwohjPtO62JatmxZleonICBAuLm5iWvXrunXHT16VMjlcv1/fu78/OvWrbvvMZ2dnYW/v3+Vzp+RkSGUSqV47LHHDP4GffrppwKAWL58uX5dTdV3UlKSACDGjx9vUG769OkCgNixY4d+nY+PjwAgdu/ebfCZ7v6uL1iwQNjZ2YkzZ84YHHPGjBlCoVCI1NRUIcTt5KZevXoiKytLX27Dhg0CgPjf//6nXzdp0iRRUXvEa6+9JtRqtSgtLS237VHG21IWRKFQYNSoUUhISDBoZv/+++/h7u6O/v37Ayjrr6HrjKrRaHDt2jX97YDDhw+XO+7YsWNhY2Nz3/PfWaagoACZmZno1q0bhBA4cuRIufIvv/yywXLPnj3x999/65d/+uknyGQyREVFldtX1yS7fv16aLVajBw5EpmZmfqXh4cHmjVrhp07d943bgCIjY3F9u3bDV5btmwxKNOmTRvMmzcPX331FUJCQpCZmYlVq1ahTp3yXdfGjBkDBwcH/fLTTz8NT09PbN68+Z5x3FmH169fR05ODnr27Fnhz6UiL730kkFzdc+ePaHRaHDx4kUAZbeAsrOz8eyzzxrUl0KhQJcuXfT1deXKFSQlJWHs2LFwdHTUH2/AgAFo1arVfePQ3er84YcfDEYtrV27Fl27dkXDhg0B3O7TsWHDBoPmelMYPXo0mjVrhvnz51c4cupB2NvbY9SoUfplPz8/ODk5oWXLlujSpYt+ve79nd9nnUmTJhksT5kyBQD03w1jv9MqlQrh4eH3jV33Mw0LC0PdunX169u1a4cBAwbc97tZmdzcXIPv+r389ttvKC4uxtSpUw06xE+YMAFqtRqbNm0yKF8T9a37NyIiwqDctGnTAKBcTK1atULPnj31y66urvDz8zM497p169CzZ084Ozsb/AyDg4Oh0Wiwe/dug2OGhobC2dlZv6w7fkWf525OTk4oKCjA9u3b71v2UcLkxsLoOgx///33AIB//vkHf/zxB0aNGgWFQgGgrB/Lxx9/jGbNmkGlUsHFxQWurq44duwYcnJyyh2zolFEFUlNTdX/4dT1o9Hdu7/7uLr+M3dydnbG9evX9cvnz59H/fr1Df4Q3+3s2bMQQqBZs2ZwdXU1eJ06darC/kcV6dy5M4KDgw1effv2LVfujTfegL+/Pw4cOICoqKhKL/TNmjUzWJbJZGjatGm5vh13+/XXX9G1a1dYW1ujbt26cHV1xWeffVbhz6UiuqRBR/cHU1evZ8+eBQD069evXH1t27ZNX1+6ZOjuzwGUXWCqIjQ0FJcuXUJCQgKAsp9nYmIiQkNDDcp0794d48ePh7u7O0aNGoUffvjBJImOQqHArFmzkJSUhF9++eWhjwcADRo0KNdB2dHREd7e3uXWATD4PuvcXadNmjSBXC7XfzeM/U57eXlVadSi7mda0c+vZcuWyMzMREFBwX2Pcze1Wn3PKSiqEoNSqUTjxo3123Vqor4vXrwIuVxebmSkh4cHnJycysV09+8YUP5v19mzZxEXF1fu5xccHAwA5X6G9/u9vZeJEyeiefPmGDRoEBo0aIBx48YhLi7uvvtZOo6WsjCBgYFo0aIFVq9ejZkzZ2L16tUQQhiMklq4cCFmz56NcePGYcGCBahbty7kcjmmTp1a4UWlKq02Go0GAwYMQFZWFt566y20aNECdnZ2uHz5MsLCwsodV5doPSytVguZTIYtW7ZUeEx7e3uTnEfn77//1icIx48fN+mx//jjDwwbNgy9evXC0qVL4enpCSsrK6xYsUKfrN5PZfWqa7nQ/Ry+/fZbeHh4lCtXUSvUgxo6dChsbW3xww8/oFu3bvjhhx8gl8vxzDPP6MvY2Nhg9+7d2LlzJzZt2oS4uDisXbsW/fr1w7Zt2x76ezJ69GgsWLAA8+fPx4gRI8ptr2wk1d0d23Uqi+d+9X4vd8dg7He6Kr+f1alFixZISkpCcXGxyaeGqIn6vt/6Bzm3VqvFgAED8Oabb1ZYtnnz5kYfszJubm5ISkrC1q1bsWXLFmzZsgUrVqzAmDFjsGrVqvvub6mY3Fig0aNHY/bs2Th27Bi+//57NGvWDJ06ddJv//HHH9G3b198/fXXBvtlZ2fDxcXlgc55/PhxnDlzBqtWrTIYiv4wTaVNmjTB1q1bkZWVVWnrTZMmTSCEQKNGjcr9wTA1rVaLsLAwqNVqTJ06FQsXLsTTTz+NJ598slxZXQKkI4TAuXPn0K5du0qP/9NPP8Ha2hpbt241GOq9YsUKk32GJk2aACj7g6j7X2RFdBO23f05gLI5dqrCzs4Ojz/+ONatW4eYmBisXbsWPXv2RP369Q3KyeVy9O/fH/3790dMTAwWLlyIt99+Gzt37rxnjFWha70JCwvDhg0bym3X/Q/57pE6d/9v3ZTOnj1r0Bp67tw5aLVa/azP1fWd1v1MK/r5nT59Gi4uLrCzszP6uEOHDkVCQgJ++uknPPvss1WO4c7RdMXFxUhJSXnon3dF7lffPj4+0Gq1OHv2LFq2bKkvl56ejuzs7PtOXliRJk2aID8/36Sf517Jl1KpxNChQzF06FBotVpMnDgRn3/+OWbPnl1r5+qqbrwtZYF0rTRz5sxBUlJSubltFApFuf8RrFu3DpcvX37gc+r+53HncYUQDzUc8amnnoIQAvPmzSu3TXeeJ598EgqFAvPmzSv3mYQQJp2NOSYmBvv27cMXX3yBBQsWoFu3bnjllVcqnE7/m2++MWiq//HHH3HlyhUMGjSo0uMrFArIZDKDVoMLFy6Y7JYKAISEhECtVmPhwoUoKSkpt103bNzT0xMBAQFYtWqVwS2x7du34+TJk1U+X2hoKP7991989dVXOHr0qMEtKQDIysoqt09AQAAAGAzDPX36NFJTU6t83js9//zzaNq0aYXfI12yd2cfCI1Ggy+++OKBzlUVuiG9OkuWLAEA/Xejur7Td/5M70zmTpw4gW3btmHw4MEPdNyXX34Znp6emDZtGs6cOVNue0ZGBt555x0AQHBwMJRKJT755BODz/b1118jJycHQ4YMeaAY7uV+9a373IsWLTIoFxMTAwAPFNPIkSORkJCArVu3ltuWnZ2N0tJSo4+pSzzvTsTv/j7I5XL9f6LuHsr+KGHLjQVq1KgRunXrpv+f6t3JzeOPP4758+cjPDwc3bp1w/Hjx/Hf//630nlJqqJFixZo0qQJpk+fjsuXL0OtVuOnn36q0j3jyvTt2xcvvPACPvnkE5w9exYDBw6EVqvFH3/8gb59+2Ly5Mlo0qQJ3nnnHURGRuLChQsYMWIEHBwckJKSgp9//hkvvfQSpk+fft9zbdmyBadPny63vlu3bmjcuDFOnTqF2bNnIywsDEOHDgVQNkdKQEAAJk6ciB9++MFgv7p166JHjx4IDw9Heno6Fi1ahKZNm2LChAmVxjBkyBDExMRg4MCBeO6555CRkYHY2Fg0bdoUx44dM7L2KqZWq/HZZ5/hhRdeQIcOHTBq1Ci4uroiNTUVmzZtQvfu3fHpp58CAKKjozFkyBD06NED48aNQ1ZWFpYsWYLWrVsjPz+/SucbPHgwHBwcMH36dCgUinIzBs+fPx+7d+/GkCFD4OPjg4yMDCxduhQNGjRAjx499OVatmyJ3r17P9CzzBQKBd5+++0KO922bt0aXbt2RWRkpL6FcM2aNQ908amqlJQUDBs2DAMHDkRCQgK+++47PPfcc/D39wcAk32nK/Lhhx9i0KBBCAoKwosvvoibN29iyZIlcHR0fOCZb52dnfHzzz9j8ODBCAgIMJih+PDhw1i9ejWCgoIAlHW+jYyMxLx58zBw4EAMGzYMycnJWLp0KTp16oTnn3/+gWK4l/vVt7+/P8aOHYsvvvgC2dnZ6N27Nw4cOIBVq1ZhxIgRFfa9u5833ngDGzduxOOPP46wsDAEBgaioKAAx48fx48//ogLFy4Y3Uquq9NXX30VISEh+gEk48ePR1ZWFvr164cGDRrg4sWLWLJkCQICAgxaoh45NTcwi2pSbGysACA6d+5cblthYaGYNm2a8PT0FDY2NqJ79+4iISFB9O7dW/Tu3Vtf7l7DQSsaKnvy5EkRHBws7O3thYuLi5gwYYI4evRouSGadw7XvZNu6OadSktLxYcffihatGghlEqlcHV1FYMGDRKJiYkG5X766SfRo0cPYWdnJ+zs7ESLFi3EpEmTRHJy8j3r6V5DwXVxl5aWik6dOokGDRoYDIsWQojFixcLAGLt2rUG9bJ69WoRGRkp3NzchI2NjRgyZIjBcHhdPdw9pPrrr78WzZo1EyqVSrRo0UKsWLGiwnqpbCj4wYMHDcpV9HPSrQ8JCRGOjo7C2tpaNGnSRISFhYlDhw6Vq9eWLVsKlUolWrVqJdavX19h3PcyevRo/TD1u8XHx4vhw4eL+vXrC6VSKerXry+effbZckNoARh8NytT2XerpKRENGnSpNxQcCGEOH/+vAgODhYqlUo/f8n27dsrHAreunXrcsf28fERQ4YMKbf+7nPpfo4nT54UTz/9tHBwcBDOzs5i8uTJ4ubNm+X2r8p3urKY7uW3334T3bt3FzY2NkKtVouhQ4eKkydPGpQxZii4zr///itef/110bx5c2FtbS1sbW1FYGCgePfdd0VOTo5B2U8//VS0aNFCWFlZCXd3d/HKK6+Um5OqJuu7pKREzJs3TzRq1EhYWVkJb29vERkZKQoLC6t07rv/dgpRNu1CZGSkaNq0qVAqlcLFxUV069ZNfPTRR/r5a3RDwXXzPt39eaKiovTLpaWlYsqUKcLV1VXIZDL934Qff/xRPPbYY8LNzU0olUrRsGFD8Z///EdcuXKl3DEfJTIhTDRGkoiwa9cu9O3bF+vWrcPTTz8tdThEj6y5c+di3rx5uHr16gP3JSTzxT43REREZFGY3BAREZFFYXJDREREFoV9boiIiMiisOWGiIiILAqTGyIiIrIoj9wkflqtFv/++y8cHByq/CwRIiIikpYQAnl5eahfv77BU+Ur8sglN//++2+5J8oSERGRebh06RIaNGhwzzKPXHLj4OAAoKxy1Gq1xNEQERFRVeTm5sLb21t/Hb+XRy650d2KUqvVTG6IiIjMTFW6lLBDMREREVkUJjdERERkUZjcEBERkUVhckNEREQWhckNERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFEkTW52796NoUOHon79+pDJZPjll1/uu8+uXbvQoUMHqFQqNG3aFCtXrqz2OImIiMh8SJrcFBQUwN/fH7GxsVUqn5KSgiFDhqBv375ISkrC1KlTMX78eGzdurWaIyUiIiJzIemDMwcNGoRBgwZVufyyZcvQqFEj/N///R8AoGXLltizZw8+/vhjhISEVFeYRET3JISAEIDQvQduLZetv/e+dy1D3Gd7+XOXO+Z9znF3gZo4593nuM/i/fevoIxUakkYACr+2UhBWUcONwdryc5vVk8FT0hIQHBwsMG6kJAQTJ06tdJ9ioqKUFRUpF/Ozc2trvCIaoQQAqVageJSbdlLc/vfUo1AqVYLjVagRCOg0d5eLtsmoNFq79hWfrlUo721/vay7r1WCGi1AloBaISAEAJabdl77a0LvEZb/n3ZC9CKsuOKit7rymjvKH/H/ncmD9o7Egfd3/KKkgrdMlBJ8nHrPe6RmNzeXvExiKi8Dg2dsH5id8nOb1bJTVpaGtzd3Q3Wubu7Izc3Fzdv3oSNjU25faKjozFv3ryaCpEeMaUaLW6UaFBYrMHNkluvW+8LSzS4WazVr7+7TOGt93cmKUW33pdo7kpcbr2KNGXbeFElcyGT3bVcbrvsPtvv3v8+BzRjFvRRYKWQdrySWSU3DyIyMhIRERH65dzcXHh7e0sYEdUWRaUa5NwoQfbNEmTfKEH2jWLkFZYiv6jslVdYioI73ucXlaCgSGOwXFiilfpjQCGXQamQw0ohg5VCjjoKGerI5VDIZagjl6GOQgaFXK5/X0cuu7VNbriskN+xzXDZSiGHXCaDQg7IZbI7XoBcLjPYJpPJoLi1vuz9rXIy2a2yZTHLbq1XyO54f+tYsjve684ju7VeBt0F785lmX697NZ63LVs8N7YY1Sw7dbudx3TsBz0573tYS/md2+/m7H7P3Sycb+AiCRgVsmNh4cH0tPTDdalp6dDrVZX2GoDACqVCiqVqibCIwkJIZBzswRX84pwNb8ImfnFuJpXhMz8ImTfKL6VvJQlMjk3inH9RglulmhMdn65DLCxUsBGqYC1laL8+3Lb5LCxKltW1ZFDeetlpZBDqbi9rKojh1KhuLVNdnv9rXXKOmVJDBER3WZWyU1QUBA2b95ssG779u0ICgqSKCKqCYUlGlzJKcS/2TdvvQpxJecmMvKK9AlMZn4RSjTG36uRywBHGys42yqhtrGC2sYKDqo6sFfVgZ2qDuyt65QtW5ct698r68DBuqycjbIsQeH/YImIagdJk5v8/HycO3dOv5ySkoKkpCTUrVsXDRs2RGRkJC5fvoxvvvkGAPDyyy/j008/xZtvvolx48Zhx44d+OGHH7Bp0yapPgKZgFYr8G/OTVy8dgMXrhXgQmYBLl67gX9zbuJKdiGuFRRX+Vhq6zpwcVDB1V6l/7eunRJOtlZwtLGCk60STreSGUfbskRGzpYPIiKLImlyc+jQIfTt21e/rOsbM3bsWKxcuRJXrlxBamqqfnujRo2wadMmvP7661i8eDEaNGiAr776isPAzURhiQbnr+YjOS0Pyel5OJ9RgAvXCpCadQPFpffuu2JjpUB9J2vUd7JBfUcbeDpZw0NtDRd7FVwdyhKZenZKWFspaujTEBFRbSUTtWVQfA3Jzc2Fo6MjcnJyoFarpQ7HYmXmF+HYP9k4/k8uktNzkZyWhwvXbkCjrfjrZqWQwbuuLXzr2cG3nh186tnCy8mmLJlxsoajjRVv+xARPcKMuX6bVZ8bqp0KSzRIupSNo5eycfSfbBy9lIPL2TcrLOtoYwU/Dwe08HBAUzd7NHIpS2Y8Ha1RR+Khg0REZBmY3JDRCks0OHzxOvb/fQ37/85C0qVsFGsMbyvJZEBTV3u0beCIVp5qNHd3gJ+HA9wcVGyBISKiasXkhqrkQmYBdpzOwM7kDPz5d1a5ZMZdrUKHhs5o18AJ/t6OaOvlCAdrK4miJSKiRxmTG6qQEAJH/8nBpmP/Iv50Bv6+WmCw3UNtja6N66Jr43ro2rgefOrZskWGiIhqBSY3ZCA5LQ8bj17G/45eQWrWDf36OnIZOvnWRb8Wbujbwg1NXO2YzBARUa3E5IZQUFSKjUf/xfd/puL45Rz9ehsrBQa0csfANh7o0cwFat5mIiIiM8Dk5hF2LiMPq/ZdxM9HLiO/qBRA2ZDs3s3dMCygPoJbusFWya8IERGZF165HkGHU6/js13nsf3k7ed0NXKxw3OdG+KpwAaoa6eUMDoiIqKHw+TmEZJ4MQsfxCXjz5Qs/brHWrljbDdfBDWux8cQEBGRRWBy8wg4fzUfH8Sdxta/ylpqrBQyjAjwwn96N0ZTNweJoyMiIjItJjcWrKCoFP+37QxWJVyARisglwHPBHrjteBmqO9kI3V4RERE1YLJjYX67WQ65mw4gX9zCgEAwS3d8ObAFmjuzpYaIiKybExuLExuYQlm/3ICG5L+BQB417XBguFt0MfPTeLIiIiIagaTGwuSeDELr61Jwj/Xb0Ihl2F8z0aY2r85bJQKqUMjIiKqMUxuLIAQAl/9kYL34k5DoxXwrmuDxaPao0NDZ6lDIyIiqnFMbsxcUakGM9efwE+H/wEADA+ojwUj2nA2YSIiemQxuTFj2TeK8eKqQ0i8eB1yGTD78VYI6+bLZz4REdEjjcmNmcrIK8QLXx1Acnoe1NZ1EDu6A3o2c5U6LCIiIskxuTFD/2bfxHNf7seFazfg5qDCd+O7cIg3ERHRLUxuzExmfhGe/+pPXLh2Aw2cbfDf8V3gU89O6rCIiIhqDSY3ZiTnZgnGfH0Af2cWwMvJBj/8J4gzDRMREd1FLnUAVDUlGi1e+S4RJ6/kwsW+7FYUExsiIqLymNyYiXc3ncK+89dgp1Rg1bhOaOTCW1FEREQVYXJjBn44dAkr910AAMSEBqB1fUdpAyIiIqrFmNzUcmfT8zD7lxMAgKnBzRDS2kPiiIiIiGo3Jje1WFGpBq+uSUJRqRa9mrvi1X7NpA6JiIio1mNyU4t9tDUZp67koq6dEh890w5yOWceJiIiuh8mN7VU0qVsfLUnBQDw/lPt4OZgLXFERERE5oHJTS1UqtFi5vrjEAJ4or0XBrRylzokIiIis8HkphZaue8CTl7JhaONFd4e0lLqcIiIiMwKk5ta5npBMRb/dhYAMGNQC7jYqySOiIiIyLwwuallPvv9PPKKStHSU43Qjt5Sh0NERGR2mNzUIv9m39RP1vfmQD+OjiIiInoATG5qkSU7zqK4VIvOjeqiT3NXqcMhIiIyS0xuaon03EL8mPgPAOCNED/IZGy1ISIiehCSJzexsbHw9fWFtbU1unTpggMHDlRatqSkBPPnz0eTJk1gbW0Nf39/xMXF1WC01WfF3gso0Qh09HFGJ9+6UodDRERktiRNbtauXYuIiAhERUXh8OHD8Pf3R0hICDIyMiosP2vWLHz++edYsmQJTp48iZdffhlPPPEEjhw5UsORm1ZeYQn+u/8iAOA/vZtIHA0REZF5kwkhhFQn79KlCzp16oRPP/0UAKDVauHt7Y0pU6ZgxowZ5crXr18fb7/9NiZNmqRf99RTT8HGxgbfffddlc6Zm5sLR0dH5OTkQK1Wm+aDPKSVe1Mw938n0cTVDttf782OxERERHcx5votWctNcXExEhMTERwcfDsYuRzBwcFISEiocJ+ioiJYWxs+hsDGxgZ79uyp9DxFRUXIzc01eNUmQgisPnAJADAmyJeJDRER0UOSLLnJzMyERqOBu7vhowXc3d2RlpZW4T4hISGIiYnB2bNnodVqsX37dqxfvx5Xrlyp9DzR0dFwdHTUv7y9a9fcMUmXspGcngdVHTlGBHhJHQ4REZHZk7xDsTEWL16MZs2aoUWLFlAqlZg8eTLCw8Mhl1f+MSIjI5GTk6N/Xbp0qQYjvr81t1pthrT1hKOtlcTREBERmT/JkhsXFxcoFAqkp6cbrE9PT4eHh0eF+7i6uuKXX35BQUEBLl68iNOnT8Pe3h6NGzeu9DwqlQpqtdrgVVsUlmiw6XhZq1Nop9rVokRERGSuJEtulEolAgMDER8fr1+n1WoRHx+PoKCge+5rbW0NLy8vlJaW4qeffsLw4cOrO9xq8cfZTOQXlcJDbc3h30RERCZSR8qTR0REYOzYsejYsSM6d+6MRYsWoaCgAOHh4QCAMWPGwMvLC9HR0QCAP//8E5cvX0ZAQAAuX76MuXPnQqvV4s0335TyYzywzbdabQa39WRHYiIiIhORNLkJDQ3F1atXMWfOHKSlpSEgIABxcXH6TsapqakG/WkKCwsxa9Ys/P3337C3t8fgwYPx7bffwsnJSaJP8OAKSzTYfrLsltyQdhXfhiMiIiLjSTrPjRRqyzw320+mY8I3h+Chtsa+Gf3YckNERHQPZjHPzaPut1utNgPbeDCxISIiMiEmNxIQQuD3M1cBAH1buEkcDRERkWVhciOB5PQ8pOUWwtpKji6NOEqKiIjIlJjcSGBXclmrTdfG9WBtpZA4GiIiIsvC5EYCu5LLnnrep7mrxJEQERFZHiY3NSy/qBSHLlwHAPTxY38bIiIiU2NyU8OOpF5HqVbAy8kGvi52UodDRERkcZjc1DBdq00nX2eJIyEiIrJMD5TcfPvtt+jevTvq16+PixcvAgAWLVqEDRs2mDQ4S3ToYhYAoCOfJUVERFQtjE5uPvvsM0RERGDw4MHIzs6GRqMBADg5OWHRokWmjs+ilGi0OJKaDQDozCHgRERE1cLo5GbJkiX48ssv8fbbb0OhuD2MuWPHjjh+/LhJg7M0p67k4kaxBo42Vmjqai91OERERBbJ6OQmJSUF7du3L7depVKhoKDAJEFZqmP/5AAA/L2d+MgFIiKiamJ0ctOoUSMkJSWVWx8XF4eWLVuaIiaLdeJyWXLT1ku6B3YSERFZujrG7hAREYFJkyahsLAQQggcOHAAq1evRnR0NL766qvqiNFinPhXl9w4ShwJERGR5TI6uRk/fjxsbGwwa9Ys3LhxA8899xzq16+PxYsXY9SoUdURo0UoKtUgOS0PANC6PpMbIiKi6mJ0cgMAo0ePxujRo3Hjxg3k5+fDzY0z7d7PmbR8lGgEnGyt0MDZRupwiIiILJbRyU1KSgpKS0vRrFkz2NrawtbWFgBw9uxZWFlZwdfX19QxWgTdLak29R0hk7EzMRERUXUxukNxWFgY9u3bV279n3/+ibCwMFPEZJGO3+pM3JqdiYmIiKqV0cnNkSNH0L1793Lru3btWuEoKipz6kouAPa3ISIiqm5GJzcymQx5eXnl1ufk5OhnKyZDQgicS88HAPi5O0gcDRERkWUzOrnp1asXoqOjDRIZjUaD6Oho9OjRw6TBWYr03CLkFZVCIZfB18VW6nCIiIgsmtEdit9//3306tULfn5+6NmzJwDgjz/+QG5uLnbs2GHyAC3B2Yyyli7ferZQ1VHcpzQRERE9DKNbblq1aoVjx45h5MiRyMjIQF5eHsaMGYPTp0+jTZs21RGj2Tt765ZUMzfekiIiIqpuDzTPTf369bFw4UJTx2KxzmbcSm7c+bBMIiKi6vZAyU12djYOHDiAjIwMaLVag21jxowxSWCW5Pyt5KapG5MbIiKi6mZ0cvO///0Po0ePRn5+PtRqtcGEdDKZjMlNBVKzbgAAfOrZSRwJERGR5TO6z820adMwbtw45OfnIzs7G9evX9e/srKyqiNGs1ZYokFabiEAoGFdjpQiIiKqbkYnN5cvX8arr76qf+wC3dvl7JsAADulAs62VhJHQ0REZPmMTm5CQkJw6NCh6ojFIuluSXnXteUzpYiIiGqA0X1uhgwZgjfeeAMnT55E27ZtYWVl2BoxbNgwkwVnCf65ldzwlhQREVHNMDq5mTBhAgBg/vz55bbJZDI+guEud7bcEBERUfUzOrm5e+g33dulrLI+N2y5ISIiqhlG97kh4/yTXdZy08DZRuJIiIiIHg0PNIlfQUEBfv/9d6SmpqK4uNhg26uvvmqSwCxFWk4RAMDD0VriSIiIiB4NRic3R44cweDBg3Hjxg0UFBSgbt26yMzMhK2tLdzc3Jjc3KFEo8W1grLkxl3N5IaIiKgmGH1b6vXXX8fQoUNx/fp12NjYYP/+/bh48SICAwPx0UcfGR1AbGwsfH19YW1tjS5duuDAgQP3LL9o0SL4+fnBxsYG3t7eeP3111FYWGj0eWtCRl4RhACsFDLUtVVKHQ4REdEjwejkJikpCdOmTYNcLodCoUBRURG8vb3xwQcfYObMmUYda+3atYiIiEBUVBQOHz4Mf39/hISEICMjo8Ly33//PWbMmIGoqCicOnUKX3/9NdauXWv0eWtK+q2Zid0crCGXc44bIiKimmB0cmNlZQW5vGw3Nzc3pKamAgAcHR1x6dIlo44VExODCRMmIDw8HK1atcKyZctga2uL5cuXV1h+37596N69O5577jn4+vrisccew7PPPnvf1h6ppOeUJTfuapXEkRARET06jE5u2rdvj4MHDwIAevfujTlz5uC///0vpk6dijZt2lT5OMXFxUhMTERwcPDtYORyBAcHIyEhocJ9unXrhsTERH0y8/fff2Pz5s0YPHhwpecpKipCbm6uwaum6J4pxc7ERERENcfo5GbhwoXw9PQEALz77rtwdnbGK6+8gqtXr+KLL76o8nEyMzOh0Wjg7u5usN7d3R1paWkV7vPcc89h/vz56NGjB6ysrNCkSRP06dPnnreloqOj4ejoqH95e3tXOcaHlZ5b1pnYzYHJDRERUU0xOrnp2LEj+vbtC6DstlRcXBxyc3ORmJgIf39/kwd4p127dmHhwoVYunQpDh8+jPXr12PTpk1YsGBBpftERkYiJydH/zL21tnD0PW54UgpIiKimvNA89yYgouLCxQKBdLT0w3Wp6enw8PDo8J9Zs+ejRdeeAHjx48HALRt2xYFBQV46aWX8Pbbb+v7At1JpVJBpZKmz0tmflnLjasD+9wQERHVlColNx06dEB8fDycnZ3Rvn37ez7d+vDhw1U6sVKpRGBgIOLj4zFixAgAZY92iI+Px+TJkyvc58aNG+USGIVCAQAQQlTpvDXp+o2yCQ7r2lndpyQRERGZSpWSm+HDh+tbP3SJiClERERg7Nix6NixIzp37oxFixahoKAA4eHhAIAxY8bAy8sL0dHRAIChQ4ciJiYG7du3R5cuXXDu3DnMnj0bQ4cO1Sc5tcn1ghIAQF07ttwQERHVlColN1FRUQAAjUaDvn37ol27dnBycnrok4eGhuLq1auYM2cO0tLSEBAQgLi4OH0n49TUVIOWmlmzZkEmk2HWrFm4fPkyXF1dMXToULz77rsPHUt10M1OzAn8iIiIao5MGHk/x9raGqdOnUKjRo2qK6ZqlZubC0dHR+Tk5ECtVlfbeW4Wa9ByThwA4Pjcx+BgzVtTRERED8qY67fRo6XatGmDv//++4GDe1Rk3epvY6WQwV4lWb9tIiKiR47Ryc0777yD6dOn49dff8WVK1ckmyCvtrteoOtMrLxnB2wiIiIyLaObFHSzAQ8bNszgoi2EgEwmg0ajMV10ZizrVnLjzP42RERENcro5Gbnzp3VEYfFuT0MnMkNERFRTTI6uendu3d1xGFxrrPlhoiISBIP3NP1xo0bSE1NRXFxscH6du3aPXRQliC3sBQAoLZhZ2IiIqKaZPSV9+rVqwgPD8eWLVsq3M4+N2Vyb5ZN4KfmEHAiIqIaZfRoqalTpyI7Oxt//vknbGxsEBcXh1WrVqFZs2bYuHFjdcRolnILbyU3NkxuiIiIapLRLTc7duzAhg0b0LFjR8jlcvj4+GDAgAFQq9WIjo7GkCFDqiNOs5Onuy1lzdtSRERENcnolpuCggK4ubkBAJydnXH16lUAZU/orupDMx8FbLkhIiKShtHJjZ+fH5KTkwEA/v7++Pzzz3H58mUsW7YMnp6eJg/QXOXe1LXcMLkhIiKqSUbfM3nttddw5coVAGUP1Bw4cCD++9//QqlUYuXKlaaOz2zdbrnhbSkiIqKaVOUr79NPP43x48dj9OjR+pmJAwMDcfHiRZw+fRoNGzaEi4tLtQVqbnSjpfjATCIioppV5dtS169fx5AhQ9CwYUPMmTNH//BMW1tbdOjQgYnNHYQQt+e5YXJDRERUo6qc3MTHx+Pvv//Giy++iO+++w7NmjVDv3798P3336OoqKg6YzQ7N4o10GgFAN6WIiIiqmlGdSj28fHB3Llz8ffff2P79u2oX78+JkyYAE9PT0yaNAmJiYnVFadZ0fW3qSOXwcZKIXE0REREjxajR0vp9OvXD9999x3S0tIQHR2NNWvWoEuXLqaMzWzpR0rZWBk8OZ2IiIiq30PdM0lJScHKlSuxcuVK5OTkIDg42FRxmTX9SClO4EdERFTjjG65KSwsxHfffYd+/fqhWbNm+Oabb/Diiy8iJSUFcXFx1RGj2cm7ldzYM7khIiKqcVW++h44cADLly/H2rVrUVhYiCeeeAJxcXHo378/b73cpaCo7OGhdkomN0RERDWtylffrl27wt/fHwsWLMDo0aPh7OxcnXGZtZvFt5IbFZMbIiKimlblq++hQ4fQoUOH6ozFYhQUl3UotlVypBQREVFNq3KfGyY2VXejmLeliIiIpPLAQ8GpcgVFZS03Nmy5ISIiqnFMbqqBvuVGxeSGiIiopjG5qQY39H1ueFuKiIiopjG5qQYF+j43bLkhIiKqaVVqWmjfvn2V57I5fPjwQwVkCW7c6nNjy6HgRERENa5KV98RI0bo3xcWFmLp0qVo1aoVgoKCAAD79+/HX3/9hYkTJ1ZLkOamgKOliIiIJFOlq29UVJT+/fjx4/Hqq69iwYIF5cpcunTJtNGZqRuc54aIiEgyRve5WbduHcaMGVNu/fPPP4+ffvrJJEGZO91oKSY3RERENc/o5MbGxgZ79+4tt37v3r2wtrY2SVDm7kYRH79AREQkFaOvvlOnTsUrr7yCw4cPo3PnzgCAP//8E8uXL8fs2bNNHqA54uMXiIiIpGN0cjNjxgw0btwYixcvxnfffQcAaNmyJVasWIGRI0eaPEBzI4S4YxI/ttwQERHVtAe6+o4cOZKJTCWKNVpotAIAYG3FlhsiIqKa9kCT+GVnZ+Orr77CzJkzkZWVBaBsfpvLly8/UBCxsbHw9fWFtbU1unTpggMHDlRatk+fPpDJZOVeQ4YMeaBzm1pRqVb/3tqKcyQSERHVNKNbbo4dO4bg4GA4OjriwoULGD9+POrWrYv169cjNTUV33zzjVHHW7t2LSIiIrBs2TJ06dIFixYtQkhICJKTk+Hm5lau/Pr161FcXKxfvnbtGvz9/fHMM88Y+1GqRfEdyY1SweSGiIiophl99Y2IiEBYWBjOnj1rMDpq8ODB2L17t9EBxMTEYMKECQgPD0erVq2wbNky2NraYvny5RWWr1u3Ljw8PPSv7du3w9bWttYkN7qWG1UdeZVndSYiIiLTMTq5OXjwIP7zn/+UW+/l5YW0tDSjjlVcXIzExEQEBwffDkguR3BwMBISEqp0jK+//hqjRo2CnZ1dhduLioqQm5tr8KpORSVlnYlVddhqQ0REJAWjr8AqlarCBOHMmTNwdXU16liZmZnQaDRwd3c3WO/u7l6lROnAgQM4ceIExo8fX2mZ6OhoODo66l/e3t5GxWgsfcsNOxMTERFJwujkZtiwYZg/fz5KSkoAADKZDKmpqXjrrbfw1FNPmTzAe/n666/Rtm1b/Xw7FYmMjEROTo7+Vd2PiLjzthQRERHVPKOvwP/3f/+H/Px8uLm54ebNm+jduzeaNm0KBwcHvPvuu0Ydy8XFBQqFAunp6Qbr09PT4eHhcc99CwoKsGbNGrz44ov3LKdSqaBWqw1e1Ym3pYiIiKRl9GgpR0dHbN++HXv27MGxY8eQn5+PDh06GPSbqSqlUonAwEDEx8frnzyu1WoRHx+PyZMn33PfdevWoaioCM8//7zR561Ot1tueFuKiIhICg88hW6PHj3Qo0ePhw4gIiICY8eORceOHdG5c2csWrQIBQUFCA8PBwCMGTMGXl5eiI6ONtjv66+/xogRI1CvXr2HjsGUbve5YcsNERGRFB4ouYmPj0d8fDwyMjKg1WoNtlU2hLsyoaGhuHr1KubMmYO0tDQEBAQgLi5O38k4NTUVcrlhopCcnIw9e/Zg27ZtDxJ+tSoq5W0pIiIiKRmd3MybNw/z589Hx44d4enpaZK5XCZPnlzpbahdu3aVW+fn5wchxEOftzoUlfC2FBERkZSMTm6WLVuGlStX4oUXXqiOeMweR0sRERFJy+grcHFxMbp161YdsVgE/W0pznNDREQkCaOTm/Hjx+P777+vjlgsAltuiIiIpGX0banCwkJ88cUX+O2339CuXTtYWVkZbI+JiTFZcObodp8bJjdERERSeKCnggcEBAAATpw4YbCND4q8c7QUb0sRERFJwejkZufOndURh8XgPDdERETS4hXYxDjPDRERkbSq1HLz5JNPYuXKlVCr1XjyySfvWXb9+vUmCcxccZ4bIiIiaVUpuXF0dNT3p3F0dKzWgMwdR0sRERFJq0rJzYoVKyp8T+XdnueGyQ0REZEUeAU2MT4VnIiISFoP9ODMH3/8ET/88ANSU1NRXFxssO3w4cMmCcxc6frcKHlbioiISBJGX4E/+eQThIeHw93dHUeOHEHnzp1Rr149/P333xg0aFB1xGhWSjS3khsF5/whIiKSgtHJzdKlS/HFF19gyZIlUCqVePPNN7F9+3a8+uqryMnJqY4YzUqJtuxp5XXkbLkhIiKSgtFX4NTUVP2DM21sbJCXlwcAeOGFF7B69WrTRmeGNNqylhsFW26IiIgkYXRy4+HhgaysLABAw4YNsX//fgBASkoKhBCmjc4MlWrK6sCKLTdERESSMPoK3K9fP2zcuBEAEB4ejtdffx0DBgxAaGgonnjiCZMHaG5Kdbel2HJDREQkCaNHS33xxRfQ3rr1MmnSJNSrVw/79u3DsGHD8J///MfkAZqb0lsdiuvImdwQERFJwejkRi6XQ37HLZdRo0Zh1KhRJg3KnN1uueFtKSIiIilUKbk5duxYlQ/Yrl27Bw7GEuj63LDlhoiISBpVSm4CAgIgk8nu22FYJpNBo9GYJDBzVXrrlh373BAREUmjSslNSkpKdcdhMfS3pdhyQ0REJIkqJTc+Pj7VHYfFuH1bin1uiIiIpPBAz5ZKTk7GkiVLcOrUKQBAy5YtMWXKFPj5+Zk0OHPE21JERETSMrp54aeffkKbNm2QmJgIf39/+Pv74/Dhw2jTpg1++umn6ojRrLDlhoiISFpGt9y8+eabiIyMxPz58w3WR0VF4c0338RTTz1lsuDMjRCCk/gRERFJzOjmhStXrmDMmDHl1j///PO4cuWKSYIyVxrt7dFk7FBMREQkDaOTmz59+uCPP/4ot37Pnj3o2bOnSYIyV6V3JjecxI+IiEgSRt+WGjZsGN566y0kJiaia9euAID9+/dj3bp1mDdvnv65U7qyj5JSttwQERFJTiaMfJS3vIodZWvrhH65ublwdHRETk4O1Gq1SY+dfaMYAfO3AwDOvTuIrTdEREQmYsz12+iWG91DM6m8Es3tPFHBlhsiIiJJmLRp4caNG6Y8nNnR3DE7sUzG5IaIiEgKRic3/fv3x+XLl8ut//PPPxEQEGCKmMxWiYYT+BEREUnN6OTG2toa7dq1w9q1awGU3aaaO3cuevbsicGDB5s8QHOia7mx4gR+REREkjG6z82mTZsQGxuLcePGYcOGDbhw4QIuXryIX3/9FY899lh1xGg2dI9eULDlhoiISDIP1MQwadIkvPrqq1izZg0OHTqEdevWPXBiExsbC19fX1hbW6NLly44cODAPctnZ2dj0qRJ8PT0hEqlQvPmzbF58+YHOrep3X4iOFtuiIiIpGL0Vfj69et46qmn8Nlnn+Hzzz/HyJEj8dhjj2Hp0qVGn3zt2rWIiIhAVFQUDh8+DH9/f4SEhCAjI6PC8sXFxRgwYAAuXLiAH3/8EcnJyfjyyy/h5eVl9Lmrw+3nSrHlhoiISCpG35Zq06YNGjVqhCNHjqBRo0aYMGEC1q5di4kTJ2LTpk3YtGlTlY8VExODCRMmIDw8HACwbNkybNq0CcuXL8eMGTPKlV++fDmysrKwb98+WFlZAQB8fX2N/QjVhh2KiYiIpGd0y83LL7+M3bt3o1GjRvp1oaGhOHr0KIqLi6t8nOLiYiQmJiI4OPh2MHI5goODkZCQUOE+GzduRFBQECZNmgR3d3e0adMGCxcuvOdkgUVFRcjNzTV4VZc7h4ITERGRNIxObmbPnl3hLMUNGjTA9u3bq3yczMxMaDQauLu7G6x3d3dHWlpahfv8/fff+PHHH6HRaLB582bMnj0b//d//4d33nmn0vNER0fD0dFR//L29q5yjMbSTeLHmYmJiIikU+Wr8AcffICbN2/ql/fu3YuioiL9cl5eHiZOnGja6O6i1Wrh5uaGL774AoGBgQgNDcXbb7+NZcuWVbpPZGQkcnJy9K9Lly5VW3xsuSEiIpJelZObyMhI5OXl6ZcHDRpkMJnfjRs38Pnnn1f5xC4uLlAoFEhPTzdYn56eDg8Pjwr38fT0RPPmzaFQKPTrWrZsibS0tEpvialUKqjVaoNXdSnRss8NERGR1Kqc3Nz9fE0jn7dZjlKpRGBgIOLj4/XrtFot4uPjERQUVOE+3bt3x7lz5wyeb3XmzBl4enpCqVQ+VDymcHu0FG9LERERSUXSq3BERAS+/PJLrFq1CqdOncIrr7yCgoIC/eipMWPGIDIyUl/+lVdeQVZWFl577TWcOXMGmzZtwsKFCzFp0iSpPoIBja7lhreliIiIJGP0UHBTCg0NxdWrVzFnzhykpaUhICAAcXFx+k7GqampBp2Xvb29sXXrVrz++uto164dvLy88Nprr+Gtt96S6iMY0E3ixyeCExERSceo5Oarr76Cvb09AKC0tBQrV66Ei4sLABj0xzHG5MmTMXny5Aq37dq1q9y6oKAg7N+//4HOVd30HYrZ54aIiEgyVU5uGjZsiC+//FK/7OHhgW+//bZcmUeZ9lY/JLmMyQ0REZFUqpzcXLhwoRrDsAy6fs5MboiIiKTDYT0mpNG33EgcCBER0SOMyY0JCd6WIiIikhyTGxPS6G5LsemGiIhIMkxuTEjL21JERESSY3JjQrrkhvPcEBERSeeBkpvz589j1qxZePbZZ5GRkQEA2LJlC/766y+TBmdutLfmuZGxzw0REZFkjE5ufv/9d7Rt2xZ//vkn1q9fj/z8fADA0aNHERUVZfIAzcmtR0tBweSGiIhIMkYnNzNmzMA777yD7du3Gzyssl+/frV25uCaItjnhoiISHJGJzfHjx/HE088UW69m5sbMjMzTRKUudJ3KGZ2Q0REJBmjkxsnJydcuXKl3PojR47Ay8vLJEGZKw1nKCYiIpKc0cnNqFGj8NZbbyEtLQ0ymQxarRZ79+7F9OnTMWbMmOqI0WzoR0sxuSEiIpKM0cnNwoUL0aJFC3h7eyM/Px+tWrVCr1690K1bN8yaNas6YjQbutFScg6wJyIikkyVH5ypo1Qq8eWXX2L27Nk4ceIE8vPz0b59ezRr1qw64jMrt3Ib3pYiIiKSkNHJzZ49e9CjRw80bNgQDRs2rI6YzJaGz5YiIiKSnNE3UPr164dGjRph5syZOHnyZHXEZLYEZygmIiKSnNHJzb///otp06bh999/R5s2bRAQEIAPP/wQ//zzT3XEZ1Y0+hmKJQ6EiIjoEWZ0cuPi4oLJkydj7969OH/+PJ555hmsWrUKvr6+6NevX3XEaDbY54aIiEh6DzWup1GjRpgxYwbee+89tG3bFr///rup4jJLfHAmERGR9B44udm7dy8mTpwIT09PPPfcc2jTpg02bdpkytjMjpa3pYiIiCRn9GipyMhIrFmzBv/++y8GDBiAxYsXY/jw4bC1ta2O+MyKhpP4ERERSc7o5Gb37t144403MHLkSLi4uFRHTGZLsM8NERGR5IxObvbu3VsdcVgEjZYPziQiIpJalZKbjRs3YtCgQbCyssLGjRvvWXbYsGEmCcwc6Z8KztyGiIhIMlVKbkaMGIG0tDS4ublhxIgRlZaTyWTQaDSmis3s8MGZRERE0qtScqPVait8T4Z0VcPbUkRERNIxeij4N998g6KionLri4uL8c0335gkKHPFZ0sRERFJz+jkJjw8HDk5OeXW5+XlITw83CRBmSv2uSEiIpKe0cmNEAKyClom/vnnHzg6OpokKHOlm8SPMxQTERFJp8pDwdu3bw+ZTAaZTIb+/fujTp3bu2o0GqSkpGDgwIHVEqS50D1bqqLkj4iIiGpGlZMb3SippKQkhISEwN7eXr9NqVTC19cXTz31lMkDNCca3pYiIiKSXJWTm6ioKACAr68vQkNDYW1tXW1BmSvBB2cSERFJzugZiseOHVsdcVgEjf7BmUxuiIiIpGJ0cqPRaPDxxx/jhx9+QGpqKoqLiw22Z2VlmSw4c6Prc8NJ/IiIiKRj9GipefPmISYmBqGhocjJyUFERASefPJJyOVyzJ0794GCiI2Nha+vL6ytrdGlSxccOHCg0rIrV67Ud2zWvWrLLTLBPjdERESSMzq5+e9//4svv/wS06ZNQ506dfDss8/iq6++wpw5c7B//36jA1i7di0iIiIQFRWFw4cPw9/fHyEhIcjIyKh0H7VajStXruhfFy9eNPq81YEPziQiIpKe0clNWloa2rZtCwCwt7fXT+j3+OOPY9OmTUYHEBMTgwkTJiA8PBytWrXCsmXLYGtri+XLl1e6j0wmg4eHh/7l7u5u9Hmrg+62FGcoJiIiko7RyU2DBg1w5coVAECTJk2wbds2AMDBgwehUqmMOlZxcTESExMRHBx8OyC5HMHBwUhISKh0v/z8fPj4+MDb2xvDhw/HX3/9VWnZoqIi5ObmGryqi/7BmUbXKhEREZmK0ZfhJ554AvHx8QCAKVOmYPbs2WjWrBnGjBmDcePGGXWszMxMaDSaci0v7u7uSEtLq3AfPz8/LF++HBs2bMB3330HrVaLbt264Z9//qmwfHR0NBwdHfUvb29vo2I0hpbPliIiIpKc0aOl3nvvPf370NBQNGzYEAkJCWjWrBmGDh1q0uAqEhQUhKCgIP1yt27d0LJlS3z++edYsGBBufKRkZGIiIjQL+fm5lZbgqPvc8PkhoiISDJGJzd3uzvZMIaLiwsUCgXS09MN1qenp8PDw6NKx7CyskL79u1x7ty5CrerVCqjb5c9KPa5ISIikl6VkpuNGzdW+YDDhg2rclmlUonAwEDEx8frH++g1WoRHx+PyZMnV+kYGo0Gx48fx+DBg6t83upy+8GZEgdCRET0CKtScqNLPO5HJpNBo9EYFUBERATGjh2Ljh07onPnzli0aBEKCgoQHh4OABgzZgy8vLwQHR0NAJg/fz66du2Kpk2bIjs7Gx9++CEuXryI8ePHG3Xe6qDrc8MZiomIiKRTpeRGq9VWWwChoaG4evUq5syZg7S0NAQEBCAuLk7fyTg1NRVy+e2mkOvXr2PChAlIS0uDs7MzAgMDsW/fPrRq1araYqwqDWcoJiIikpxM6KbVfUTk5ubC0dEROTk5UKvVJj32sE/34Ng/OVge1hH9WtSOuXeIiIgsgTHXb6M7FM+fP/+e2+fMmWPsIS0GH5xJREQkPaOTm59//tlguaSkBCkpKahTpw6aNGnySCc3fHAmERGR9IxObo4cOVJuXW5uLsLCwvDEE0+YJChzpeU8N0RERJIzyaBltVqNefPmYfbs2aY4nNnSz1DMoeBERESSMdllOCcnR/8QzUeVho9fICIikpzRt6U++eQTg2UhBK5cuYJvv/0WgwYNMllg5kg37kwhZ3JDREQkFaOTm48//thgWS6Xw9XVFWPHjkVkZKTJAjNHt58tJXEgREREjzCjk5uUlJTqiMMi8KngRERE0mPXVxPiaCkiIiLpGd1yU1hYiCVLlmDnzp3IyMgo92iGw4cPmyw4c6NlnxsiIiLJGZ3cvPjii9i2bRuefvppdO7cmbPx3kGjf3CmxIEQERE9woxObn799Vds3rwZ3bt3r454zJruMV1suSEiIpKO0X1uvLy84ODgUB2xmD0N+9wQERFJzujk5v/+7//w1ltv4eLFi9URj1nT9blhww0REZF0jL4t1bFjRxQWFqJx48awtbWFlZWVwfasrCyTBWdudLelAGY3REREUjE6uXn22Wdx+fJlLFy4EO7u7uxQfAd9asMqISIikozRyc2+ffuQkJAAf3//6ojHvN3KbpjbEBERScfoPjctWrTAzZs3qyMWs3e75YbpDRERkVSMTm7ee+89TJs2Dbt27cK1a9eQm5tr8CK23BAREUnJ6NtSAwcOBAD079/fYL0QAjKZDBqNxjSRmaHbHYqJiIhIKkYnNzt37qyOOCwCOxQTERFJz+jkpnfv3tURh0UQ+g7FzG6IiIikYnRys3v37ntu79Wr1wMHY+4E+GwpIiIiqRmd3PTp06fcujtHBz3afW6kjoCIiIiMHi11/fp1g1dGRgbi4uLQqVMnbNu2rTpiNBvsc0NERCQ9o1tuHB0dy60bMGAAlEolIiIikJiYaJLAzJKuzw2zGyIiIskY3XJTGXd3dyQnJ5vqcGaNqQ0REZF0jG65OXbsmMGyEAJXrlzBe++9h4CAAFPFZZbYoZiIiEh6Ric3AQEBkMlk5Sas69q1K5YvX26ywMwROxQTERFJz+jkJiUlxWBZLpfD1dUV1tbWJgvKXOk7FPPGFBERkWSMTm58fHyqIw6LoGvN4m0pIiIi6VS5Q/GOHTvQqlWrCh+OmZOTg9atW+OPP/4waXDm5nbLDREREUmlysnNokWLMGHCBKjV6nLbHB0d8Z///AcxMTEmDc7cCGY3REREkqtycnP06FH9E8Er8thjjz3ac9zcgX1uiIiIpFPl5CY9PR1WVlaVbq9Tpw6uXr1qkqDMHfvcEBERSafKyY2XlxdOnDhR6fZjx47B09PzgYKIjY2Fr68vrK2t0aVLFxw4cKBK+61ZswYymQwjRox4oPOa0p1D45nbEBERSafKyc3gwYMxe/ZsFBYWltt28+ZNREVF4fHHHzc6gLVr1yIiIgJRUVE4fPgw/P39ERISgoyMjHvud+HCBUyfPh09e/Y0+pzV4c45bvj4BSIiIunIxN2z8VUiPT0dHTp0gEKhwOTJk+Hn5wcAOH36NGJjY6HRaHD48GG4u7sbFUCXLl3QqVMnfPrppwAArVYLb29vTJkyBTNmzKhwH41Gg169emHcuHH4448/kJ2djV9++aVK58vNzYWjoyNycnIq7Bz9oDRagSYzNwMADs8egLp2SpMdm4iI6FFnzPW7yvPcuLu7Y9++fXjllVcQGRl5x5wuMoSEhCA2NtboxKa4uBiJiYmIjIzUr5PL5QgODkZCQkKl+82fPx9ubm548cUX7zv8vKioCEVFRfrlioaymwJvSxEREdUORk3i5+Pjg82bN+P69es4d+4chBBo1qwZnJ2dH+jkmZmZ0Gg05ZIid3d3nD59usJ99uzZg6+//hpJSUlVOkd0dDTmzZv3QPEZ487mL96VIiIiks4DPRXc2dkZnTp1QufOnR84sXkQeXl5eOGFF/Dll1/CxcWlSvtERkYiJydH/7p06VK1xGbQ54ZtN0RERJIx+vELpuTi4gKFQoH09HSD9enp6fDw8ChX/vz587hw4QKGDh2qX6fVagGUDUVPTk5GkyZNDPZRqVRQqVTVEL0hAYPshoiIiCTyQC03pqJUKhEYGIj4+Hj9Oq1Wi/j4eAQFBZUr36JFCxw/fhxJSUn617Bhw9C3b18kJSXB29u7JsOvFG9LERERSUfSlhsAiIiIwNixY9GxY0d07twZixYtQkFBAcLDwwEAY8aMgZeXF6Kjo2FtbY02bdoY7O/k5AQA5dbXNMGGGyIiolpB8uQmNDQUV69exZw5c5CWloaAgADExcXpOxmnpqZCLpe0gclonOeGiIhIOlWe58ZSVNc8NzeLNWg5Jw4A8Ne8ENipJM8biYiILIYx12/zahKpxQw6FBMREZFkmNyYiOHjF6SLg4iI6FHH5MZEDCbxY5diIiIiyTC5MRGDxy8wtyEiIpIMkxsTYY8bIiKi2oHJTTVgyw0REZF0mNyYCJ8tRUREVDswuTEVjpYiIiKqFZjcmMid89wwtyEiIpIOkxsTebTmeSYiIqq9mNyYiME8N7wvRUREJBkmNyZiMM+NhHEQERE96pjcmIhhy41kYRARET3ymNxUA96WIiIikg6TGxNhh2IiIqLagcmNieiGgrPRhoiISFpMbkzlVssNcxsiIiJpMbkxEd1dKfa3ISIikhaTGxMRbLkhIiKqFZjcmIgAexQTERHVBkxuTETfcsOmGyIiIkkxuTExGW9MERERSYrJjYnob0oxtyEiIpIUkxsT0T1birkNERGRtJjcmAj73BAREdUOTG5MjH1uiIiIpMXkxkTYckNERFQ7MLkxEf2zpSSOg4iI6FHH5MZE+FRwIiKi2oHJjYnx2VJERETSYnJjIvoHZ0oaBRERETG5MRHBJ2cSERHVCkxuTIQtN0RERLUDkxsTuT0UnOkNERGRlJjcmMytoeDMbYiIiCRVK5Kb2NhY+Pr6wtraGl26dMGBAwcqLbt+/Xp07NgRTk5OsLOzQ0BAAL799tsajLZi7HJDRERUO0ie3KxduxYRERGIiorC4cOH4e/vj5CQEGRkZFRYvm7dunj77beRkJCAY8eOITw8HOHh4di6dWsNR25I3+eGTTdERESSkjy5iYmJwYQJExAeHo5WrVph2bJlsLW1xfLlyyss36dPHzzxxBNo2bIlmjRpgtdeew3t2rXDnj17ajhyIiIiqo0kTW6Ki4uRmJiI4OBg/Tq5XI7g4GAkJCTcd38hBOLj45GcnIxevXpVWKaoqAi5ubkGr+rA21JERES1g6TJTWZmJjQaDdzd3Q3Wu7u7Iy0trdL9cnJyYG9vD6VSiSFDhmDJkiUYMGBAhWWjo6Ph6Oiof3l7e5v0M+gIdigmIiKqFSS/LfUgHBwckJSUhIMHD+Ldd99FREQEdu3aVWHZyMhI5OTk6F+XLl2qlphuP1uK2Q0REZGU6kh5chcXFygUCqSnpxusT09Ph4eHR6X7yeVyNG3aFAAQEBCAU6dOITo6Gn369ClXVqVSQaVSmTTuitye56baT0VERET3IGnLjVKpRGBgIOLj4/XrtFot4uPjERQUVOXjaLVaFBUVVUeIVaa/LSVpFERERCRpyw0AREREYOzYsejYsSM6d+6MRYsWoaCgAOHh4QCAMWPGwMvLC9HR0QDK+tB07NgRTZo0QVFRETZv3oxvv/0Wn332mZQfgy03REREtYTkyU1oaCiuXr2KOXPmIC0tDQEBAYiLi9N3Mk5NTYVcfruBqaCgABMnTsQ///wDGxsbtGjRAt999x1CQ0Ol+ggGZGy7ISIikpRMiNtdYR8Fubm5cHR0RE5ODtRqtcmOe/yfHAz9dA88Ha2RENnfZMclIiIi467fZjlaioiIiKgyTG5MhB2KiYiIagcmNyZyu0Mx0xsiIiIpMbkxkUeq4xIREVEtxuTGRHT9stlwQ0REJC0mNyaia7lhckNERCQtJjcmcvup4MxuiIiIpMTkxkTkMkBVRw5VHVYpERGRlCSfodhStG/ojOR3BkkdBhER0SOPzQxERERkUZjcEBERkUVhckNEREQWhckNERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BAREZFFYXJDREREFoXJDREREVkUJjdERERkUZjcEBERkUWpI3UANU0IAQDIzc2VOBIiIiKqKt11W3cdv5dHLrnJy8sDAHh7e0scCRERERkrLy8Pjo6O9ywjE1VJgSyIVqvFv//+CwcHB8hkMpMeOzc3F97e3rh06RLUarVJj20pWEdVw3q6P9bR/bGOqob1dH+1oY6EEMjLy0P9+vUhl9+7V80j13Ijl8vRoEGDaj2HWq3mL8h9sI6qhvV0f6yj+2MdVQ3r6f6krqP7tdjosEMxERERWRQmN0RERGRRmNyYkEqlQlRUFFQqldSh1Fqso6phPd0f6+j+WEdVw3q6P3Oro0euQzERERFZNrbcEBERkUVhckNEREQWhckNERERWRQmN0RERGRRmNyYSGxsLHx9fWFtbY0uXbrgwIEDUodUY+bOnQuZTGbwatGihX57YWEhJk2ahHr16sHe3h5PPfUU0tPTDY6RmpqKIUOGwNbWFm5ubnjjjTdQWlpa0x/FpHbv3o2hQ4eifv36kMlk+OWXXwy2CyEwZ84ceHp6wsbGBsHBwTh79qxBmaysLIwePRpqtRpOTk548cUXkZ+fb1Dm2LFj6NmzJ6ytreHt7Y0PPviguj+aydyvjsLCwsp9twYOHGhQxtLrKDo6Gp06dYKDgwPc3NwwYsQIJCcnG5Qx1e/Yrl270KFDB6hUKjRt2hQrV66s7o9nElWpoz59+pT7Lr388ssGZSy5jgDgs88+Q7t27fQT8QUFBWHLli367Rb1PRL00NasWSOUSqVYvny5+Ouvv8SECROEk5OTSE9Plzq0GhEVFSVat24trly5on9dvXpVv/3ll18W3t7eIj4+Xhw6dEh07dpVdOvWTb+9tLRUtGnTRgQHB4sjR46IzZs3CxcXFxEZGSnFxzGZzZs3i7ffflusX79eABA///yzwfb33ntPODo6il9++UUcPXpUDBs2TDRq1EjcvHlTX2bgwIHC399f7N+/X/zxxx+iadOm4tlnn9Vvz8nJEe7u7mL06NHixIkTYvXq1cLGxkZ8/vnnNfUxH8r96mjs2LFi4MCBBt+trKwsgzKWXkchISFixYoV4sSJEyIpKUkMHjxYNGzYUOTn5+vLmOJ37O+//xa2trYiIiJCnDx5UixZskQoFAoRFxdXo5/3QVSljnr37i0mTJhg8F3KycnRb7f0OhJCiI0bN4pNmzaJM2fOiOTkZDFz5kxhZWUlTpw4IYSwrO8RkxsT6Ny5s5g0aZJ+WaPRiPr164vo6GgJo6o5UVFRwt/fv8Jt2dnZwsrKSqxbt06/7tSpUwKASEhIEEKUXeDkcrlIS0vTl/nss8+EWq0WRUVF1Rp7Tbn7wq3VaoWHh4f48MMP9euys7OFSqUSq1evFkIIcfLkSQFAHDx4UF9my5YtQiaTicuXLwshhFi6dKlwdnY2qKe33npL+Pn5VfMnMr3Kkpvhw4dXus+jVkdCCJGRkSEAiN9//10IYbrfsTfffFO0bt3a4FyhoaEiJCSkuj+Syd1dR0KUJTevvfZapfs8anWk4+zsLL766iuL+x7xttRDKi4uRmJiIoKDg/Xr5HI5goODkZCQIGFkNevs2bOoX78+GjdujNGjRyM1NRUAkJiYiJKSEoP6adGiBRo2bKivn4SEBLRt2xbu7u76MiEhIcjNzcVff/1Vsx+khqSkpCAtLc2gXhwdHdGlSxeDenFyckLHjh31ZYKDgyGXy/Hnn3/qy/Tq1QtKpVJfJiQkBMnJybh+/XoNfZrqtWvXLri5ucHPzw+vvPIKrl27pt/2KNZRTk4OAKBu3boATPc7lpCQYHAMXRlz/Dt2dx3p/Pe//4WLiwvatGmDyMhI3LhxQ7/tUasjjUaDNWvWoKCgAEFBQRb3PXrkHpxpapmZmdBoNAY/bABwd3fH6dOnJYqqZnXp0gUrV66En58frly5gnnz5qFnz544ceIE0tLSoFQq4eTkZLCPu7s70tLSAABpaWkV1p9umyXSfa6KPved9eLm5mawvU6dOqhbt65BmUaNGpU7hm6bs7NztcRfUwYOHIgnn3wSjRo1wvnz5zFz5kwMGjQICQkJUCgUj1wdabVaTJ06Fd27d0ebNm0AwGS/Y5WVyc3Nxc2bN2FjY1MdH8nkKqojAHjuuefg4+OD+vXr49ixY3jrrbeQnJyM9evXA3h06uj48eMICgpCYWEh7O3t8fPPP6NVq1ZISkqyqO8Rkxt6aIMGDdK/b9euHbp06QIfHx/88MMPZvHLTrXXqFGj9O/btm2Ldu3aoUmTJti1axf69+8vYWTSmDRpEk6cOIE9e/ZIHUqtVVkdvfTSS/r3bdu2haenJ/r374/z58+jSZMmNR2mZPz8/JCUlIScnBz8+OOPGDt2LH7//XepwzI53pZ6SC4uLlAoFOV6lKenp8PDw0OiqKTl5OSE5s2b49y5c/Dw8EBxcTGys7MNytxZPx4eHhXWn26bJdJ9rnt9bzw8PJCRkWGwvbS0FFlZWY9s3TVu3BguLi44d+4cgEerjiZPnoxff/0VO3fuRIMGDfTrTfU7VlkZtVptNv9JqayOKtKlSxcAMPguPQp1pFQq0bRpUwQGBiI6Ohr+/v5YvHixxX2PmNw8JKVSicDAQMTHx+vXabVaxMfHIygoSMLIpJOfn4/z58/D09MTgYGBsLKyMqif5ORkpKam6usnKCgIx48fN7hIbd++HWq1Gq1atarx+GtCo0aN4OHhYVAvubm5+PPPPw3qJTs7G4mJifoyO3bsgFar1f9hDgoKwu7du1FSUqIvs337dvj5+ZnV7Zaq+ueff3Dt2jV4enoCeDTqSAiByZMn4+eff8aOHTvK3WIz1e9YUFCQwTF0Zczh79j96qgiSUlJAGDwXbLkOqqMVqtFUVGR5X2ParT7soVas2aNUKlUYuXKleLkyZPipZdeEk5OTgY9yi3ZtGnTxK5du0RKSorYu3evCA4OFi4uLiIjI0MIUTa8sGHDhmLHjh3i0KFDIigoSAQFBen31w0vfOyxx0RSUpKIi4sTrq6uZj8UPC8vTxw5ckQcOXJEABAxMTHiyJEj4uLFi0KIsqHgTk5OYsOGDeLYsWNi+PDhFQ4Fb9++vfjzzz/Fnj17RLNmzQyGOWdnZwt3d3fxwgsviBMnTog1a9YIW1tbsxnmfK86ysvLE9OnTxcJCQkiJSVF/Pbbb6JDhw6iWbNmorCwUH8MS6+jV155RTg6Oopdu3YZDGO+ceOGvowpfsd0Q3jfeOMNcerUKREbG2s2w5zvV0fnzp0T8+fPF4cOHRIpKSliw4YNonHjxqJXr176Y1h6HQkhxIwZM8Tvv/8uUlJSxLFjx8SMGTOETCYT27ZtE0JY1veIyY2JLFmyRDRs2FAolUrRuXNnsX//fqlDqjGhoaHC09NTKJVK4eXlJUJDQ8W5c+f022/evCkmTpwonJ2dha2trXjiiSfElStXDI5x4cIFMWjQIGFjYyNcXFzEtGnTRElJSU1/FJPauXOnAFDuNXbsWCFE2XDw2bNnC3d3d6FSqUT//v1FcnKywTGuXbsmnn32WWFvby/UarUIDw8XeXl5BmWOHj0qevToIVQqlfDy8hLvvfdeTX3Eh3avOrpx44Z47LHHhKurq7CyshI+Pj5iwoQJ5f7TYOl1VFH9ABArVqzQlzHV79jOnTtFQECAUCqVonHjxgbnqM3uV0epqamiV69eom7dukKlUommTZuKN954w2CeGyEsu46EEGLcuHHCx8dHKJVK4erqKvr3769PbISwrO+RTAghaq6diIiIiKh6sc8NERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BAREZFFYXJDRACACxcuQCaT6aelrw1Onz6Nrl27wtraGgEBAVKHQ0RmgskNUS0RFhYGmUyG9957z2D9L7/8AplMJlFU0oqKioKdnR2Sk5PLPa/mTmlpaZgyZQoaN24MlUoFb29vDB069J77PIrCwsIwYsQIqcMgqnZMbohqEWtra7z//vu4fv261KGYTHFx8QPve/78efTo0QM+Pj6oV69ehWUuXLiAwMBA7NixAx9++CGOHz+OuLg49O3bF5MmTXrgcxOR+WJyQ1SLBAcHw8PDA9HR0ZWWmTt3brlbNIsWLYKvr69+Wfc/9IULF8Ld3R1OTk6YP38+SktL8cYbb6Bu3bpo0KABVqxYUe74p0+fRrdu3WBtbY02bdrg999/N9h+4sQJDBo0CPb29nB3d8cLL7yAzMxM/fY+ffpg8uTJmDp1KlxcXBASElLh59BqtZg/fz4aNGgAlUqFgIAAxMXF6bfLZDIkJiZi/vz5kMlkmDt3boXHmThxImQyGQ4cOICnnnoKzZs3R+vWrREREYH9+/fry6WmpmL48OGwt7eHWq3GyJEjkZ6eXq5ely9fjoYNG8Le3h4TJ06ERqPBBx98AA8PD7i5ueHdd981OL9MJsNnn32GQYMGwcbGBo0bN8aPP/5oUOb48ePo168fbGxsUK9ePbz00kvIz88v9/P66KOP4OnpiXr16mHSpEkGTzIvKirC9OnT4eXlBTs7O3Tp0gW7du3Sb1+5ciWcnJywdetWtGzZEvb29hg4cCCuXLmi/3yrVq3Chg0bIJPJIJPJsGvXLhQXF2Py5Mnw9PSEtbU1fHx87vn9IzILNf40KyKq0NixY8Xw4cPF+vXrhbW1tbh06ZIQQoiff/5Z3PmrGhUVJfz9/Q32/fjjj4WPj4/BsRwcHMSkSZPE6dOnxddffy0AiJCQEPHuu++KM2fOiAULFggrKyv9eVJSUgQA0aBBA/Hjjz+KkydPivHjxwsHBweRmZkphBDi+vXr+qcAnzp1Shw+fFgMGDBA9O3bV3/u3r17C3t7e/HGG2+I06dPi9OnT1f4eWNiYoRarRarV68Wp0+fFm+++aawsrISZ86cEUIIceXKFdG6dWsxbdo0ceXKlXIPwxSi7KGZMplMLFy48J51q9FoREBAgOjRo4c4dOiQ2L9/vwgMDBS9e/c2qFd7e3vx9NNPi7/++kts3LhRKJVKERISIqZMmSJOnz4tli9fLgAYPBgXgKhXr5748ssvRXJyspg1a5ZQKBTi5MmTQggh8vPzhaenp3jyySfF8ePHRXx8vGjUqJH+Aaq6n5darRYvv/yyOHXqlPjf//4nbG1txRdffKEvM378eNGtWzexe/duce7cOfHhhx8KlUqlr68VK1YIKysrERwcLA4ePCgSExNFy5YtxXPPPSeEKHsC+8iRI8XAgQP1T80uKioSH374ofD29ha7d+8WFy5cEH/88Yf4/vvv71mfRLUdkxuiWkKX3AghRNeuXcW4ceOEEA+e3Pj4+AiNRqNf5+fnJ3r27KlfLi0tFXZ2dmL16tVCiNvJzZ1PzC4pKRENGjQQ77//vhBCiAULFojHHnvM4NyXLl0SAPRPNO/du7do3779fT9v/fr1xbvvvmuwrlOnTmLixIn6ZX9/fxEVFVXpMf78808BQKxfv/6e59q2bZtQKBQiNTVVv+6vv/4SAMSBAweEEGX1amtrK3Jzc/VlQkJChK+vb7l6jI6O1i8DEC+//LLB+bp06SJeeeUVIYQQX3zxhXB2dhb5+fn67Zs2bRJyuVz/hHPdz6u0tFRf5plnnhGhoaFCCCEuXrwoFAqFuHz5ssF5+vfvLyIjI4UQZckNAHHu3Dn99tjYWOHu7q5fvvM7pjNlyhTRr18/odVqK60/InPD21JEtdD777+PVatW4dSpUw98jNatW0Muv/0r7u7ujrZt2+qXFQoF6tWrh4yMDIP9goKC9O/r1KmDjh076uM4evQodu7cCXt7e/2rRYsWAMr6x+gEBgbeM7bc3Fz8+++/6N69u8H67t27G/WZhRBVKnfq1Cl4e3vD29tbv65Vq1ZwcnIyOJ+vry8cHBz0y+7u7mjVqlW5erxXnemWdcc9deoU/P39YWdnp9/evXt3aLVaJCcn69e1bt0aCoVCv+zp6ak/z/Hjx6HRaNC8eXODuv/9998N6t3W1hZNmjSp8BiVCQsLQ1JSEvz8/PDqq69i27Zt9yxPZA7qSB0AEZXXq1cvhISEIDIyEmFhYQbb5HJ5uYv6nX0zdKysrAyWZTJZheu0Wm2V48rPz8fQoUPx/vvvl9vm6empf3/nhbw6NWvWDDKZDKdPnzbJ8aqjzh7m3Lrz5OfnQ6FQIDEx0SABAgB7e/t7HuN+CWCHDh2QkpKCLVu24LfffsPIkSMRHBxcrt8QkTlhyw1RLfXee+/hf//7HxISEgzWu7q6Ii0tzeCiZcq5ae7shFtaWorExES0bNkSQNmF8K+//oKvry+aNm1q8DImoVGr1ahfvz727t1rsH7v3r1o1apVlY9Tt25dhISEIDY2FgUFBeW2Z2dnAwBatmyJS5cu4dKlS/ptJ0+eRHZ2tlHnq8yddaZb1tVZy5YtcfToUYP49u7dC7lcDj8/vyodv3379tBoNMjIyChX7x4eHlWOU6lUQqPRlFuvVqsRGhqKL7/8EmvXrsVPP/2ErKysKh+XqLZhckNUS7Vt2xajR4/GJ598YrC+T58+uHr1Kj744AOcP38esbGx2LJli8nOGxsbi59//hmnT5/GpEmTcP36dYwbNw4AMGnSJGRlZeHZZ5/FwYMHcf78eWzduhXh4eEVXjTv5Y033sD777+PtWvXIjk5GTNmzEBSUhJee+01o+PVaDTo3LkzfvrpJ5w9exanTp3CJ598or9dFBwcrK/Pw4cP48CBAxgzZgx69+6Njh07GnW+iqxbtw7Lly/HmTNnEBUVhQMHDmDy5MkAgNGjR8Pa2hpjx47FiRMnsHPnTkyZMgUvvPAC3N3dq3T85s2bY/To0RgzZgzWr1+PlJQUHDhwANHR0di0aVOV4/T19cWxY8eQnJyMzMxMlJSUICYmBqtXr8bp06dx5swZrFu3Dh4eHnBycnqQqiCqFZjcENVi8+fPL3cLpGXLlli6dCliY2Ph7++PAwcOYPr06SY753vvvYf33nsP/v7+2LNnDzZu3AgXFxcA0Le2aDQaPPbYY2jbti2mTp0KJycng34pVfHqq68iIiIC06ZNQ9u2bREXF4eNGzeiWbNmRh2ncePGOHz4MPr27Ytp06ahTZs2GDBgAOLj4/HZZ58BKLs9s2HDBjg7O6NXr14IDg5G48aNsXbtWqPOVZl58+ZhzZo1aNeuHb755husXr1a3yJka2uLrVu3IisrC506dcLTTz+N/v3749NPPzXqHCtWrMCYMWMwbdo0+Pn5YcSIETh48CAaNmxY5WNMmDABfn5+6NixI1xdXbF37144ODjggw8+QMeOHdGpUydcuHABmzdvNvrnSVSbyERVe+QREVE5MpkMP//8M2f+JapFmJoTERGRRWFyQ0RERBaFQ8GJiB4C7+wT1T5suSEiIiKLwuSGiIiILAqTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii/L/HUmMRdxDnuIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components for 99% explained variance: 613\n",
            "Number of components for 95% explained variance: 209\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Initialize PCA with desired number of components\n",
        "n_components = 3072\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Apply PCA to scaled data\n",
        "Xtrain_pca = pca.fit_transform(Xtrain_scaled)\n",
        "Xtest_pca = pca.transform(Xtest_scaled)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance Ratios:\", explained_variance)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cum_explained_variance = np.cumsum(explained_variance)\n",
        "plt.plot(cum_explained_variance)\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.title(\"Variance Explained vs. Number of Components\")\n",
        "plt.show()\n",
        "\n",
        "index_99_percent = np.argmax(cum_explained_variance >= 0.99) #Explained Variance Calculations (VALUES CHANGE ON EACH REFRESH SLIGHTLY!)\n",
        "index_95_percent = np.argmax(cum_explained_variance >= 0.95)\n",
        "\n",
        "# Print the number of components for 99% and 95% explained variance\n",
        "print(f\"Number of components for 99% explained variance: {index_99_percent}\")\n",
        "print(f\"Number of components for 95% explained variance: {index_95_percent}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWNAMSpjgJrN"
      },
      "source": [
        "***SET PCA TO DESIRED COMPONENTS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgP97ynMgJYY"
      },
      "outputs": [],
      "source": [
        "n_components = 209 #CHOOSEN FROM EXPLAINED VARIANCE 95%\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Apply PCA to scaled data\n",
        "Xtrain_pca = pca.fit_transform(Xtrain_scaled)\n",
        "Xtest_pca = pca.transform(Xtest_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PaztiSceW52"
      },
      "source": [
        "***TRAINED THE MLP *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwjyztEleVdS",
        "outputId": "afdf7655-2b96-4115-a918-f6875623ec6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 3.59468874\n",
            "Iteration 2, loss = 2.25943474\n",
            "Iteration 3, loss = 1.91739232\n",
            "Iteration 4, loss = 1.68428926\n",
            "Iteration 5, loss = 1.49058922\n",
            "Iteration 6, loss = 1.32129674\n",
            "Iteration 7, loss = 1.18259209\n",
            "Iteration 8, loss = 1.04628036\n",
            "Iteration 9, loss = 0.92614217\n",
            "Iteration 10, loss = 0.81560194\n",
            "Training Accuracy: 0.8556\n",
            "Validation Accuracy: 0.2628\n",
            "Classification Report from test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.50      0.51       251\n",
            "           1       0.51      0.50      0.51       244\n",
            "           2       0.36      0.35      0.35       258\n",
            "           3       0.29      0.22      0.25       254\n",
            "           4       0.38      0.33      0.35       250\n",
            "           5       0.30      0.32      0.31       234\n",
            "           6       0.42      0.48      0.45       258\n",
            "           7       0.48      0.49      0.49       250\n",
            "           8       0.52      0.59      0.55       256\n",
            "           9       0.50      0.51      0.51       245\n",
            "\n",
            "    accuracy                           0.43      2500\n",
            "   macro avg       0.43      0.43      0.43      2500\n",
            "weighted avg       0.43      0.43      0.43      2500\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[126  15  17   2   8   6   9   5  39  24]\n",
            " [ 14 123  10  13  10   5  14   4  22  29]\n",
            " [ 21   5  91  16  26  30  31  19  12   7]\n",
            " [ 11  10  12  57  13  61  40  28  12  10]\n",
            " [ 12   5  49  11  82  16  32  28   8   7]\n",
            " [  7  10  22  37  24  75  21  20  11   7]\n",
            " [  7   6  32  29  17  19 125   9   6   8]\n",
            " [ 11   9  12  13  24  20  13 123   9  16]\n",
            " [ 32  21   5   9   5  10   2   4 151  17]\n",
            " [  6  37   5   9   9   6  12  15  21 125]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "hidden_layer_sizes = 1050\n",
        "activation_fcn = 'relu'  # {identity, logistic, tanh, relu}, default='relu'\n",
        "max_iter = 10\n",
        "\n",
        "# model initialization\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(hidden_layer_sizes), activation=activation_fcn,\n",
        "                    max_iter=max_iter,\n",
        "                    solver='adam', verbose=1,\n",
        "                    random_state=None,\n",
        "                    tol=0.00001, n_iter_no_change=20)\n",
        "\n",
        "mlp.fit(Xtrain_pca, ytrain)\n",
        "\n",
        "# Evaluate performance on validation set\n",
        "validation_accuracy = mlp.score(Xtest_pca, ytest)\n",
        "\n",
        "# Evaluate performance on training set\n",
        "training_accuracy = mlp.score(Xtrain_pca, ytrain)\n",
        "#Evaluation of MLP\n",
        "ytrue = np.argmax(ytest, axis=1)\n",
        "\n",
        "#prediction prob\n",
        "ypreda = mlp.predict_proba(Xtest_pca)\n",
        "\n",
        "#prediction labels\n",
        "ypred = np.argmax(ypreda, axis=1)\n",
        "\n",
        "#classification report\n",
        "report = classification_report(ytrue, ypred)\n",
        "\n",
        "#confusion matrix\n",
        "mat = confusion_matrix(ytrue, ypred)\n",
        "\n",
        "print(f\"Training Accuracy: {training_accuracy}\")\n",
        "print(f\"Validation Accuracy: {validation_accuracy}\")\n",
        "print(\"Classification Report from test set:\")\n",
        "print(report)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWgIGYkt9i0H"
      },
      "source": [
        "**Testing different activation functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqMIW1y-9hP7",
        "outputId": "bbf60b1a-1dcf-4841-bd16-11b582242a60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation Function: relu\n",
            "Training Time: 19.93 seconds\n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 0.2888\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.50      0.49       251\n",
            "           1       0.50      0.44      0.47       244\n",
            "           2       0.38      0.38      0.38       258\n",
            "           3       0.29      0.30      0.30       254\n",
            "           4       0.38      0.38      0.38       250\n",
            "           5       0.32      0.31      0.32       234\n",
            "           6       0.47      0.50      0.49       258\n",
            "           7       0.53      0.50      0.51       250\n",
            "           8       0.57      0.61      0.59       256\n",
            "           9       0.48      0.49      0.48       245\n",
            "\n",
            "    accuracy                           0.44      2500\n",
            "   macro avg       0.44      0.44      0.44      2500\n",
            "weighted avg       0.44      0.44      0.44      2500\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation Function: tanh\n",
            "Training Time: 11.94 seconds\n",
            "Training Accuracy: 0.9994666666666666\n",
            "Validation Accuracy: 0.2052\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.44       251\n",
            "           1       0.48      0.45      0.46       244\n",
            "           2       0.29      0.28      0.28       258\n",
            "           3       0.21      0.18      0.19       254\n",
            "           4       0.30      0.37      0.33       250\n",
            "           5       0.30      0.23      0.26       234\n",
            "           6       0.38      0.49      0.43       258\n",
            "           7       0.44      0.40      0.42       250\n",
            "           8       0.47      0.57      0.51       256\n",
            "           9       0.46      0.42      0.44       245\n",
            "\n",
            "    accuracy                           0.38      2500\n",
            "   macro avg       0.38      0.38      0.38      2500\n",
            "weighted avg       0.38      0.38      0.38      2500\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation Function: logistic\n",
            "Training Time: 11.08 seconds\n",
            "Training Accuracy: 0.9062666666666667\n",
            "Validation Accuracy: 0.2188\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.45      0.44       251\n",
            "           1       0.54      0.49      0.51       244\n",
            "           2       0.37      0.39      0.38       258\n",
            "           3       0.30      0.24      0.27       254\n",
            "           4       0.40      0.37      0.39       250\n",
            "           5       0.34      0.28      0.31       234\n",
            "           6       0.42      0.55      0.48       258\n",
            "           7       0.48      0.45      0.46       250\n",
            "           8       0.44      0.56      0.49       256\n",
            "           9       0.51      0.47      0.49       245\n",
            "\n",
            "    accuracy                           0.43      2500\n",
            "   macro avg       0.42      0.43      0.42      2500\n",
            "weighted avg       0.42      0.43      0.42      2500\n",
            "\n",
            "Activation Function: identity\n",
            "Training Time: 3.82 seconds\n",
            "Training Accuracy: 0.18066666666666667\n",
            "Validation Accuracy: 0.132\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.37      0.40       251\n",
            "           1       0.39      0.38      0.39       244\n",
            "           2       0.28      0.22      0.25       258\n",
            "           3       0.21      0.14      0.17       254\n",
            "           4       0.32      0.30      0.31       250\n",
            "           5       0.26      0.34      0.29       234\n",
            "           6       0.37      0.41      0.39       258\n",
            "           7       0.40      0.42      0.41       250\n",
            "           8       0.40      0.48      0.44       256\n",
            "           9       0.41      0.50      0.45       245\n",
            "\n",
            "    accuracy                           0.36      2500\n",
            "   macro avg       0.35      0.36      0.35      2500\n",
            "weighted avg       0.35      0.36      0.35      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "activation_functions = ['relu', 'tanh', 'logistic','identity']\n",
        "\n",
        "for activation in activation_functions:\n",
        "    start_time = time.time()  # Record the start time\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(500,), activation=activation, max_iter=50, solver='adam', random_state=None)\n",
        "    mlp.fit(Xtrain_pca, ytrain)\n",
        "\n",
        "    end_time = time.time()  # Record the end time\n",
        "\n",
        "    # Calculate the training time\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    # Evaluate performance on validation set\n",
        "    validation_accuracy = mlp.score(Xtest_pca, ytest)\n",
        "\n",
        "    # Evaluate performance on training set\n",
        "    training_accuracy = mlp.score(Xtrain_pca, ytrain)\n",
        "\n",
        "    # Evaluation of MLP on test set\n",
        "    ytrue = np.argmax(ytest, axis=1)\n",
        "\n",
        "    # Prediction prob\n",
        "    ypreda = mlp.predict_proba(Xtest_pca)\n",
        "\n",
        "    # Prediction labels\n",
        "    ypred = np.argmax(ypreda, axis=1)\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(ytrue, ypred)\n",
        "\n",
        "    print(f\"Activation Function: {activation}\")\n",
        "    print(f\"Training Time: {training_time:.2f} seconds\")  # Print the training time\n",
        "    print(f\"Training Accuracy: {training_accuracy}\")\n",
        "    print(f\"Validation Accuracy: {validation_accuracy}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jblDSn6Ng4yh"
      },
      "source": [
        "***GRID SEARCH FOR MLP PARAMS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoS0Voi81G0t",
        "outputId": "4adac457-5d9e-4a77-a1b9-19d6979dfafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'activation': 'relu', 'hidden_layer_sizes': (1000,), 'max_iter': 100}\n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 0.292\n",
            "Classification Report from test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.49      0.49       251\n",
            "           1       0.56      0.52      0.54       244\n",
            "           2       0.38      0.41      0.40       258\n",
            "           3       0.30      0.31      0.31       254\n",
            "           4       0.41      0.40      0.41       250\n",
            "           5       0.37      0.29      0.33       234\n",
            "           6       0.49      0.54      0.52       258\n",
            "           7       0.53      0.52      0.52       250\n",
            "           8       0.57      0.63      0.60       256\n",
            "           9       0.49      0.48      0.48       245\n",
            "\n",
            "    accuracy                           0.46      2500\n",
            "   macro avg       0.46      0.46      0.46      2500\n",
            "weighted avg       0.46      0.46      0.46      2500\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[122  10  21  13   8   5   5  12  43  12]\n",
            " [ 11 126   6  10   9   2  14   9  17  40]\n",
            " [ 14   3 106  18  35  24  31  12   8   7]\n",
            " [ 12  10  21  80  15  40  31  18  11  16]\n",
            " [ 14   7  44  12 100  12  24  23   7   7]\n",
            " [  7  10  31  56  17  69  14  14   8   8]\n",
            " [ 10   8  18  26  18  12 140  14   5   7]\n",
            " [ 12   4  18  17  31  12  10 130   5  11]\n",
            " [ 27  13   4  18   4   3   5   4 162  16]\n",
            " [ 16  35   9  15   5  10  10  10  18 117]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(400,), (500,), (1000,)],\n",
        "    'activation': ['relu','logistic'],\n",
        "    'max_iter': [10, 50, 100]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(MLPClassifier(solver='adam', random_state=None, tol=0.00001, n_iter_no_change=20),\n",
        "                           param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(Xtrain_pca, ytrain)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "# Evaluate performance on validation set\n",
        "validation_accuracy = best_model.score(Xtest_pca, ytest)\n",
        "\n",
        "# Evaluate performance on training set\n",
        "training_accuracy = best_model.score(Xtrain_pca, ytrain)\n",
        "\n",
        "# Evaluation of MLP on test set\n",
        "ytrue = np.argmax(ytest, axis=1)\n",
        "\n",
        "# Prediction prob\n",
        "ypreda = best_model.predict_proba(Xtest_pca)\n",
        "\n",
        "# Prediction labels\n",
        "ypred = np.argmax(ypreda, axis=1)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(ytrue, ypred)\n",
        "\n",
        "# Confusion matrix\n",
        "mat = confusion_matrix(ytrue, ypred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Training Accuracy: {training_accuracy}\")\n",
        "print(f\"Validation Accuracy: {validation_accuracy}\")\n",
        "print(\"Classification Report from test set:\")\n",
        "print(report)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(mat)\n",
        "\n",
        "# Evaluate best model on test set\n",
        "test_accuracy = best_model.score(Xtest_pca, ytest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3wjtGJkhJ73"
      },
      "source": [
        "**Initializing and train SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q0uQd9ohQmY",
        "outputId": "034e6edf-6ec5-4ebc-f35e-18bacb59de1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibSVM]SVM Test Set Accuracy: 0.4664\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "ytrain_labels = np.argmax(ytrain, axis=1)\n",
        "ytest_labels = np.argmax(ytest, axis=1)\n",
        "\n",
        "# Initialize SVM\n",
        "svm = SVC(kernel='rbf', C=10.0, gamma='scale', verbose=True, random_state=None)\n",
        "\n",
        "# Train the SVM\n",
        "svm.fit(Xtrain_pca, ytrain_labels)\n",
        "\n",
        "svm_test_accuracy = svm.score(Xtest_pca, ytest_labels)\n",
        "print(f\"SVM Test Set Accuracy: {svm_test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWMdZKdkKgh"
      },
      "source": [
        "**CROSS VALIDATION FOR SVM USING GRID SEARCH(prints each params score)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlWaCwVA4Am5"
      },
      "source": [
        "The SVM uses Grid Search in a way that prints the results fro each parameter set tested vis nested forloop printing the best overall param settings at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1CtlIi4-t6O",
        "outputId": "b9a6e1fd-e4a8-411a-c876-a3f0b768cae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Parameters: C=10000, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=1000, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=100, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=10, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=1, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=0.1, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=0.01, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=0.001, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=0.0001, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Current Parameters: C=1e-05, kernel=rbf\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Parameters: C=10000, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 10000, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.4533333333333333\n",
            "SVM Test Set Accuracy: 0.4648\n",
            "Training Time: 87.14250779151917 seconds\n",
            "==============================\n",
            "Parameters: C=1000, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 1000, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.4533333333333333\n",
            "SVM Test Set Accuracy: 0.4648\n",
            "Training Time: 79.63117361068726 seconds\n",
            "==============================\n",
            "Parameters: C=100, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 100, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.4533333333333333\n",
            "SVM Test Set Accuracy: 0.4648\n",
            "Training Time: 78.25958800315857 seconds\n",
            "==============================\n",
            "Parameters: C=10, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.45813333333333334\n",
            "SVM Test Set Accuracy: 0.4664\n",
            "Training Time: 104.32818913459778 seconds\n",
            "==============================\n",
            "Parameters: C=1, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 1, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.4516\n",
            "SVM Test Set Accuracy: 0.45\n",
            "Training Time: 72.90481853485107 seconds\n",
            "==============================\n",
            "Parameters: C=0.1, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.36293333333333333\n",
            "SVM Test Set Accuracy: 0.3644\n",
            "Training Time: 68.10588097572327 seconds\n",
            "==============================\n",
            "Parameters: C=0.01, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 0.01, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.1628\n",
            "SVM Test Set Accuracy: 0.1876\n",
            "Training Time: 81.40959763526917 seconds\n",
            "==============================\n",
            "Parameters: C=0.001, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 0.001, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.1032\n",
            "SVM Test Set Accuracy: 0.1032\n",
            "Training Time: 83.95729851722717 seconds\n",
            "==============================\n",
            "Parameters: C=0.0001, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 0.0001, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.1032\n",
            "SVM Test Set Accuracy: 0.1032\n",
            "Training Time: 80.1717700958252 seconds\n",
            "==============================\n",
            "Parameters: C=1e-05, kernel=rbf\n",
            "Best SVM Hyperparameters: {'C': 1e-05, 'kernel': 'rbf'}\n",
            "Best SVM Cross-Validation Score: 0.1032\n",
            "SVM Test Set Accuracy: 0.1032\n",
            "Training Time: 82.86058449745178 seconds\n",
            "==============================\n",
            "\n",
            "Best Parameters:\n",
            "Best SVM Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n",
            "Best SVM Test Set Accuracy: 0.4664\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import time\n",
        "\n",
        "ytrain_labels = np.argmax(ytrain, axis=1)\n",
        "ytest_labels = np.argmax(ytest, axis=1)\n",
        "\n",
        "# Define the parameter grid for SVM\n",
        "svm_param_grid = {\n",
        "    'C': [10000, 1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with SVM classifier and parameter grid\n",
        "svm_grid_search = GridSearchCV(SVC(random_state=None), svm_param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Perform nested cross-validation for SVM\n",
        "for C in svm_param_grid['C']:\n",
        "    for kernel in svm_param_grid['kernel']:\n",
        "        print(f\"Current Parameters: C={C}, kernel={kernel}\")\n",
        "\n",
        "        # Update the parameter values\n",
        "        svm_grid_search.param_grid = {'C': [C], 'kernel': [kernel]}\n",
        "\n",
        "        # Record start time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Fit the model\n",
        "        svm_grid_search.fit(Xtrain_pca, ytrain_labels)\n",
        "\n",
        "        # Get the best SVM model\n",
        "        best_svm_model = svm_grid_search.best_estimator_\n",
        "\n",
        "        # Evaluate the best SVM model on the test set\n",
        "        best_svm_test_accuracy = best_svm_model.score(Xtest_pca, ytest_labels)\n",
        "\n",
        "        # Record end time\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'C': C,\n",
        "            'kernel': kernel,\n",
        "            'best_params': svm_grid_search.best_params_,\n",
        "            'cross_val_score': svm_grid_search.best_score_,\n",
        "            'test_accuracy': best_svm_test_accuracy,\n",
        "            'training_time': elapsed_time\n",
        "        })\n",
        "\n",
        "best_params = None\n",
        "best_accuracy = 0\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(f\"Parameters: C={result['C']}, kernel={result['kernel']}\")\n",
        "    print(f\"Best SVM Hyperparameters: {result['best_params']}\")\n",
        "    print(f\"Best SVM Cross-Validation Score: {result['cross_val_score']}\")\n",
        "    print(f\"SVM Test Set Accuracy: {result['test_accuracy']}\")\n",
        "    print(f\"Training Time: {result['training_time']} seconds\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # Update best parameters if needed\n",
        "    if result['test_accuracy'] > best_accuracy:\n",
        "        best_accuracy = result['test_accuracy']\n",
        "        best_params = result['best_params']\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"\\nBest Parameters:\")\n",
        "print(f\"Best SVM Hyperparameters: {best_params}\")\n",
        "print(f\"Best SVM Test Set Accuracy: {best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zReI0i1QZsfn"
      },
      "source": [
        "**10X10 Cross Validation MLP Model (Structured was used from last prac)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JthvB8kbZ0tB",
        "outputId": "addfdfb8-6d09-4d37-e089-896ee98792b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Outer Iteration 1 of 10\n",
            "***** cross_val_predict\n",
            "Iteration 1, loss = 2.01195790\n",
            "Iteration 2, loss = 1.71219437\n",
            "Iteration 3, loss = 1.61922513\n",
            "Iteration 4, loss = 1.56434171\n",
            "Iteration 5, loss = 1.52070616\n",
            "Iteration 6, loss = 1.48423793\n",
            "Iteration 7, loss = 1.45061422\n",
            "Iteration 8, loss = 1.42407242\n",
            "Iteration 9, loss = 1.38644210\n",
            "Iteration 10, loss = 1.35403016\n",
            "Iteration 11, loss = 1.31916276\n",
            "Iteration 12, loss = 1.28785376\n",
            "Iteration 13, loss = 1.25186898\n",
            "Iteration 14, loss = 1.21127233\n",
            "Iteration 15, loss = 1.17189349\n",
            "Iteration 16, loss = 1.13806542\n",
            "Iteration 17, loss = 1.09294577\n",
            "Iteration 18, loss = 1.05536279\n",
            "Iteration 19, loss = 1.01041478\n",
            "Iteration 20, loss = 0.96627229\n",
            "Iteration 21, loss = 0.92421850\n",
            "Iteration 22, loss = 0.88271154\n",
            "Iteration 23, loss = 0.83871333\n",
            "Iteration 24, loss = 0.79919868\n",
            "Iteration 25, loss = 0.75441507\n",
            "Iteration 26, loss = 0.71757594\n",
            "Iteration 27, loss = 0.68034274\n",
            "Iteration 28, loss = 0.63947409\n",
            "Iteration 29, loss = 0.60066514\n",
            "Iteration 30, loss = 0.56712009\n",
            "Iteration 31, loss = 0.52955425\n",
            "Iteration 32, loss = 0.49804406\n",
            "Iteration 33, loss = 0.46933660\n",
            "Iteration 34, loss = 0.43857736\n",
            "Iteration 35, loss = 0.41108174\n",
            "Iteration 36, loss = 0.38502631\n",
            "Iteration 37, loss = 0.36009978\n",
            "Iteration 38, loss = 0.33680986\n",
            "Iteration 39, loss = 0.31419838\n",
            "Iteration 40, loss = 0.29363435\n",
            "Iteration 41, loss = 0.27520999\n",
            "Iteration 42, loss = 0.25791176\n",
            "Iteration 43, loss = 0.24106375\n",
            "Iteration 44, loss = 0.22506508\n",
            "Iteration 45, loss = 0.21016034\n",
            "Iteration 46, loss = 0.19718286\n",
            "Iteration 47, loss = 0.18428277\n",
            "Iteration 48, loss = 0.17333316\n",
            "Iteration 49, loss = 0.16264208\n",
            "Iteration 50, loss = 0.15215049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01736807\n",
            "Iteration 2, loss = 1.71608758\n",
            "Iteration 3, loss = 1.62025273\n",
            "Iteration 4, loss = 1.56626975\n",
            "Iteration 5, loss = 1.52165812\n",
            "Iteration 6, loss = 1.49258202\n",
            "Iteration 7, loss = 1.45580726\n",
            "Iteration 8, loss = 1.42465779\n",
            "Iteration 9, loss = 1.39054089\n",
            "Iteration 10, loss = 1.36384691\n",
            "Iteration 11, loss = 1.32846663\n",
            "Iteration 12, loss = 1.29336499\n",
            "Iteration 13, loss = 1.25597276\n",
            "Iteration 14, loss = 1.22216387\n",
            "Iteration 15, loss = 1.18685374\n",
            "Iteration 16, loss = 1.14340191\n",
            "Iteration 17, loss = 1.10476533\n",
            "Iteration 18, loss = 1.06145321\n",
            "Iteration 19, loss = 1.02742732\n",
            "Iteration 20, loss = 0.98328909\n",
            "Iteration 21, loss = 0.93869234\n",
            "Iteration 22, loss = 0.89543389\n",
            "Iteration 23, loss = 0.85212828\n",
            "Iteration 24, loss = 0.81311305\n",
            "Iteration 25, loss = 0.77291265\n",
            "Iteration 26, loss = 0.73312492\n",
            "Iteration 27, loss = 0.69045222\n",
            "Iteration 28, loss = 0.65389566\n",
            "Iteration 29, loss = 0.61378342\n",
            "Iteration 30, loss = 0.57719905\n",
            "Iteration 31, loss = 0.54194658\n",
            "Iteration 32, loss = 0.50741106\n",
            "Iteration 33, loss = 0.47782852\n",
            "Iteration 34, loss = 0.44893829\n",
            "Iteration 35, loss = 0.41861790\n",
            "Iteration 36, loss = 0.39162324\n",
            "Iteration 37, loss = 0.36602785\n",
            "Iteration 38, loss = 0.34224093\n",
            "Iteration 39, loss = 0.32118844\n",
            "Iteration 40, loss = 0.29834480\n",
            "Iteration 41, loss = 0.27898091\n",
            "Iteration 42, loss = 0.26033824\n",
            "Iteration 43, loss = 0.24409665\n",
            "Iteration 44, loss = 0.22711560\n",
            "Iteration 45, loss = 0.21345926\n",
            "Iteration 46, loss = 0.19944555\n",
            "Iteration 47, loss = 0.18756160\n",
            "Iteration 48, loss = 0.17475859\n",
            "Iteration 49, loss = 0.16433057\n",
            "Iteration 50, loss = 0.15382668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01594461\n",
            "Iteration 2, loss = 1.71154793\n",
            "Iteration 3, loss = 1.61906475\n",
            "Iteration 4, loss = 1.56293077\n",
            "Iteration 5, loss = 1.51840959\n",
            "Iteration 6, loss = 1.48519977\n",
            "Iteration 7, loss = 1.45445288\n",
            "Iteration 8, loss = 1.41886632\n",
            "Iteration 9, loss = 1.38850196\n",
            "Iteration 10, loss = 1.35419158\n",
            "Iteration 11, loss = 1.32439683\n",
            "Iteration 12, loss = 1.29017529\n",
            "Iteration 13, loss = 1.25220953\n",
            "Iteration 14, loss = 1.21612289\n",
            "Iteration 15, loss = 1.17680114\n",
            "Iteration 16, loss = 1.14282553\n",
            "Iteration 17, loss = 1.09559234\n",
            "Iteration 18, loss = 1.05610188\n",
            "Iteration 19, loss = 1.01644929\n",
            "Iteration 20, loss = 0.97217930\n",
            "Iteration 21, loss = 0.93095564\n",
            "Iteration 22, loss = 0.88630182\n",
            "Iteration 23, loss = 0.84437721\n",
            "Iteration 24, loss = 0.80506591\n",
            "Iteration 25, loss = 0.75898141\n",
            "Iteration 26, loss = 0.72044651\n",
            "Iteration 27, loss = 0.68027124\n",
            "Iteration 28, loss = 0.64039505\n",
            "Iteration 29, loss = 0.60208377\n",
            "Iteration 30, loss = 0.56655128\n",
            "Iteration 31, loss = 0.53364529\n",
            "Iteration 32, loss = 0.49982149\n",
            "Iteration 33, loss = 0.46735829\n",
            "Iteration 34, loss = 0.43670818\n",
            "Iteration 35, loss = 0.40797095\n",
            "Iteration 36, loss = 0.38190945\n",
            "Iteration 37, loss = 0.35775096\n",
            "Iteration 38, loss = 0.33420202\n",
            "Iteration 39, loss = 0.31153711\n",
            "Iteration 40, loss = 0.28996780\n",
            "Iteration 41, loss = 0.27174457\n",
            "Iteration 42, loss = 0.25287595\n",
            "Iteration 43, loss = 0.23702776\n",
            "Iteration 44, loss = 0.22165651\n",
            "Iteration 45, loss = 0.20721232\n",
            "Iteration 46, loss = 0.19422404\n",
            "Iteration 47, loss = 0.18235451\n",
            "Iteration 48, loss = 0.17035386\n",
            "Iteration 49, loss = 0.15918014\n",
            "Iteration 50, loss = 0.14932765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03708748\n",
            "Iteration 2, loss = 1.72357618\n",
            "Iteration 3, loss = 1.62400295\n",
            "Iteration 4, loss = 1.57304514\n",
            "Iteration 5, loss = 1.53204973\n",
            "Iteration 6, loss = 1.49667169\n",
            "Iteration 7, loss = 1.46094310\n",
            "Iteration 8, loss = 1.42780513\n",
            "Iteration 9, loss = 1.39661346\n",
            "Iteration 10, loss = 1.36710258\n",
            "Iteration 11, loss = 1.33170265\n",
            "Iteration 12, loss = 1.29885551\n",
            "Iteration 13, loss = 1.26161253\n",
            "Iteration 14, loss = 1.22374851\n",
            "Iteration 15, loss = 1.18421762\n",
            "Iteration 16, loss = 1.14516902\n",
            "Iteration 17, loss = 1.10379489\n",
            "Iteration 18, loss = 1.06309229\n",
            "Iteration 19, loss = 1.02256229\n",
            "Iteration 20, loss = 0.97975133\n",
            "Iteration 21, loss = 0.93747337\n",
            "Iteration 22, loss = 0.89175743\n",
            "Iteration 23, loss = 0.84985090\n",
            "Iteration 24, loss = 0.80655291\n",
            "Iteration 25, loss = 0.76630749\n",
            "Iteration 26, loss = 0.72526266\n",
            "Iteration 27, loss = 0.68543677\n",
            "Iteration 28, loss = 0.64482051\n",
            "Iteration 29, loss = 0.60844372\n",
            "Iteration 30, loss = 0.57144246\n",
            "Iteration 31, loss = 0.53826356\n",
            "Iteration 32, loss = 0.50315967\n",
            "Iteration 33, loss = 0.47185477\n",
            "Iteration 34, loss = 0.44053430\n",
            "Iteration 35, loss = 0.41301700\n",
            "Iteration 36, loss = 0.38494440\n",
            "Iteration 37, loss = 0.36015777\n",
            "Iteration 38, loss = 0.33743012\n",
            "Iteration 39, loss = 0.31587885\n",
            "Iteration 40, loss = 0.29553384\n",
            "Iteration 41, loss = 0.27571025\n",
            "Iteration 42, loss = 0.25665597\n",
            "Iteration 43, loss = 0.24135761\n",
            "Iteration 44, loss = 0.22410371\n",
            "Iteration 45, loss = 0.21074582\n",
            "Iteration 46, loss = 0.19647639\n",
            "Iteration 47, loss = 0.18395509\n",
            "Iteration 48, loss = 0.17287907\n",
            "Iteration 49, loss = 0.16192936\n",
            "Iteration 50, loss = 0.15233083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00511058\n",
            "Iteration 2, loss = 1.71044222\n",
            "Iteration 3, loss = 1.61285231\n",
            "Iteration 4, loss = 1.56235137\n",
            "Iteration 5, loss = 1.51791355\n",
            "Iteration 6, loss = 1.48292910\n",
            "Iteration 7, loss = 1.44741380\n",
            "Iteration 8, loss = 1.41445898\n",
            "Iteration 9, loss = 1.38526906\n",
            "Iteration 10, loss = 1.35318590\n",
            "Iteration 11, loss = 1.32033923\n",
            "Iteration 12, loss = 1.28487894\n",
            "Iteration 13, loss = 1.25037179\n",
            "Iteration 14, loss = 1.21131965\n",
            "Iteration 15, loss = 1.17580588\n",
            "Iteration 16, loss = 1.13592984\n",
            "Iteration 17, loss = 1.09645800\n",
            "Iteration 18, loss = 1.05633928\n",
            "Iteration 19, loss = 1.01536540\n",
            "Iteration 20, loss = 0.97128226\n",
            "Iteration 21, loss = 0.92833943\n",
            "Iteration 22, loss = 0.88498448\n",
            "Iteration 23, loss = 0.84614522\n",
            "Iteration 24, loss = 0.80211548\n",
            "Iteration 25, loss = 0.75978800\n",
            "Iteration 26, loss = 0.72109474\n",
            "Iteration 27, loss = 0.68334391\n",
            "Iteration 28, loss = 0.64302351\n",
            "Iteration 29, loss = 0.60507870\n",
            "Iteration 30, loss = 0.56817628\n",
            "Iteration 31, loss = 0.53600716\n",
            "Iteration 32, loss = 0.50140778\n",
            "Iteration 33, loss = 0.47015963\n",
            "Iteration 34, loss = 0.43821061\n",
            "Iteration 35, loss = 0.41023123\n",
            "Iteration 36, loss = 0.38405221\n",
            "Iteration 37, loss = 0.35993527\n",
            "Iteration 38, loss = 0.33546907\n",
            "Iteration 39, loss = 0.31201612\n",
            "Iteration 40, loss = 0.29211497\n",
            "Iteration 41, loss = 0.27206290\n",
            "Iteration 42, loss = 0.25497338\n",
            "Iteration 43, loss = 0.23830695\n",
            "Iteration 44, loss = 0.22241592\n",
            "Iteration 45, loss = 0.20778910\n",
            "Iteration 46, loss = 0.19412913\n",
            "Iteration 47, loss = 0.18157452\n",
            "Iteration 48, loss = 0.17100521\n",
            "Iteration 49, loss = 0.15973205\n",
            "Iteration 50, loss = 0.14963308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02886855\n",
            "Iteration 2, loss = 1.72425863\n",
            "Iteration 3, loss = 1.62706267\n",
            "Iteration 4, loss = 1.56591861\n",
            "Iteration 5, loss = 1.52418208\n",
            "Iteration 6, loss = 1.49221445\n",
            "Iteration 7, loss = 1.45810467\n",
            "Iteration 8, loss = 1.42642586\n",
            "Iteration 9, loss = 1.39505517\n",
            "Iteration 10, loss = 1.36653257\n",
            "Iteration 11, loss = 1.33614546\n",
            "Iteration 12, loss = 1.29792622\n",
            "Iteration 13, loss = 1.26085833\n",
            "Iteration 14, loss = 1.22516579\n",
            "Iteration 15, loss = 1.18883317\n",
            "Iteration 16, loss = 1.15158748\n",
            "Iteration 17, loss = 1.10828192\n",
            "Iteration 18, loss = 1.06855183\n",
            "Iteration 19, loss = 1.02578324\n",
            "Iteration 20, loss = 0.98419341\n",
            "Iteration 21, loss = 0.94357185\n",
            "Iteration 22, loss = 0.90226375\n",
            "Iteration 23, loss = 0.85474472\n",
            "Iteration 24, loss = 0.81522305\n",
            "Iteration 25, loss = 0.77446037\n",
            "Iteration 26, loss = 0.73381744\n",
            "Iteration 27, loss = 0.69050043\n",
            "Iteration 28, loss = 0.65231353\n",
            "Iteration 29, loss = 0.61624010\n",
            "Iteration 30, loss = 0.57840192\n",
            "Iteration 31, loss = 0.54074423\n",
            "Iteration 32, loss = 0.51138151\n",
            "Iteration 33, loss = 0.47772291\n",
            "Iteration 34, loss = 0.44809798\n",
            "Iteration 35, loss = 0.41957071\n",
            "Iteration 36, loss = 0.39093610\n",
            "Iteration 37, loss = 0.36531782\n",
            "Iteration 38, loss = 0.34228696\n",
            "Iteration 39, loss = 0.31865254\n",
            "Iteration 40, loss = 0.29804988\n",
            "Iteration 41, loss = 0.27916993\n",
            "Iteration 42, loss = 0.26025558\n",
            "Iteration 43, loss = 0.24421532\n",
            "Iteration 44, loss = 0.22725205\n",
            "Iteration 45, loss = 0.21304397\n",
            "Iteration 46, loss = 0.19955777\n",
            "Iteration 47, loss = 0.18640161\n",
            "Iteration 48, loss = 0.17505014\n",
            "Iteration 49, loss = 0.16382690\n",
            "Iteration 50, loss = 0.15484014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01613664\n",
            "Iteration 2, loss = 1.71155093\n",
            "Iteration 3, loss = 1.61623803\n",
            "Iteration 4, loss = 1.56110836\n",
            "Iteration 5, loss = 1.52188606\n",
            "Iteration 6, loss = 1.48476045\n",
            "Iteration 7, loss = 1.45584511\n",
            "Iteration 8, loss = 1.41716852\n",
            "Iteration 9, loss = 1.39024526\n",
            "Iteration 10, loss = 1.35662903\n",
            "Iteration 11, loss = 1.32092558\n",
            "Iteration 12, loss = 1.29041265\n",
            "Iteration 13, loss = 1.25156585\n",
            "Iteration 14, loss = 1.21552987\n",
            "Iteration 15, loss = 1.17925531\n",
            "Iteration 16, loss = 1.14017826\n",
            "Iteration 17, loss = 1.10143795\n",
            "Iteration 18, loss = 1.05833205\n",
            "Iteration 19, loss = 1.01848154\n",
            "Iteration 20, loss = 0.97751965\n",
            "Iteration 21, loss = 0.93261757\n",
            "Iteration 22, loss = 0.89471584\n",
            "Iteration 23, loss = 0.84961505\n",
            "Iteration 24, loss = 0.80737900\n",
            "Iteration 25, loss = 0.76526329\n",
            "Iteration 26, loss = 0.72497217\n",
            "Iteration 27, loss = 0.68654372\n",
            "Iteration 28, loss = 0.64743715\n",
            "Iteration 29, loss = 0.61111546\n",
            "Iteration 30, loss = 0.57261841\n",
            "Iteration 31, loss = 0.54190321\n",
            "Iteration 32, loss = 0.50679702\n",
            "Iteration 33, loss = 0.47482570\n",
            "Iteration 34, loss = 0.44391111\n",
            "Iteration 35, loss = 0.41629171\n",
            "Iteration 36, loss = 0.38958359\n",
            "Iteration 37, loss = 0.36529056\n",
            "Iteration 38, loss = 0.34111648\n",
            "Iteration 39, loss = 0.31939584\n",
            "Iteration 40, loss = 0.29837140\n",
            "Iteration 41, loss = 0.27722585\n",
            "Iteration 42, loss = 0.25969196\n",
            "Iteration 43, loss = 0.24274814\n",
            "Iteration 44, loss = 0.22709661\n",
            "Iteration 45, loss = 0.21314375\n",
            "Iteration 46, loss = 0.19928799\n",
            "Iteration 47, loss = 0.18681002\n",
            "Iteration 48, loss = 0.17450597\n",
            "Iteration 49, loss = 0.16433440\n",
            "Iteration 50, loss = 0.15397193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01898201\n",
            "Iteration 2, loss = 1.72023333\n",
            "Iteration 3, loss = 1.62335117\n",
            "Iteration 4, loss = 1.56371261\n",
            "Iteration 5, loss = 1.52515084\n",
            "Iteration 6, loss = 1.49083261\n",
            "Iteration 7, loss = 1.46358019\n",
            "Iteration 8, loss = 1.42994636\n",
            "Iteration 9, loss = 1.39493467\n",
            "Iteration 10, loss = 1.36369329\n",
            "Iteration 11, loss = 1.32871136\n",
            "Iteration 12, loss = 1.29437453\n",
            "Iteration 13, loss = 1.25608547\n",
            "Iteration 14, loss = 1.21971777\n",
            "Iteration 15, loss = 1.18137062\n",
            "Iteration 16, loss = 1.14336325\n",
            "Iteration 17, loss = 1.10256022\n",
            "Iteration 18, loss = 1.06310749\n",
            "Iteration 19, loss = 1.01934082\n",
            "Iteration 20, loss = 0.98084566\n",
            "Iteration 21, loss = 0.93386140\n",
            "Iteration 22, loss = 0.89156436\n",
            "Iteration 23, loss = 0.84936367\n",
            "Iteration 24, loss = 0.80529457\n",
            "Iteration 25, loss = 0.76370812\n",
            "Iteration 26, loss = 0.72390481\n",
            "Iteration 27, loss = 0.68399313\n",
            "Iteration 28, loss = 0.64479739\n",
            "Iteration 29, loss = 0.60517758\n",
            "Iteration 30, loss = 0.57034042\n",
            "Iteration 31, loss = 0.53593752\n",
            "Iteration 32, loss = 0.50208515\n",
            "Iteration 33, loss = 0.47159759\n",
            "Iteration 34, loss = 0.44015547\n",
            "Iteration 35, loss = 0.41151634\n",
            "Iteration 36, loss = 0.38497847\n",
            "Iteration 37, loss = 0.36089958\n",
            "Iteration 38, loss = 0.33616793\n",
            "Iteration 39, loss = 0.31235101\n",
            "Iteration 40, loss = 0.29142341\n",
            "Iteration 41, loss = 0.27333068\n",
            "Iteration 42, loss = 0.25484793\n",
            "Iteration 43, loss = 0.23820273\n",
            "Iteration 44, loss = 0.22302318\n",
            "Iteration 45, loss = 0.20872282\n",
            "Iteration 46, loss = 0.19470817\n",
            "Iteration 47, loss = 0.18266676\n",
            "Iteration 48, loss = 0.17095284\n",
            "Iteration 49, loss = 0.16104269\n",
            "Iteration 50, loss = 0.15045528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02163742\n",
            "Iteration 2, loss = 1.72003644\n",
            "Iteration 3, loss = 1.62792540\n",
            "Iteration 4, loss = 1.56948073\n",
            "Iteration 5, loss = 1.52656614\n",
            "Iteration 6, loss = 1.48967567\n",
            "Iteration 7, loss = 1.45843362\n",
            "Iteration 8, loss = 1.42469497\n",
            "Iteration 9, loss = 1.39506670\n",
            "Iteration 10, loss = 1.36192390\n",
            "Iteration 11, loss = 1.32856161\n",
            "Iteration 12, loss = 1.29300862\n",
            "Iteration 13, loss = 1.25545223\n",
            "Iteration 14, loss = 1.21860588\n",
            "Iteration 15, loss = 1.17951827\n",
            "Iteration 16, loss = 1.14087100\n",
            "Iteration 17, loss = 1.10120939\n",
            "Iteration 18, loss = 1.05922419\n",
            "Iteration 19, loss = 1.01485289\n",
            "Iteration 20, loss = 0.97257393\n",
            "Iteration 21, loss = 0.92732591\n",
            "Iteration 22, loss = 0.88731101\n",
            "Iteration 23, loss = 0.84309385\n",
            "Iteration 24, loss = 0.79935108\n",
            "Iteration 25, loss = 0.75639859\n",
            "Iteration 26, loss = 0.71574440\n",
            "Iteration 27, loss = 0.67707211\n",
            "Iteration 28, loss = 0.63768417\n",
            "Iteration 29, loss = 0.60045607\n",
            "Iteration 30, loss = 0.56747048\n",
            "Iteration 31, loss = 0.53100234\n",
            "Iteration 32, loss = 0.49645079\n",
            "Iteration 33, loss = 0.46224975\n",
            "Iteration 34, loss = 0.43424275\n",
            "Iteration 35, loss = 0.40812821\n",
            "Iteration 36, loss = 0.37980970\n",
            "Iteration 37, loss = 0.35532014\n",
            "Iteration 38, loss = 0.33093816\n",
            "Iteration 39, loss = 0.30898746\n",
            "Iteration 40, loss = 0.28973171\n",
            "Iteration 41, loss = 0.26995574\n",
            "Iteration 42, loss = 0.25459008\n",
            "Iteration 43, loss = 0.23633754\n",
            "Iteration 44, loss = 0.22087023\n",
            "Iteration 45, loss = 0.20690110\n",
            "Iteration 46, loss = 0.19353771\n",
            "Iteration 47, loss = 0.18151388\n",
            "Iteration 48, loss = 0.16982069\n",
            "Iteration 49, loss = 0.15927142\n",
            "Iteration 50, loss = 0.14957300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02879548\n",
            "Iteration 2, loss = 1.71697624\n",
            "Iteration 3, loss = 1.61867520\n",
            "Iteration 4, loss = 1.56320113\n",
            "Iteration 5, loss = 1.51997914\n",
            "Iteration 6, loss = 1.48776349\n",
            "Iteration 7, loss = 1.45322089\n",
            "Iteration 8, loss = 1.41628699\n",
            "Iteration 9, loss = 1.38857403\n",
            "Iteration 10, loss = 1.35871193\n",
            "Iteration 11, loss = 1.31895721\n",
            "Iteration 12, loss = 1.29312084\n",
            "Iteration 13, loss = 1.25172329\n",
            "Iteration 14, loss = 1.21664144\n",
            "Iteration 15, loss = 1.17811529\n",
            "Iteration 16, loss = 1.14100905\n",
            "Iteration 17, loss = 1.09942528\n",
            "Iteration 18, loss = 1.05662709\n",
            "Iteration 19, loss = 1.01629516\n",
            "Iteration 20, loss = 0.97556192\n",
            "Iteration 21, loss = 0.93483386\n",
            "Iteration 22, loss = 0.89211383\n",
            "Iteration 23, loss = 0.84759128\n",
            "Iteration 24, loss = 0.80556378\n",
            "Iteration 25, loss = 0.76223058\n",
            "Iteration 26, loss = 0.72310807\n",
            "Iteration 27, loss = 0.68046573\n",
            "Iteration 28, loss = 0.64412801\n",
            "Iteration 29, loss = 0.60559037\n",
            "Iteration 30, loss = 0.56863215\n",
            "Iteration 31, loss = 0.53391963\n",
            "Iteration 32, loss = 0.50081114\n",
            "Iteration 33, loss = 0.46722468\n",
            "Iteration 34, loss = 0.43851293\n",
            "Iteration 35, loss = 0.41038961\n",
            "Iteration 36, loss = 0.38229253\n",
            "Iteration 37, loss = 0.35743319\n",
            "Iteration 38, loss = 0.33577243\n",
            "Iteration 39, loss = 0.31272333\n",
            "Iteration 40, loss = 0.29194879\n",
            "Iteration 41, loss = 0.27302198\n",
            "Iteration 42, loss = 0.25427208\n",
            "Iteration 43, loss = 0.23739558\n",
            "Iteration 44, loss = 0.22241543\n",
            "Iteration 45, loss = 0.20768892\n",
            "Iteration 46, loss = 0.19421684\n",
            "Iteration 47, loss = 0.18264804\n",
            "Iteration 48, loss = 0.17088562\n",
            "Iteration 49, loss = 0.15965123\n",
            "Iteration 50, loss = 0.14962080\n",
            "#### Outer Iteration 2 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02576401\n",
            "Iteration 2, loss = 1.71722196\n",
            "Iteration 3, loss = 1.61541619\n",
            "Iteration 4, loss = 1.55733605\n",
            "Iteration 5, loss = 1.51769001\n",
            "Iteration 6, loss = 1.48190327\n",
            "Iteration 7, loss = 1.45073754\n",
            "Iteration 8, loss = 1.41614267\n",
            "Iteration 9, loss = 1.38740958\n",
            "Iteration 10, loss = 1.35347857\n",
            "Iteration 11, loss = 1.32572604\n",
            "Iteration 12, loss = 1.28712056\n",
            "Iteration 13, loss = 1.24895780\n",
            "Iteration 14, loss = 1.21202937\n",
            "Iteration 15, loss = 1.17575783\n",
            "Iteration 16, loss = 1.13418438\n",
            "Iteration 17, loss = 1.09543215\n",
            "Iteration 18, loss = 1.05465126\n",
            "Iteration 19, loss = 1.01673417\n",
            "Iteration 20, loss = 0.97565770\n",
            "Iteration 21, loss = 0.92919952\n",
            "Iteration 22, loss = 0.88704577\n",
            "Iteration 23, loss = 0.84219792\n",
            "Iteration 24, loss = 0.80411865\n",
            "Iteration 25, loss = 0.76049496\n",
            "Iteration 26, loss = 0.72126137\n",
            "Iteration 27, loss = 0.68212127\n",
            "Iteration 28, loss = 0.64312649\n",
            "Iteration 29, loss = 0.60645992\n",
            "Iteration 30, loss = 0.56780058\n",
            "Iteration 31, loss = 0.53309625\n",
            "Iteration 32, loss = 0.50196281\n",
            "Iteration 33, loss = 0.47044797\n",
            "Iteration 34, loss = 0.43872181\n",
            "Iteration 35, loss = 0.41240358\n",
            "Iteration 36, loss = 0.38318159\n",
            "Iteration 37, loss = 0.35922359\n",
            "Iteration 38, loss = 0.33580528\n",
            "Iteration 39, loss = 0.31315913\n",
            "Iteration 40, loss = 0.29391343\n",
            "Iteration 41, loss = 0.27300412\n",
            "Iteration 42, loss = 0.25543532\n",
            "Iteration 43, loss = 0.23850355\n",
            "Iteration 44, loss = 0.22394932\n",
            "Iteration 45, loss = 0.20927030\n",
            "Iteration 46, loss = 0.19519394\n",
            "Iteration 47, loss = 0.18321315\n",
            "Iteration 48, loss = 0.17213051\n",
            "Iteration 49, loss = 0.16100856\n",
            "Iteration 50, loss = 0.15143503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00238959\n",
            "Iteration 2, loss = 1.71466664\n",
            "Iteration 3, loss = 1.61734512\n",
            "Iteration 4, loss = 1.55889211\n",
            "Iteration 5, loss = 1.52054015\n",
            "Iteration 6, loss = 1.48887495\n",
            "Iteration 7, loss = 1.45146351\n",
            "Iteration 8, loss = 1.41738098\n",
            "Iteration 9, loss = 1.38472983\n",
            "Iteration 10, loss = 1.35435302\n",
            "Iteration 11, loss = 1.32081705\n",
            "Iteration 12, loss = 1.28138976\n",
            "Iteration 13, loss = 1.24890710\n",
            "Iteration 14, loss = 1.20824409\n",
            "Iteration 15, loss = 1.17071801\n",
            "Iteration 16, loss = 1.13107479\n",
            "Iteration 17, loss = 1.08727086\n",
            "Iteration 18, loss = 1.04511130\n",
            "Iteration 19, loss = 1.00070509\n",
            "Iteration 20, loss = 0.96143811\n",
            "Iteration 21, loss = 0.91833920\n",
            "Iteration 22, loss = 0.87563907\n",
            "Iteration 23, loss = 0.83212592\n",
            "Iteration 24, loss = 0.79070912\n",
            "Iteration 25, loss = 0.74690324\n",
            "Iteration 26, loss = 0.70538557\n",
            "Iteration 27, loss = 0.66567525\n",
            "Iteration 28, loss = 0.62730912\n",
            "Iteration 29, loss = 0.59048744\n",
            "Iteration 30, loss = 0.55476338\n",
            "Iteration 31, loss = 0.51933520\n",
            "Iteration 32, loss = 0.48787018\n",
            "Iteration 33, loss = 0.45421316\n",
            "Iteration 34, loss = 0.42681162\n",
            "Iteration 35, loss = 0.39639599\n",
            "Iteration 36, loss = 0.37157463\n",
            "Iteration 37, loss = 0.34637310\n",
            "Iteration 38, loss = 0.32213993\n",
            "Iteration 39, loss = 0.30215842\n",
            "Iteration 40, loss = 0.28215618\n",
            "Iteration 41, loss = 0.26374450\n",
            "Iteration 42, loss = 0.24558711\n",
            "Iteration 43, loss = 0.22965622\n",
            "Iteration 44, loss = 0.21415986\n",
            "Iteration 45, loss = 0.20121266\n",
            "Iteration 46, loss = 0.18777310\n",
            "Iteration 47, loss = 0.17607440\n",
            "Iteration 48, loss = 0.16474724\n",
            "Iteration 49, loss = 0.15420662\n",
            "Iteration 50, loss = 0.14499972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01752642\n",
            "Iteration 2, loss = 1.71120995\n",
            "Iteration 3, loss = 1.61494338\n",
            "Iteration 4, loss = 1.55922752\n",
            "Iteration 5, loss = 1.51619525\n",
            "Iteration 6, loss = 1.47831457\n",
            "Iteration 7, loss = 1.45358873\n",
            "Iteration 8, loss = 1.41792560\n",
            "Iteration 9, loss = 1.38317736\n",
            "Iteration 10, loss = 1.35009596\n",
            "Iteration 11, loss = 1.31898833\n",
            "Iteration 12, loss = 1.28638776\n",
            "Iteration 13, loss = 1.24935200\n",
            "Iteration 14, loss = 1.20935999\n",
            "Iteration 15, loss = 1.17316758\n",
            "Iteration 16, loss = 1.13735370\n",
            "Iteration 17, loss = 1.09388781\n",
            "Iteration 18, loss = 1.05485522\n",
            "Iteration 19, loss = 1.00850168\n",
            "Iteration 20, loss = 0.96784173\n",
            "Iteration 21, loss = 0.92725031\n",
            "Iteration 22, loss = 0.88396730\n",
            "Iteration 23, loss = 0.83907950\n",
            "Iteration 24, loss = 0.79791179\n",
            "Iteration 25, loss = 0.75862276\n",
            "Iteration 26, loss = 0.71674200\n",
            "Iteration 27, loss = 0.67800531\n",
            "Iteration 28, loss = 0.63996836\n",
            "Iteration 29, loss = 0.60168360\n",
            "Iteration 30, loss = 0.56576405\n",
            "Iteration 31, loss = 0.53210723\n",
            "Iteration 32, loss = 0.49913070\n",
            "Iteration 33, loss = 0.46889679\n",
            "Iteration 34, loss = 0.43732853\n",
            "Iteration 35, loss = 0.40836634\n",
            "Iteration 36, loss = 0.38379623\n",
            "Iteration 37, loss = 0.35766517\n",
            "Iteration 38, loss = 0.33347000\n",
            "Iteration 39, loss = 0.31155518\n",
            "Iteration 40, loss = 0.29095829\n",
            "Iteration 41, loss = 0.27181813\n",
            "Iteration 42, loss = 0.25320528\n",
            "Iteration 43, loss = 0.23611415\n",
            "Iteration 44, loss = 0.22118644\n",
            "Iteration 45, loss = 0.20667729\n",
            "Iteration 46, loss = 0.19456467\n",
            "Iteration 47, loss = 0.18160336\n",
            "Iteration 48, loss = 0.16936941\n",
            "Iteration 49, loss = 0.15920691\n",
            "Iteration 50, loss = 0.14985975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00425868\n",
            "Iteration 2, loss = 1.70862124\n",
            "Iteration 3, loss = 1.61963125\n",
            "Iteration 4, loss = 1.56120103\n",
            "Iteration 5, loss = 1.51731118\n",
            "Iteration 6, loss = 1.48573658\n",
            "Iteration 7, loss = 1.45090568\n",
            "Iteration 8, loss = 1.41898704\n",
            "Iteration 9, loss = 1.38159158\n",
            "Iteration 10, loss = 1.35321447\n",
            "Iteration 11, loss = 1.31487869\n",
            "Iteration 12, loss = 1.28295113\n",
            "Iteration 13, loss = 1.24526480\n",
            "Iteration 14, loss = 1.20876070\n",
            "Iteration 15, loss = 1.17221207\n",
            "Iteration 16, loss = 1.13219377\n",
            "Iteration 17, loss = 1.08997316\n",
            "Iteration 18, loss = 1.05012219\n",
            "Iteration 19, loss = 1.00591441\n",
            "Iteration 20, loss = 0.96671077\n",
            "Iteration 21, loss = 0.92350151\n",
            "Iteration 22, loss = 0.87692627\n",
            "Iteration 23, loss = 0.83439315\n",
            "Iteration 24, loss = 0.79315820\n",
            "Iteration 25, loss = 0.74836345\n",
            "Iteration 26, loss = 0.71358213\n",
            "Iteration 27, loss = 0.67425607\n",
            "Iteration 28, loss = 0.63271413\n",
            "Iteration 29, loss = 0.59530278\n",
            "Iteration 30, loss = 0.55841997\n",
            "Iteration 31, loss = 0.52455609\n",
            "Iteration 32, loss = 0.49078519\n",
            "Iteration 33, loss = 0.45962083\n",
            "Iteration 34, loss = 0.43003675\n",
            "Iteration 35, loss = 0.40289179\n",
            "Iteration 36, loss = 0.37578690\n",
            "Iteration 37, loss = 0.35035443\n",
            "Iteration 38, loss = 0.32809527\n",
            "Iteration 39, loss = 0.30715118\n",
            "Iteration 40, loss = 0.28613158\n",
            "Iteration 41, loss = 0.26656051\n",
            "Iteration 42, loss = 0.24872984\n",
            "Iteration 43, loss = 0.23139093\n",
            "Iteration 44, loss = 0.21659749\n",
            "Iteration 45, loss = 0.20324519\n",
            "Iteration 46, loss = 0.19008438\n",
            "Iteration 47, loss = 0.17814404\n",
            "Iteration 48, loss = 0.16659367\n",
            "Iteration 49, loss = 0.15663827\n",
            "Iteration 50, loss = 0.14629923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01508867\n",
            "Iteration 2, loss = 1.71688664\n",
            "Iteration 3, loss = 1.62340685\n",
            "Iteration 4, loss = 1.56107499\n",
            "Iteration 5, loss = 1.52308903\n",
            "Iteration 6, loss = 1.48500485\n",
            "Iteration 7, loss = 1.45603695\n",
            "Iteration 8, loss = 1.42392709\n",
            "Iteration 9, loss = 1.38880172\n",
            "Iteration 10, loss = 1.35751909\n",
            "Iteration 11, loss = 1.31815695\n",
            "Iteration 12, loss = 1.28765681\n",
            "Iteration 13, loss = 1.25136132\n",
            "Iteration 14, loss = 1.21151155\n",
            "Iteration 15, loss = 1.17945783\n",
            "Iteration 16, loss = 1.13373748\n",
            "Iteration 17, loss = 1.09463806\n",
            "Iteration 18, loss = 1.05342216\n",
            "Iteration 19, loss = 1.00962327\n",
            "Iteration 20, loss = 0.96677531\n",
            "Iteration 21, loss = 0.92274057\n",
            "Iteration 22, loss = 0.88114749\n",
            "Iteration 23, loss = 0.84056184\n",
            "Iteration 24, loss = 0.79927582\n",
            "Iteration 25, loss = 0.75551819\n",
            "Iteration 26, loss = 0.71257908\n",
            "Iteration 27, loss = 0.67318767\n",
            "Iteration 28, loss = 0.63231257\n",
            "Iteration 29, loss = 0.59651976\n",
            "Iteration 30, loss = 0.56192923\n",
            "Iteration 31, loss = 0.52712575\n",
            "Iteration 32, loss = 0.49480734\n",
            "Iteration 33, loss = 0.46123071\n",
            "Iteration 34, loss = 0.43320213\n",
            "Iteration 35, loss = 0.40405350\n",
            "Iteration 36, loss = 0.37846972\n",
            "Iteration 37, loss = 0.35245717\n",
            "Iteration 38, loss = 0.33092475\n",
            "Iteration 39, loss = 0.30870387\n",
            "Iteration 40, loss = 0.28848664\n",
            "Iteration 41, loss = 0.26906055\n",
            "Iteration 42, loss = 0.25219985\n",
            "Iteration 43, loss = 0.23424503\n",
            "Iteration 44, loss = 0.21950525\n",
            "Iteration 45, loss = 0.20618925\n",
            "Iteration 46, loss = 0.19224549\n",
            "Iteration 47, loss = 0.18027089\n",
            "Iteration 48, loss = 0.16876600\n",
            "Iteration 49, loss = 0.15876723\n",
            "Iteration 50, loss = 0.14910756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00920371\n",
            "Iteration 2, loss = 1.71015152\n",
            "Iteration 3, loss = 1.61687002\n",
            "Iteration 4, loss = 1.56115356\n",
            "Iteration 5, loss = 1.51651009\n",
            "Iteration 6, loss = 1.48896640\n",
            "Iteration 7, loss = 1.45161949\n",
            "Iteration 8, loss = 1.42025218\n",
            "Iteration 9, loss = 1.38644758\n",
            "Iteration 10, loss = 1.35229419\n",
            "Iteration 11, loss = 1.32070429\n",
            "Iteration 12, loss = 1.28562165\n",
            "Iteration 13, loss = 1.24965799\n",
            "Iteration 14, loss = 1.21116274\n",
            "Iteration 15, loss = 1.17086996\n",
            "Iteration 16, loss = 1.13447085\n",
            "Iteration 17, loss = 1.09364125\n",
            "Iteration 18, loss = 1.05232884\n",
            "Iteration 19, loss = 1.01055890\n",
            "Iteration 20, loss = 0.96565395\n",
            "Iteration 21, loss = 0.92511417\n",
            "Iteration 22, loss = 0.88191525\n",
            "Iteration 23, loss = 0.84291995\n",
            "Iteration 24, loss = 0.79964752\n",
            "Iteration 25, loss = 0.75622438\n",
            "Iteration 26, loss = 0.71980258\n",
            "Iteration 27, loss = 0.67883584\n",
            "Iteration 28, loss = 0.63904100\n",
            "Iteration 29, loss = 0.60320016\n",
            "Iteration 30, loss = 0.56656103\n",
            "Iteration 31, loss = 0.53225943\n",
            "Iteration 32, loss = 0.49874140\n",
            "Iteration 33, loss = 0.46653819\n",
            "Iteration 34, loss = 0.43961576\n",
            "Iteration 35, loss = 0.41033992\n",
            "Iteration 36, loss = 0.38406274\n",
            "Iteration 37, loss = 0.35831508\n",
            "Iteration 38, loss = 0.33613426\n",
            "Iteration 39, loss = 0.31303926\n",
            "Iteration 40, loss = 0.29274969\n",
            "Iteration 41, loss = 0.27305017\n",
            "Iteration 42, loss = 0.25593847\n",
            "Iteration 43, loss = 0.23921420\n",
            "Iteration 44, loss = 0.22279488\n",
            "Iteration 45, loss = 0.20846175\n",
            "Iteration 46, loss = 0.19541885\n",
            "Iteration 47, loss = 0.18316796\n",
            "Iteration 48, loss = 0.17136607\n",
            "Iteration 49, loss = 0.16077867\n",
            "Iteration 50, loss = 0.15123163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01399142\n",
            "Iteration 2, loss = 1.71760144\n",
            "Iteration 3, loss = 1.61910065\n",
            "Iteration 4, loss = 1.56047062\n",
            "Iteration 5, loss = 1.52092777\n",
            "Iteration 6, loss = 1.48963489\n",
            "Iteration 7, loss = 1.45540090\n",
            "Iteration 8, loss = 1.42373818\n",
            "Iteration 9, loss = 1.39691266\n",
            "Iteration 10, loss = 1.36189914\n",
            "Iteration 11, loss = 1.32924141\n",
            "Iteration 12, loss = 1.29137381\n",
            "Iteration 13, loss = 1.25884555\n",
            "Iteration 14, loss = 1.22160257\n",
            "Iteration 15, loss = 1.18521344\n",
            "Iteration 16, loss = 1.14426326\n",
            "Iteration 17, loss = 1.10691997\n",
            "Iteration 18, loss = 1.06424103\n",
            "Iteration 19, loss = 1.02257035\n",
            "Iteration 20, loss = 0.97778215\n",
            "Iteration 21, loss = 0.93759851\n",
            "Iteration 22, loss = 0.89555307\n",
            "Iteration 23, loss = 0.85164657\n",
            "Iteration 24, loss = 0.80704677\n",
            "Iteration 25, loss = 0.76737894\n",
            "Iteration 26, loss = 0.72508063\n",
            "Iteration 27, loss = 0.68616791\n",
            "Iteration 28, loss = 0.64676573\n",
            "Iteration 29, loss = 0.60902167\n",
            "Iteration 30, loss = 0.57463088\n",
            "Iteration 31, loss = 0.53776248\n",
            "Iteration 32, loss = 0.50470742\n",
            "Iteration 33, loss = 0.47289040\n",
            "Iteration 34, loss = 0.44237466\n",
            "Iteration 35, loss = 0.41338463\n",
            "Iteration 36, loss = 0.38954138\n",
            "Iteration 37, loss = 0.36270467\n",
            "Iteration 38, loss = 0.33831195\n",
            "Iteration 39, loss = 0.31620486\n",
            "Iteration 40, loss = 0.29519417\n",
            "Iteration 41, loss = 0.27591988\n",
            "Iteration 42, loss = 0.25771554\n",
            "Iteration 43, loss = 0.24127377\n",
            "Iteration 44, loss = 0.22558053\n",
            "Iteration 45, loss = 0.21080861\n",
            "Iteration 46, loss = 0.19729998\n",
            "Iteration 47, loss = 0.18559240\n",
            "Iteration 48, loss = 0.17284568\n",
            "Iteration 49, loss = 0.16312321\n",
            "Iteration 50, loss = 0.15257496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02249889\n",
            "Iteration 2, loss = 1.71498443\n",
            "Iteration 3, loss = 1.61682675\n",
            "Iteration 4, loss = 1.56536419\n",
            "Iteration 5, loss = 1.52197110\n",
            "Iteration 6, loss = 1.48662680\n",
            "Iteration 7, loss = 1.45492812\n",
            "Iteration 8, loss = 1.42169048\n",
            "Iteration 9, loss = 1.39203954\n",
            "Iteration 10, loss = 1.35900155\n",
            "Iteration 11, loss = 1.32611893\n",
            "Iteration 12, loss = 1.28849821\n",
            "Iteration 13, loss = 1.25366058\n",
            "Iteration 14, loss = 1.21728512\n",
            "Iteration 15, loss = 1.17584724\n",
            "Iteration 16, loss = 1.13952011\n",
            "Iteration 17, loss = 1.09865349\n",
            "Iteration 18, loss = 1.05921655\n",
            "Iteration 19, loss = 1.01523878\n",
            "Iteration 20, loss = 0.96969980\n",
            "Iteration 21, loss = 0.92723127\n",
            "Iteration 22, loss = 0.88568120\n",
            "Iteration 23, loss = 0.84494753\n",
            "Iteration 24, loss = 0.80156894\n",
            "Iteration 25, loss = 0.76137418\n",
            "Iteration 26, loss = 0.71918073\n",
            "Iteration 27, loss = 0.67917333\n",
            "Iteration 28, loss = 0.64080609\n",
            "Iteration 29, loss = 0.60484762\n",
            "Iteration 30, loss = 0.56741390\n",
            "Iteration 31, loss = 0.53283370\n",
            "Iteration 32, loss = 0.50102589\n",
            "Iteration 33, loss = 0.46864982\n",
            "Iteration 34, loss = 0.43868638\n",
            "Iteration 35, loss = 0.41104341\n",
            "Iteration 36, loss = 0.38476648\n",
            "Iteration 37, loss = 0.36033674\n",
            "Iteration 38, loss = 0.33712080\n",
            "Iteration 39, loss = 0.31406118\n",
            "Iteration 40, loss = 0.29324639\n",
            "Iteration 41, loss = 0.27428215\n",
            "Iteration 42, loss = 0.25585047\n",
            "Iteration 43, loss = 0.23889456\n",
            "Iteration 44, loss = 0.22366030\n",
            "Iteration 45, loss = 0.20904547\n",
            "Iteration 46, loss = 0.19648985\n",
            "Iteration 47, loss = 0.18400900\n",
            "Iteration 48, loss = 0.17252187\n",
            "Iteration 49, loss = 0.16199933\n",
            "Iteration 50, loss = 0.15151138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01861051\n",
            "Iteration 2, loss = 1.72334731\n",
            "Iteration 3, loss = 1.61937769\n",
            "Iteration 4, loss = 1.56408870\n",
            "Iteration 5, loss = 1.52448956\n",
            "Iteration 6, loss = 1.49144989\n",
            "Iteration 7, loss = 1.45465677\n",
            "Iteration 8, loss = 1.42176905\n",
            "Iteration 9, loss = 1.39305488\n",
            "Iteration 10, loss = 1.36288807\n",
            "Iteration 11, loss = 1.32187329\n",
            "Iteration 12, loss = 1.28787439\n",
            "Iteration 13, loss = 1.25476646\n",
            "Iteration 14, loss = 1.21780703\n",
            "Iteration 15, loss = 1.17840700\n",
            "Iteration 16, loss = 1.13849219\n",
            "Iteration 17, loss = 1.10080366\n",
            "Iteration 18, loss = 1.05597153\n",
            "Iteration 19, loss = 1.01438656\n",
            "Iteration 20, loss = 0.97181689\n",
            "Iteration 21, loss = 0.93106706\n",
            "Iteration 22, loss = 0.88796561\n",
            "Iteration 23, loss = 0.84522091\n",
            "Iteration 24, loss = 0.80405954\n",
            "Iteration 25, loss = 0.75957010\n",
            "Iteration 26, loss = 0.71977544\n",
            "Iteration 27, loss = 0.68094223\n",
            "Iteration 28, loss = 0.64116819\n",
            "Iteration 29, loss = 0.60275164\n",
            "Iteration 30, loss = 0.56638822\n",
            "Iteration 31, loss = 0.53116011\n",
            "Iteration 32, loss = 0.49786708\n",
            "Iteration 33, loss = 0.46646030\n",
            "Iteration 34, loss = 0.43597666\n",
            "Iteration 35, loss = 0.40814357\n",
            "Iteration 36, loss = 0.38160656\n",
            "Iteration 37, loss = 0.35546906\n",
            "Iteration 38, loss = 0.33274978\n",
            "Iteration 39, loss = 0.31050951\n",
            "Iteration 40, loss = 0.28887033\n",
            "Iteration 41, loss = 0.26991181\n",
            "Iteration 42, loss = 0.25238086\n",
            "Iteration 43, loss = 0.23638974\n",
            "Iteration 44, loss = 0.22028710\n",
            "Iteration 45, loss = 0.20531602\n",
            "Iteration 46, loss = 0.19286298\n",
            "Iteration 47, loss = 0.18057850\n",
            "Iteration 48, loss = 0.16897692\n",
            "Iteration 49, loss = 0.15814736\n",
            "Iteration 50, loss = 0.14814050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03261044\n",
            "Iteration 2, loss = 1.72089488\n",
            "Iteration 3, loss = 1.62553642\n",
            "Iteration 4, loss = 1.57023218\n",
            "Iteration 5, loss = 1.52891038\n",
            "Iteration 6, loss = 1.49230259\n",
            "Iteration 7, loss = 1.46249439\n",
            "Iteration 8, loss = 1.42522427\n",
            "Iteration 9, loss = 1.39899374\n",
            "Iteration 10, loss = 1.36327610\n",
            "Iteration 11, loss = 1.33916755\n",
            "Iteration 12, loss = 1.29475216\n",
            "Iteration 13, loss = 1.26060935\n",
            "Iteration 14, loss = 1.22480891\n",
            "Iteration 15, loss = 1.18262929\n",
            "Iteration 16, loss = 1.14933110\n",
            "Iteration 17, loss = 1.10995532\n",
            "Iteration 18, loss = 1.06451463\n",
            "Iteration 19, loss = 1.02167377\n",
            "Iteration 20, loss = 0.98023655\n",
            "Iteration 21, loss = 0.93771189\n",
            "Iteration 22, loss = 0.89394274\n",
            "Iteration 23, loss = 0.85128324\n",
            "Iteration 24, loss = 0.80763864\n",
            "Iteration 25, loss = 0.76768759\n",
            "Iteration 26, loss = 0.73033076\n",
            "Iteration 27, loss = 0.69062834\n",
            "Iteration 28, loss = 0.64786160\n",
            "Iteration 29, loss = 0.61019732\n",
            "Iteration 30, loss = 0.57262939\n",
            "Iteration 31, loss = 0.53896240\n",
            "Iteration 32, loss = 0.50565153\n",
            "Iteration 33, loss = 0.47335127\n",
            "Iteration 34, loss = 0.44290101\n",
            "Iteration 35, loss = 0.41409504\n",
            "Iteration 36, loss = 0.38754600\n",
            "Iteration 37, loss = 0.36348365\n",
            "Iteration 38, loss = 0.33985823\n",
            "Iteration 39, loss = 0.31865420\n",
            "Iteration 40, loss = 0.29663262\n",
            "Iteration 41, loss = 0.27620000\n",
            "Iteration 42, loss = 0.25875975\n",
            "Iteration 43, loss = 0.24162837\n",
            "Iteration 44, loss = 0.22689144\n",
            "Iteration 45, loss = 0.21139608\n",
            "Iteration 46, loss = 0.19799812\n",
            "Iteration 47, loss = 0.18581664\n",
            "Iteration 48, loss = 0.17347480\n",
            "Iteration 49, loss = 0.16286424\n",
            "Iteration 50, loss = 0.15287614\n",
            "#### Outer Iteration 3 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02892669\n",
            "Iteration 2, loss = 1.72191666\n",
            "Iteration 3, loss = 1.62586699\n",
            "Iteration 4, loss = 1.56967633\n",
            "Iteration 5, loss = 1.53067170\n",
            "Iteration 6, loss = 1.49028771\n",
            "Iteration 7, loss = 1.46177759\n",
            "Iteration 8, loss = 1.42956584\n",
            "Iteration 9, loss = 1.40123449\n",
            "Iteration 10, loss = 1.36844585\n",
            "Iteration 11, loss = 1.33676951\n",
            "Iteration 12, loss = 1.29797324\n",
            "Iteration 13, loss = 1.26500795\n",
            "Iteration 14, loss = 1.22633889\n",
            "Iteration 15, loss = 1.18781880\n",
            "Iteration 16, loss = 1.14921923\n",
            "Iteration 17, loss = 1.10907618\n",
            "Iteration 18, loss = 1.06695555\n",
            "Iteration 19, loss = 1.02557051\n",
            "Iteration 20, loss = 0.98332728\n",
            "Iteration 21, loss = 0.94034771\n",
            "Iteration 22, loss = 0.89690359\n",
            "Iteration 23, loss = 0.85346716\n",
            "Iteration 24, loss = 0.81252526\n",
            "Iteration 25, loss = 0.77114717\n",
            "Iteration 26, loss = 0.73228478\n",
            "Iteration 27, loss = 0.68961505\n",
            "Iteration 28, loss = 0.65276846\n",
            "Iteration 29, loss = 0.61341266\n",
            "Iteration 30, loss = 0.57715017\n",
            "Iteration 31, loss = 0.54119391\n",
            "Iteration 32, loss = 0.50886018\n",
            "Iteration 33, loss = 0.47724387\n",
            "Iteration 34, loss = 0.44590403\n",
            "Iteration 35, loss = 0.41756080\n",
            "Iteration 36, loss = 0.39137271\n",
            "Iteration 37, loss = 0.36535123\n",
            "Iteration 38, loss = 0.34068761\n",
            "Iteration 39, loss = 0.31886262\n",
            "Iteration 40, loss = 0.29900266\n",
            "Iteration 41, loss = 0.27866749\n",
            "Iteration 42, loss = 0.25956629\n",
            "Iteration 43, loss = 0.24224927\n",
            "Iteration 44, loss = 0.22719608\n",
            "Iteration 45, loss = 0.21326201\n",
            "Iteration 46, loss = 0.19964976\n",
            "Iteration 47, loss = 0.18663651\n",
            "Iteration 48, loss = 0.17530429\n",
            "Iteration 49, loss = 0.16471519\n",
            "Iteration 50, loss = 0.15460650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00707855\n",
            "Iteration 2, loss = 1.71059622\n",
            "Iteration 3, loss = 1.62103518\n",
            "Iteration 4, loss = 1.56441122\n",
            "Iteration 5, loss = 1.52513198\n",
            "Iteration 6, loss = 1.48954045\n",
            "Iteration 7, loss = 1.45709578\n",
            "Iteration 8, loss = 1.42065787\n",
            "Iteration 9, loss = 1.38994559\n",
            "Iteration 10, loss = 1.35847998\n",
            "Iteration 11, loss = 1.32553513\n",
            "Iteration 12, loss = 1.29111088\n",
            "Iteration 13, loss = 1.25687353\n",
            "Iteration 14, loss = 1.22318200\n",
            "Iteration 15, loss = 1.17768394\n",
            "Iteration 16, loss = 1.13929154\n",
            "Iteration 17, loss = 1.09606590\n",
            "Iteration 18, loss = 1.06154469\n",
            "Iteration 19, loss = 1.01874620\n",
            "Iteration 20, loss = 0.97346179\n",
            "Iteration 21, loss = 0.93194419\n",
            "Iteration 22, loss = 0.88830319\n",
            "Iteration 23, loss = 0.84615836\n",
            "Iteration 24, loss = 0.80469658\n",
            "Iteration 25, loss = 0.76224486\n",
            "Iteration 26, loss = 0.72001242\n",
            "Iteration 27, loss = 0.67967774\n",
            "Iteration 28, loss = 0.64364602\n",
            "Iteration 29, loss = 0.60302791\n",
            "Iteration 30, loss = 0.56870032\n",
            "Iteration 31, loss = 0.53512932\n",
            "Iteration 32, loss = 0.49930092\n",
            "Iteration 33, loss = 0.46747410\n",
            "Iteration 34, loss = 0.43739869\n",
            "Iteration 35, loss = 0.40917335\n",
            "Iteration 36, loss = 0.38243444\n",
            "Iteration 37, loss = 0.35671119\n",
            "Iteration 38, loss = 0.33410859\n",
            "Iteration 39, loss = 0.31247169\n",
            "Iteration 40, loss = 0.29104959\n",
            "Iteration 41, loss = 0.27185251\n",
            "Iteration 42, loss = 0.25282923\n",
            "Iteration 43, loss = 0.23682023\n",
            "Iteration 44, loss = 0.22191914\n",
            "Iteration 45, loss = 0.20621967\n",
            "Iteration 46, loss = 0.19283791\n",
            "Iteration 47, loss = 0.18107342\n",
            "Iteration 48, loss = 0.16938604\n",
            "Iteration 49, loss = 0.15932664\n",
            "Iteration 50, loss = 0.14880432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01911004\n",
            "Iteration 2, loss = 1.72026300\n",
            "Iteration 3, loss = 1.62053522\n",
            "Iteration 4, loss = 1.56395262\n",
            "Iteration 5, loss = 1.52521782\n",
            "Iteration 6, loss = 1.49146316\n",
            "Iteration 7, loss = 1.45862876\n",
            "Iteration 8, loss = 1.42745395\n",
            "Iteration 9, loss = 1.39830141\n",
            "Iteration 10, loss = 1.36166969\n",
            "Iteration 11, loss = 1.32826773\n",
            "Iteration 12, loss = 1.29421336\n",
            "Iteration 13, loss = 1.25919025\n",
            "Iteration 14, loss = 1.22499457\n",
            "Iteration 15, loss = 1.18225284\n",
            "Iteration 16, loss = 1.14241663\n",
            "Iteration 17, loss = 1.10864564\n",
            "Iteration 18, loss = 1.05685007\n",
            "Iteration 19, loss = 1.02096988\n",
            "Iteration 20, loss = 0.97756256\n",
            "Iteration 21, loss = 0.93438317\n",
            "Iteration 22, loss = 0.88948257\n",
            "Iteration 23, loss = 0.84734165\n",
            "Iteration 24, loss = 0.80510320\n",
            "Iteration 25, loss = 0.76132459\n",
            "Iteration 26, loss = 0.72082239\n",
            "Iteration 27, loss = 0.68336026\n",
            "Iteration 28, loss = 0.64187498\n",
            "Iteration 29, loss = 0.60553604\n",
            "Iteration 30, loss = 0.56810283\n",
            "Iteration 31, loss = 0.53187584\n",
            "Iteration 32, loss = 0.49931736\n",
            "Iteration 33, loss = 0.46911557\n",
            "Iteration 34, loss = 0.43825775\n",
            "Iteration 35, loss = 0.40891942\n",
            "Iteration 36, loss = 0.38103318\n",
            "Iteration 37, loss = 0.35618004\n",
            "Iteration 38, loss = 0.33351443\n",
            "Iteration 39, loss = 0.31146087\n",
            "Iteration 40, loss = 0.29138507\n",
            "Iteration 41, loss = 0.27102283\n",
            "Iteration 42, loss = 0.25223196\n",
            "Iteration 43, loss = 0.23611210\n",
            "Iteration 44, loss = 0.22104104\n",
            "Iteration 45, loss = 0.20625741\n",
            "Iteration 46, loss = 0.19398183\n",
            "Iteration 47, loss = 0.18073083\n",
            "Iteration 48, loss = 0.16922584\n",
            "Iteration 49, loss = 0.15901123\n",
            "Iteration 50, loss = 0.14882715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01675174\n",
            "Iteration 2, loss = 1.71571411\n",
            "Iteration 3, loss = 1.62066797\n",
            "Iteration 4, loss = 1.56113879\n",
            "Iteration 5, loss = 1.51854387\n",
            "Iteration 6, loss = 1.48639188\n",
            "Iteration 7, loss = 1.45684557\n",
            "Iteration 8, loss = 1.42426126\n",
            "Iteration 9, loss = 1.38780323\n",
            "Iteration 10, loss = 1.35820184\n",
            "Iteration 11, loss = 1.32512485\n",
            "Iteration 12, loss = 1.28684243\n",
            "Iteration 13, loss = 1.25393705\n",
            "Iteration 14, loss = 1.21758048\n",
            "Iteration 15, loss = 1.17770993\n",
            "Iteration 16, loss = 1.14010616\n",
            "Iteration 17, loss = 1.10380629\n",
            "Iteration 18, loss = 1.06028013\n",
            "Iteration 19, loss = 1.01807399\n",
            "Iteration 20, loss = 0.97502626\n",
            "Iteration 21, loss = 0.93193094\n",
            "Iteration 22, loss = 0.89181607\n",
            "Iteration 23, loss = 0.84703052\n",
            "Iteration 24, loss = 0.80992272\n",
            "Iteration 25, loss = 0.76689605\n",
            "Iteration 26, loss = 0.72230699\n",
            "Iteration 27, loss = 0.68291776\n",
            "Iteration 28, loss = 0.64601065\n",
            "Iteration 29, loss = 0.61107133\n",
            "Iteration 30, loss = 0.57262673\n",
            "Iteration 31, loss = 0.53671383\n",
            "Iteration 32, loss = 0.50447185\n",
            "Iteration 33, loss = 0.47357524\n",
            "Iteration 34, loss = 0.44121279\n",
            "Iteration 35, loss = 0.41363309\n",
            "Iteration 36, loss = 0.38736440\n",
            "Iteration 37, loss = 0.36157600\n",
            "Iteration 38, loss = 0.33814740\n",
            "Iteration 39, loss = 0.31572467\n",
            "Iteration 40, loss = 0.29502159\n",
            "Iteration 41, loss = 0.27672935\n",
            "Iteration 42, loss = 0.25802492\n",
            "Iteration 43, loss = 0.24143501\n",
            "Iteration 44, loss = 0.22540862\n",
            "Iteration 45, loss = 0.21093532\n",
            "Iteration 46, loss = 0.19760057\n",
            "Iteration 47, loss = 0.18540904\n",
            "Iteration 48, loss = 0.17333084\n",
            "Iteration 49, loss = 0.16226393\n",
            "Iteration 50, loss = 0.15267999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01209463\n",
            "Iteration 2, loss = 1.71697369\n",
            "Iteration 3, loss = 1.62192230\n",
            "Iteration 4, loss = 1.56574854\n",
            "Iteration 5, loss = 1.52734207\n",
            "Iteration 6, loss = 1.49143952\n",
            "Iteration 7, loss = 1.46043263\n",
            "Iteration 8, loss = 1.43129469\n",
            "Iteration 9, loss = 1.39824894\n",
            "Iteration 10, loss = 1.36029182\n",
            "Iteration 11, loss = 1.32683858\n",
            "Iteration 12, loss = 1.28994231\n",
            "Iteration 13, loss = 1.25380017\n",
            "Iteration 14, loss = 1.21877899\n",
            "Iteration 15, loss = 1.17799533\n",
            "Iteration 16, loss = 1.13900654\n",
            "Iteration 17, loss = 1.09532387\n",
            "Iteration 18, loss = 1.05626372\n",
            "Iteration 19, loss = 1.01248620\n",
            "Iteration 20, loss = 0.97152701\n",
            "Iteration 21, loss = 0.92586901\n",
            "Iteration 22, loss = 0.88157833\n",
            "Iteration 23, loss = 0.84243498\n",
            "Iteration 24, loss = 0.80148893\n",
            "Iteration 25, loss = 0.75750583\n",
            "Iteration 26, loss = 0.71563528\n",
            "Iteration 27, loss = 0.67449672\n",
            "Iteration 28, loss = 0.63539937\n",
            "Iteration 29, loss = 0.60001993\n",
            "Iteration 30, loss = 0.56164246\n",
            "Iteration 31, loss = 0.52888811\n",
            "Iteration 32, loss = 0.49585962\n",
            "Iteration 33, loss = 0.46559488\n",
            "Iteration 34, loss = 0.43454875\n",
            "Iteration 35, loss = 0.40628970\n",
            "Iteration 36, loss = 0.38039448\n",
            "Iteration 37, loss = 0.35548537\n",
            "Iteration 38, loss = 0.33144379\n",
            "Iteration 39, loss = 0.31012483\n",
            "Iteration 40, loss = 0.28997498\n",
            "Iteration 41, loss = 0.27037260\n",
            "Iteration 42, loss = 0.25364786\n",
            "Iteration 43, loss = 0.23610624\n",
            "Iteration 44, loss = 0.21999028\n",
            "Iteration 45, loss = 0.20659529\n",
            "Iteration 46, loss = 0.19342692\n",
            "Iteration 47, loss = 0.18041930\n",
            "Iteration 48, loss = 0.16956211\n",
            "Iteration 49, loss = 0.15900713\n",
            "Iteration 50, loss = 0.14951674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02188424\n",
            "Iteration 2, loss = 1.71672945\n",
            "Iteration 3, loss = 1.61873684\n",
            "Iteration 4, loss = 1.56400772\n",
            "Iteration 5, loss = 1.52049933\n",
            "Iteration 6, loss = 1.48563533\n",
            "Iteration 7, loss = 1.45573947\n",
            "Iteration 8, loss = 1.42620446\n",
            "Iteration 9, loss = 1.39052408\n",
            "Iteration 10, loss = 1.35434708\n",
            "Iteration 11, loss = 1.32127608\n",
            "Iteration 12, loss = 1.29097465\n",
            "Iteration 13, loss = 1.25150785\n",
            "Iteration 14, loss = 1.21294499\n",
            "Iteration 15, loss = 1.17974837\n",
            "Iteration 16, loss = 1.13934318\n",
            "Iteration 17, loss = 1.09682841\n",
            "Iteration 18, loss = 1.05702474\n",
            "Iteration 19, loss = 1.01895561\n",
            "Iteration 20, loss = 0.97217512\n",
            "Iteration 21, loss = 0.93184598\n",
            "Iteration 22, loss = 0.88707004\n",
            "Iteration 23, loss = 0.84756130\n",
            "Iteration 24, loss = 0.80540560\n",
            "Iteration 25, loss = 0.76330693\n",
            "Iteration 26, loss = 0.72229499\n",
            "Iteration 27, loss = 0.68409214\n",
            "Iteration 28, loss = 0.64285029\n",
            "Iteration 29, loss = 0.60643743\n",
            "Iteration 30, loss = 0.57291999\n",
            "Iteration 31, loss = 0.53654270\n",
            "Iteration 32, loss = 0.50228893\n",
            "Iteration 33, loss = 0.47086576\n",
            "Iteration 34, loss = 0.44066405\n",
            "Iteration 35, loss = 0.41351284\n",
            "Iteration 36, loss = 0.38590060\n",
            "Iteration 37, loss = 0.36118499\n",
            "Iteration 38, loss = 0.33568449\n",
            "Iteration 39, loss = 0.31573021\n",
            "Iteration 40, loss = 0.29503710\n",
            "Iteration 41, loss = 0.27583872\n",
            "Iteration 42, loss = 0.25676308\n",
            "Iteration 43, loss = 0.24010198\n",
            "Iteration 44, loss = 0.22452366\n",
            "Iteration 45, loss = 0.21108131\n",
            "Iteration 46, loss = 0.19616830\n",
            "Iteration 47, loss = 0.18372042\n",
            "Iteration 48, loss = 0.17280596\n",
            "Iteration 49, loss = 0.16239108\n",
            "Iteration 50, loss = 0.15191495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01052665\n",
            "Iteration 2, loss = 1.71561928\n",
            "Iteration 3, loss = 1.62364348\n",
            "Iteration 4, loss = 1.56946432\n",
            "Iteration 5, loss = 1.52866675\n",
            "Iteration 6, loss = 1.49424563\n",
            "Iteration 7, loss = 1.46290097\n",
            "Iteration 8, loss = 1.42855234\n",
            "Iteration 9, loss = 1.39644540\n",
            "Iteration 10, loss = 1.36688399\n",
            "Iteration 11, loss = 1.33193407\n",
            "Iteration 12, loss = 1.29613382\n",
            "Iteration 13, loss = 1.26213944\n",
            "Iteration 14, loss = 1.22550274\n",
            "Iteration 15, loss = 1.18847782\n",
            "Iteration 16, loss = 1.14790609\n",
            "Iteration 17, loss = 1.10872754\n",
            "Iteration 18, loss = 1.07089160\n",
            "Iteration 19, loss = 1.02559809\n",
            "Iteration 20, loss = 0.98496668\n",
            "Iteration 21, loss = 0.94287030\n",
            "Iteration 22, loss = 0.90120602\n",
            "Iteration 23, loss = 0.85981723\n",
            "Iteration 24, loss = 0.81345213\n",
            "Iteration 25, loss = 0.77366184\n",
            "Iteration 26, loss = 0.73351920\n",
            "Iteration 27, loss = 0.69231399\n",
            "Iteration 28, loss = 0.65375225\n",
            "Iteration 29, loss = 0.61752259\n",
            "Iteration 30, loss = 0.57979254\n",
            "Iteration 31, loss = 0.54634822\n",
            "Iteration 32, loss = 0.51221136\n",
            "Iteration 33, loss = 0.48206700\n",
            "Iteration 34, loss = 0.44893597\n",
            "Iteration 35, loss = 0.42103887\n",
            "Iteration 36, loss = 0.39242911\n",
            "Iteration 37, loss = 0.36662952\n",
            "Iteration 38, loss = 0.34256706\n",
            "Iteration 39, loss = 0.32196640\n",
            "Iteration 40, loss = 0.30021144\n",
            "Iteration 41, loss = 0.28015947\n",
            "Iteration 42, loss = 0.26179173\n",
            "Iteration 43, loss = 0.24406445\n",
            "Iteration 44, loss = 0.22839116\n",
            "Iteration 45, loss = 0.21358835\n",
            "Iteration 46, loss = 0.20006554\n",
            "Iteration 47, loss = 0.18755029\n",
            "Iteration 48, loss = 0.17586386\n",
            "Iteration 49, loss = 0.16495328\n",
            "Iteration 50, loss = 0.15465670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02532155\n",
            "Iteration 2, loss = 1.71441721\n",
            "Iteration 3, loss = 1.62226550\n",
            "Iteration 4, loss = 1.56532074\n",
            "Iteration 5, loss = 1.52539407\n",
            "Iteration 6, loss = 1.48654426\n",
            "Iteration 7, loss = 1.45571264\n",
            "Iteration 8, loss = 1.42486447\n",
            "Iteration 9, loss = 1.39560435\n",
            "Iteration 10, loss = 1.36216506\n",
            "Iteration 11, loss = 1.32905986\n",
            "Iteration 12, loss = 1.29324658\n",
            "Iteration 13, loss = 1.25989656\n",
            "Iteration 14, loss = 1.21968347\n",
            "Iteration 15, loss = 1.18486946\n",
            "Iteration 16, loss = 1.14819886\n",
            "Iteration 17, loss = 1.10668985\n",
            "Iteration 18, loss = 1.06414084\n",
            "Iteration 19, loss = 1.02377188\n",
            "Iteration 20, loss = 0.98143889\n",
            "Iteration 21, loss = 0.94052431\n",
            "Iteration 22, loss = 0.89463299\n",
            "Iteration 23, loss = 0.85676231\n",
            "Iteration 24, loss = 0.81549593\n",
            "Iteration 25, loss = 0.76734235\n",
            "Iteration 26, loss = 0.72828854\n",
            "Iteration 27, loss = 0.69047102\n",
            "Iteration 28, loss = 0.64918565\n",
            "Iteration 29, loss = 0.61090938\n",
            "Iteration 30, loss = 0.57351095\n",
            "Iteration 31, loss = 0.54021996\n",
            "Iteration 32, loss = 0.50731677\n",
            "Iteration 33, loss = 0.47412674\n",
            "Iteration 34, loss = 0.44473543\n",
            "Iteration 35, loss = 0.41324734\n",
            "Iteration 36, loss = 0.38809960\n",
            "Iteration 37, loss = 0.36176490\n",
            "Iteration 38, loss = 0.33794323\n",
            "Iteration 39, loss = 0.31526466\n",
            "Iteration 40, loss = 0.29509740\n",
            "Iteration 41, loss = 0.27440425\n",
            "Iteration 42, loss = 0.25795225\n",
            "Iteration 43, loss = 0.23906621\n",
            "Iteration 44, loss = 0.22447296\n",
            "Iteration 45, loss = 0.20968837\n",
            "Iteration 46, loss = 0.19657141\n",
            "Iteration 47, loss = 0.18378137\n",
            "Iteration 48, loss = 0.17199808\n",
            "Iteration 49, loss = 0.16177891\n",
            "Iteration 50, loss = 0.15195655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01135491\n",
            "Iteration 2, loss = 1.71408892\n",
            "Iteration 3, loss = 1.61993377\n",
            "Iteration 4, loss = 1.56186253\n",
            "Iteration 5, loss = 1.52072816\n",
            "Iteration 6, loss = 1.48565649\n",
            "Iteration 7, loss = 1.45559552\n",
            "Iteration 8, loss = 1.42326352\n",
            "Iteration 9, loss = 1.39067728\n",
            "Iteration 10, loss = 1.35762360\n",
            "Iteration 11, loss = 1.32441963\n",
            "Iteration 12, loss = 1.29124192\n",
            "Iteration 13, loss = 1.25381985\n",
            "Iteration 14, loss = 1.21897315\n",
            "Iteration 15, loss = 1.17952170\n",
            "Iteration 16, loss = 1.14303716\n",
            "Iteration 17, loss = 1.09836381\n",
            "Iteration 18, loss = 1.05840298\n",
            "Iteration 19, loss = 1.01465392\n",
            "Iteration 20, loss = 0.97774098\n",
            "Iteration 21, loss = 0.93268619\n",
            "Iteration 22, loss = 0.88833990\n",
            "Iteration 23, loss = 0.84547766\n",
            "Iteration 24, loss = 0.80864705\n",
            "Iteration 25, loss = 0.76118185\n",
            "Iteration 26, loss = 0.72170710\n",
            "Iteration 27, loss = 0.68218402\n",
            "Iteration 28, loss = 0.64452222\n",
            "Iteration 29, loss = 0.60295030\n",
            "Iteration 30, loss = 0.57034670\n",
            "Iteration 31, loss = 0.53223481\n",
            "Iteration 32, loss = 0.49909206\n",
            "Iteration 33, loss = 0.46778512\n",
            "Iteration 34, loss = 0.43953333\n",
            "Iteration 35, loss = 0.40793784\n",
            "Iteration 36, loss = 0.38065113\n",
            "Iteration 37, loss = 0.35566659\n",
            "Iteration 38, loss = 0.33191704\n",
            "Iteration 39, loss = 0.31020848\n",
            "Iteration 40, loss = 0.28862331\n",
            "Iteration 41, loss = 0.27068411\n",
            "Iteration 42, loss = 0.25281720\n",
            "Iteration 43, loss = 0.23616050\n",
            "Iteration 44, loss = 0.21995782\n",
            "Iteration 45, loss = 0.20602389\n",
            "Iteration 46, loss = 0.19274756\n",
            "Iteration 47, loss = 0.18040362\n",
            "Iteration 48, loss = 0.16882582\n",
            "Iteration 49, loss = 0.15777939\n",
            "Iteration 50, loss = 0.14878912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00436367\n",
            "Iteration 2, loss = 1.70634266\n",
            "Iteration 3, loss = 1.60805815\n",
            "Iteration 4, loss = 1.55445583\n",
            "Iteration 5, loss = 1.51232528\n",
            "Iteration 6, loss = 1.47688543\n",
            "Iteration 7, loss = 1.44555411\n",
            "Iteration 8, loss = 1.41096145\n",
            "Iteration 9, loss = 1.37867272\n",
            "Iteration 10, loss = 1.34634073\n",
            "Iteration 11, loss = 1.31317067\n",
            "Iteration 12, loss = 1.27777012\n",
            "Iteration 13, loss = 1.24449244\n",
            "Iteration 14, loss = 1.20943622\n",
            "Iteration 15, loss = 1.16942691\n",
            "Iteration 16, loss = 1.12991744\n",
            "Iteration 17, loss = 1.08786967\n",
            "Iteration 18, loss = 1.04716731\n",
            "Iteration 19, loss = 1.01025830\n",
            "Iteration 20, loss = 0.96502784\n",
            "Iteration 21, loss = 0.92554751\n",
            "Iteration 22, loss = 0.88146626\n",
            "Iteration 23, loss = 0.84147952\n",
            "Iteration 24, loss = 0.79876760\n",
            "Iteration 25, loss = 0.75412377\n",
            "Iteration 26, loss = 0.71755305\n",
            "Iteration 27, loss = 0.67596403\n",
            "Iteration 28, loss = 0.63803330\n",
            "Iteration 29, loss = 0.59981150\n",
            "Iteration 30, loss = 0.56323323\n",
            "Iteration 31, loss = 0.52970102\n",
            "Iteration 32, loss = 0.49599996\n",
            "Iteration 33, loss = 0.46525542\n",
            "Iteration 34, loss = 0.43534880\n",
            "Iteration 35, loss = 0.40531468\n",
            "Iteration 36, loss = 0.37867082\n",
            "Iteration 37, loss = 0.35498972\n",
            "Iteration 38, loss = 0.33165050\n",
            "Iteration 39, loss = 0.31050466\n",
            "Iteration 40, loss = 0.28946452\n",
            "Iteration 41, loss = 0.26975063\n",
            "Iteration 42, loss = 0.25143450\n",
            "Iteration 43, loss = 0.23626460\n",
            "Iteration 44, loss = 0.22027172\n",
            "Iteration 45, loss = 0.20623179\n",
            "Iteration 46, loss = 0.19306061\n",
            "Iteration 47, loss = 0.18004191\n",
            "Iteration 48, loss = 0.16898286\n",
            "Iteration 49, loss = 0.15785364\n",
            "Iteration 50, loss = 0.14804334\n",
            "#### Outer Iteration 4 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03186683\n",
            "Iteration 2, loss = 1.71850416\n",
            "Iteration 3, loss = 1.62183222\n",
            "Iteration 4, loss = 1.56684475\n",
            "Iteration 5, loss = 1.52533460\n",
            "Iteration 6, loss = 1.49002757\n",
            "Iteration 7, loss = 1.45666872\n",
            "Iteration 8, loss = 1.42740127\n",
            "Iteration 9, loss = 1.39849438\n",
            "Iteration 10, loss = 1.36766093\n",
            "Iteration 11, loss = 1.33238207\n",
            "Iteration 12, loss = 1.29644069\n",
            "Iteration 13, loss = 1.26410917\n",
            "Iteration 14, loss = 1.22481354\n",
            "Iteration 15, loss = 1.19306567\n",
            "Iteration 16, loss = 1.14583265\n",
            "Iteration 17, loss = 1.10836101\n",
            "Iteration 18, loss = 1.06724384\n",
            "Iteration 19, loss = 1.02866999\n",
            "Iteration 20, loss = 0.98729394\n",
            "Iteration 21, loss = 0.94462716\n",
            "Iteration 22, loss = 0.90192410\n",
            "Iteration 23, loss = 0.85797170\n",
            "Iteration 24, loss = 0.81746048\n",
            "Iteration 25, loss = 0.77715989\n",
            "Iteration 26, loss = 0.73436853\n",
            "Iteration 27, loss = 0.69720379\n",
            "Iteration 28, loss = 0.65503524\n",
            "Iteration 29, loss = 0.62013536\n",
            "Iteration 30, loss = 0.58295061\n",
            "Iteration 31, loss = 0.54808689\n",
            "Iteration 32, loss = 0.51652226\n",
            "Iteration 33, loss = 0.48197352\n",
            "Iteration 34, loss = 0.44994061\n",
            "Iteration 35, loss = 0.42324073\n",
            "Iteration 36, loss = 0.39618024\n",
            "Iteration 37, loss = 0.36933618\n",
            "Iteration 38, loss = 0.34629249\n",
            "Iteration 39, loss = 0.32435651\n",
            "Iteration 40, loss = 0.30249422\n",
            "Iteration 41, loss = 0.28338796\n",
            "Iteration 42, loss = 0.26403997\n",
            "Iteration 43, loss = 0.24591926\n",
            "Iteration 44, loss = 0.23024346\n",
            "Iteration 45, loss = 0.21532080\n",
            "Iteration 46, loss = 0.20177460\n",
            "Iteration 47, loss = 0.18895053\n",
            "Iteration 48, loss = 0.17713052\n",
            "Iteration 49, loss = 0.16663019\n",
            "Iteration 50, loss = 0.15612283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01949464\n",
            "Iteration 2, loss = 1.71719517\n",
            "Iteration 3, loss = 1.61809965\n",
            "Iteration 4, loss = 1.56460838\n",
            "Iteration 5, loss = 1.52284195\n",
            "Iteration 6, loss = 1.48768750\n",
            "Iteration 7, loss = 1.45809046\n",
            "Iteration 8, loss = 1.42616364\n",
            "Iteration 9, loss = 1.39399473\n",
            "Iteration 10, loss = 1.36418195\n",
            "Iteration 11, loss = 1.32935410\n",
            "Iteration 12, loss = 1.29402931\n",
            "Iteration 13, loss = 1.25670108\n",
            "Iteration 14, loss = 1.22176734\n",
            "Iteration 15, loss = 1.18144894\n",
            "Iteration 16, loss = 1.14273929\n",
            "Iteration 17, loss = 1.10659036\n",
            "Iteration 18, loss = 1.06205610\n",
            "Iteration 19, loss = 1.02199823\n",
            "Iteration 20, loss = 0.98099000\n",
            "Iteration 21, loss = 0.94056361\n",
            "Iteration 22, loss = 0.89752217\n",
            "Iteration 23, loss = 0.85676076\n",
            "Iteration 24, loss = 0.81094360\n",
            "Iteration 25, loss = 0.77106633\n",
            "Iteration 26, loss = 0.72887844\n",
            "Iteration 27, loss = 0.68799182\n",
            "Iteration 28, loss = 0.64951308\n",
            "Iteration 29, loss = 0.61205208\n",
            "Iteration 30, loss = 0.57421241\n",
            "Iteration 31, loss = 0.53846545\n",
            "Iteration 32, loss = 0.50623005\n",
            "Iteration 33, loss = 0.47355875\n",
            "Iteration 34, loss = 0.44554445\n",
            "Iteration 35, loss = 0.41401657\n",
            "Iteration 36, loss = 0.38742642\n",
            "Iteration 37, loss = 0.36270111\n",
            "Iteration 38, loss = 0.33934564\n",
            "Iteration 39, loss = 0.31593611\n",
            "Iteration 40, loss = 0.29523820\n",
            "Iteration 41, loss = 0.27579527\n",
            "Iteration 42, loss = 0.25778579\n",
            "Iteration 43, loss = 0.24037356\n",
            "Iteration 44, loss = 0.22443417\n",
            "Iteration 45, loss = 0.21043214\n",
            "Iteration 46, loss = 0.19634834\n",
            "Iteration 47, loss = 0.18401911\n",
            "Iteration 48, loss = 0.17235979\n",
            "Iteration 49, loss = 0.16252525\n",
            "Iteration 50, loss = 0.15225025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03754564\n",
            "Iteration 2, loss = 1.71850742\n",
            "Iteration 3, loss = 1.62607321\n",
            "Iteration 4, loss = 1.56428285\n",
            "Iteration 5, loss = 1.52291311\n",
            "Iteration 6, loss = 1.48768708\n",
            "Iteration 7, loss = 1.45672796\n",
            "Iteration 8, loss = 1.42605489\n",
            "Iteration 9, loss = 1.39405453\n",
            "Iteration 10, loss = 1.36035917\n",
            "Iteration 11, loss = 1.32831727\n",
            "Iteration 12, loss = 1.29421872\n",
            "Iteration 13, loss = 1.25924872\n",
            "Iteration 14, loss = 1.22305741\n",
            "Iteration 15, loss = 1.18720871\n",
            "Iteration 16, loss = 1.14701751\n",
            "Iteration 17, loss = 1.10397846\n",
            "Iteration 18, loss = 1.06438502\n",
            "Iteration 19, loss = 1.02138886\n",
            "Iteration 20, loss = 0.97912281\n",
            "Iteration 21, loss = 0.93890131\n",
            "Iteration 22, loss = 0.89198403\n",
            "Iteration 23, loss = 0.85057860\n",
            "Iteration 24, loss = 0.80841217\n",
            "Iteration 25, loss = 0.76590667\n",
            "Iteration 26, loss = 0.72525712\n",
            "Iteration 27, loss = 0.68671025\n",
            "Iteration 28, loss = 0.64388338\n",
            "Iteration 29, loss = 0.61025238\n",
            "Iteration 30, loss = 0.57265203\n",
            "Iteration 31, loss = 0.53806222\n",
            "Iteration 32, loss = 0.50450724\n",
            "Iteration 33, loss = 0.47134248\n",
            "Iteration 34, loss = 0.44348380\n",
            "Iteration 35, loss = 0.41379303\n",
            "Iteration 36, loss = 0.38680013\n",
            "Iteration 37, loss = 0.36135533\n",
            "Iteration 38, loss = 0.33864140\n",
            "Iteration 39, loss = 0.31586907\n",
            "Iteration 40, loss = 0.29571756\n",
            "Iteration 41, loss = 0.27586906\n",
            "Iteration 42, loss = 0.25824033\n",
            "Iteration 43, loss = 0.24040743\n",
            "Iteration 44, loss = 0.22550361\n",
            "Iteration 45, loss = 0.20955696\n",
            "Iteration 46, loss = 0.19705313\n",
            "Iteration 47, loss = 0.18410098\n",
            "Iteration 48, loss = 0.17347634\n",
            "Iteration 49, loss = 0.16240819\n",
            "Iteration 50, loss = 0.15221446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02228339\n",
            "Iteration 2, loss = 1.72040642\n",
            "Iteration 3, loss = 1.62021104\n",
            "Iteration 4, loss = 1.56166456\n",
            "Iteration 5, loss = 1.52415925\n",
            "Iteration 6, loss = 1.49029726\n",
            "Iteration 7, loss = 1.46045727\n",
            "Iteration 8, loss = 1.42751560\n",
            "Iteration 9, loss = 1.39403211\n",
            "Iteration 10, loss = 1.36136276\n",
            "Iteration 11, loss = 1.33135462\n",
            "Iteration 12, loss = 1.29268789\n",
            "Iteration 13, loss = 1.25386076\n",
            "Iteration 14, loss = 1.22195132\n",
            "Iteration 15, loss = 1.17940366\n",
            "Iteration 16, loss = 1.14617978\n",
            "Iteration 17, loss = 1.10145999\n",
            "Iteration 18, loss = 1.05872397\n",
            "Iteration 19, loss = 1.01850677\n",
            "Iteration 20, loss = 0.97627793\n",
            "Iteration 21, loss = 0.93299542\n",
            "Iteration 22, loss = 0.88826113\n",
            "Iteration 23, loss = 0.84943596\n",
            "Iteration 24, loss = 0.80407163\n",
            "Iteration 25, loss = 0.76521204\n",
            "Iteration 26, loss = 0.72231456\n",
            "Iteration 27, loss = 0.67999783\n",
            "Iteration 28, loss = 0.64329768\n",
            "Iteration 29, loss = 0.60772668\n",
            "Iteration 30, loss = 0.56899675\n",
            "Iteration 31, loss = 0.53451350\n",
            "Iteration 32, loss = 0.50104763\n",
            "Iteration 33, loss = 0.46902227\n",
            "Iteration 34, loss = 0.43947782\n",
            "Iteration 35, loss = 0.41134527\n",
            "Iteration 36, loss = 0.38450171\n",
            "Iteration 37, loss = 0.35791197\n",
            "Iteration 38, loss = 0.33637498\n",
            "Iteration 39, loss = 0.31404988\n",
            "Iteration 40, loss = 0.29287629\n",
            "Iteration 41, loss = 0.27468368\n",
            "Iteration 42, loss = 0.25500456\n",
            "Iteration 43, loss = 0.23844630\n",
            "Iteration 44, loss = 0.22378953\n",
            "Iteration 45, loss = 0.20960057\n",
            "Iteration 46, loss = 0.19529106\n",
            "Iteration 47, loss = 0.18318282\n",
            "Iteration 48, loss = 0.17190027\n",
            "Iteration 49, loss = 0.16211369\n",
            "Iteration 50, loss = 0.15106278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02175142\n",
            "Iteration 2, loss = 1.71304193\n",
            "Iteration 3, loss = 1.61522124\n",
            "Iteration 4, loss = 1.55664663\n",
            "Iteration 5, loss = 1.51968044\n",
            "Iteration 6, loss = 1.47803731\n",
            "Iteration 7, loss = 1.45091258\n",
            "Iteration 8, loss = 1.41687942\n",
            "Iteration 9, loss = 1.38318372\n",
            "Iteration 10, loss = 1.35387482\n",
            "Iteration 11, loss = 1.31736953\n",
            "Iteration 12, loss = 1.28318760\n",
            "Iteration 13, loss = 1.24970327\n",
            "Iteration 14, loss = 1.21695434\n",
            "Iteration 15, loss = 1.17068024\n",
            "Iteration 16, loss = 1.13488940\n",
            "Iteration 17, loss = 1.09366192\n",
            "Iteration 18, loss = 1.05259281\n",
            "Iteration 19, loss = 1.01265611\n",
            "Iteration 20, loss = 0.97016906\n",
            "Iteration 21, loss = 0.92624157\n",
            "Iteration 22, loss = 0.88611199\n",
            "Iteration 23, loss = 0.84165039\n",
            "Iteration 24, loss = 0.79995446\n",
            "Iteration 25, loss = 0.75828751\n",
            "Iteration 26, loss = 0.72093608\n",
            "Iteration 27, loss = 0.67927637\n",
            "Iteration 28, loss = 0.63980434\n",
            "Iteration 29, loss = 0.60403302\n",
            "Iteration 30, loss = 0.56621501\n",
            "Iteration 31, loss = 0.53065213\n",
            "Iteration 32, loss = 0.49995694\n",
            "Iteration 33, loss = 0.46725582\n",
            "Iteration 34, loss = 0.43925347\n",
            "Iteration 35, loss = 0.40952971\n",
            "Iteration 36, loss = 0.38439126\n",
            "Iteration 37, loss = 0.35717350\n",
            "Iteration 38, loss = 0.33450055\n",
            "Iteration 39, loss = 0.31279845\n",
            "Iteration 40, loss = 0.29199246\n",
            "Iteration 41, loss = 0.27281010\n",
            "Iteration 42, loss = 0.25558828\n",
            "Iteration 43, loss = 0.23868839\n",
            "Iteration 44, loss = 0.22200455\n",
            "Iteration 45, loss = 0.20760165\n",
            "Iteration 46, loss = 0.19503692\n",
            "Iteration 47, loss = 0.18245853\n",
            "Iteration 48, loss = 0.17066312\n",
            "Iteration 49, loss = 0.16024123\n",
            "Iteration 50, loss = 0.15052210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03320571\n",
            "Iteration 2, loss = 1.71804763\n",
            "Iteration 3, loss = 1.61869420\n",
            "Iteration 4, loss = 1.56496875\n",
            "Iteration 5, loss = 1.51910310\n",
            "Iteration 6, loss = 1.48925906\n",
            "Iteration 7, loss = 1.45521498\n",
            "Iteration 8, loss = 1.42472492\n",
            "Iteration 9, loss = 1.39233723\n",
            "Iteration 10, loss = 1.35581547\n",
            "Iteration 11, loss = 1.32810151\n",
            "Iteration 12, loss = 1.29260548\n",
            "Iteration 13, loss = 1.25679164\n",
            "Iteration 14, loss = 1.21783921\n",
            "Iteration 15, loss = 1.18106427\n",
            "Iteration 16, loss = 1.13959191\n",
            "Iteration 17, loss = 1.10057641\n",
            "Iteration 18, loss = 1.06049875\n",
            "Iteration 19, loss = 1.01763906\n",
            "Iteration 20, loss = 0.97879183\n",
            "Iteration 21, loss = 0.93534946\n",
            "Iteration 22, loss = 0.89040801\n",
            "Iteration 23, loss = 0.85064065\n",
            "Iteration 24, loss = 0.80652090\n",
            "Iteration 25, loss = 0.76419785\n",
            "Iteration 26, loss = 0.72419838\n",
            "Iteration 27, loss = 0.68471261\n",
            "Iteration 28, loss = 0.64558994\n",
            "Iteration 29, loss = 0.60816127\n",
            "Iteration 30, loss = 0.57130658\n",
            "Iteration 31, loss = 0.53805091\n",
            "Iteration 32, loss = 0.50278866\n",
            "Iteration 33, loss = 0.47298766\n",
            "Iteration 34, loss = 0.44307190\n",
            "Iteration 35, loss = 0.41267212\n",
            "Iteration 36, loss = 0.38607481\n",
            "Iteration 37, loss = 0.36338589\n",
            "Iteration 38, loss = 0.33986761\n",
            "Iteration 39, loss = 0.31610413\n",
            "Iteration 40, loss = 0.29455540\n",
            "Iteration 41, loss = 0.27580234\n",
            "Iteration 42, loss = 0.25797352\n",
            "Iteration 43, loss = 0.24129447\n",
            "Iteration 44, loss = 0.22601809\n",
            "Iteration 45, loss = 0.21097890\n",
            "Iteration 46, loss = 0.19826106\n",
            "Iteration 47, loss = 0.18545300\n",
            "Iteration 48, loss = 0.17403326\n",
            "Iteration 49, loss = 0.16328750\n",
            "Iteration 50, loss = 0.15332813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01750385\n",
            "Iteration 2, loss = 1.71748992\n",
            "Iteration 3, loss = 1.62397903\n",
            "Iteration 4, loss = 1.57002588\n",
            "Iteration 5, loss = 1.52649109\n",
            "Iteration 6, loss = 1.48713044\n",
            "Iteration 7, loss = 1.45579395\n",
            "Iteration 8, loss = 1.42314025\n",
            "Iteration 9, loss = 1.39426534\n",
            "Iteration 10, loss = 1.35674109\n",
            "Iteration 11, loss = 1.32381191\n",
            "Iteration 12, loss = 1.28721520\n",
            "Iteration 13, loss = 1.25157538\n",
            "Iteration 14, loss = 1.21384803\n",
            "Iteration 15, loss = 1.17627782\n",
            "Iteration 16, loss = 1.13760038\n",
            "Iteration 17, loss = 1.10105646\n",
            "Iteration 18, loss = 1.05755789\n",
            "Iteration 19, loss = 1.01698866\n",
            "Iteration 20, loss = 0.97200456\n",
            "Iteration 21, loss = 0.92492509\n",
            "Iteration 22, loss = 0.88587988\n",
            "Iteration 23, loss = 0.84493991\n",
            "Iteration 24, loss = 0.80259786\n",
            "Iteration 25, loss = 0.76011538\n",
            "Iteration 26, loss = 0.71479329\n",
            "Iteration 27, loss = 0.67982789\n",
            "Iteration 28, loss = 0.63846908\n",
            "Iteration 29, loss = 0.59990643\n",
            "Iteration 30, loss = 0.56665796\n",
            "Iteration 31, loss = 0.53109049\n",
            "Iteration 32, loss = 0.49961163\n",
            "Iteration 33, loss = 0.46639304\n",
            "Iteration 34, loss = 0.43549651\n",
            "Iteration 35, loss = 0.40856226\n",
            "Iteration 36, loss = 0.38138391\n",
            "Iteration 37, loss = 0.35546922\n",
            "Iteration 38, loss = 0.33287034\n",
            "Iteration 39, loss = 0.31011773\n",
            "Iteration 40, loss = 0.29200378\n",
            "Iteration 41, loss = 0.27118825\n",
            "Iteration 42, loss = 0.25322343\n",
            "Iteration 43, loss = 0.23724089\n",
            "Iteration 44, loss = 0.22120423\n",
            "Iteration 45, loss = 0.20614211\n",
            "Iteration 46, loss = 0.19288098\n",
            "Iteration 47, loss = 0.18162011\n",
            "Iteration 48, loss = 0.16981444\n",
            "Iteration 49, loss = 0.15913038\n",
            "Iteration 50, loss = 0.14946942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02667229\n",
            "Iteration 2, loss = 1.71688636\n",
            "Iteration 3, loss = 1.61678818\n",
            "Iteration 4, loss = 1.56296502\n",
            "Iteration 5, loss = 1.52122783\n",
            "Iteration 6, loss = 1.48543387\n",
            "Iteration 7, loss = 1.45310323\n",
            "Iteration 8, loss = 1.42160376\n",
            "Iteration 9, loss = 1.38825993\n",
            "Iteration 10, loss = 1.35640404\n",
            "Iteration 11, loss = 1.32476379\n",
            "Iteration 12, loss = 1.28731960\n",
            "Iteration 13, loss = 1.24913237\n",
            "Iteration 14, loss = 1.20972564\n",
            "Iteration 15, loss = 1.17856979\n",
            "Iteration 16, loss = 1.13919276\n",
            "Iteration 17, loss = 1.09276913\n",
            "Iteration 18, loss = 1.05177029\n",
            "Iteration 19, loss = 1.01351343\n",
            "Iteration 20, loss = 0.96997940\n",
            "Iteration 21, loss = 0.92577419\n",
            "Iteration 22, loss = 0.88413514\n",
            "Iteration 23, loss = 0.84225446\n",
            "Iteration 24, loss = 0.79960073\n",
            "Iteration 25, loss = 0.75970949\n",
            "Iteration 26, loss = 0.71977708\n",
            "Iteration 27, loss = 0.67673419\n",
            "Iteration 28, loss = 0.63914720\n",
            "Iteration 29, loss = 0.60558197\n",
            "Iteration 30, loss = 0.56861406\n",
            "Iteration 31, loss = 0.53286095\n",
            "Iteration 32, loss = 0.49938853\n",
            "Iteration 33, loss = 0.46855926\n",
            "Iteration 34, loss = 0.43744159\n",
            "Iteration 35, loss = 0.41092159\n",
            "Iteration 36, loss = 0.38432775\n",
            "Iteration 37, loss = 0.35865798\n",
            "Iteration 38, loss = 0.33640047\n",
            "Iteration 39, loss = 0.31293981\n",
            "Iteration 40, loss = 0.29342692\n",
            "Iteration 41, loss = 0.27289961\n",
            "Iteration 42, loss = 0.25584926\n",
            "Iteration 43, loss = 0.24016005\n",
            "Iteration 44, loss = 0.22474391\n",
            "Iteration 45, loss = 0.20981466\n",
            "Iteration 46, loss = 0.19600569\n",
            "Iteration 47, loss = 0.18347478\n",
            "Iteration 48, loss = 0.17199505\n",
            "Iteration 49, loss = 0.16153379\n",
            "Iteration 50, loss = 0.15128981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01698301\n",
            "Iteration 2, loss = 1.71918066\n",
            "Iteration 3, loss = 1.62474369\n",
            "Iteration 4, loss = 1.56274555\n",
            "Iteration 5, loss = 1.52092929\n",
            "Iteration 6, loss = 1.48782451\n",
            "Iteration 7, loss = 1.45538168\n",
            "Iteration 8, loss = 1.42100928\n",
            "Iteration 9, loss = 1.39350859\n",
            "Iteration 10, loss = 1.35825130\n",
            "Iteration 11, loss = 1.32629407\n",
            "Iteration 12, loss = 1.29317313\n",
            "Iteration 13, loss = 1.25506350\n",
            "Iteration 14, loss = 1.21841961\n",
            "Iteration 15, loss = 1.18105708\n",
            "Iteration 16, loss = 1.13910234\n",
            "Iteration 17, loss = 1.10072611\n",
            "Iteration 18, loss = 1.06156902\n",
            "Iteration 19, loss = 1.01690965\n",
            "Iteration 20, loss = 0.97237503\n",
            "Iteration 21, loss = 0.93224264\n",
            "Iteration 22, loss = 0.89292858\n",
            "Iteration 23, loss = 0.84792939\n",
            "Iteration 24, loss = 0.80554091\n",
            "Iteration 25, loss = 0.76570656\n",
            "Iteration 26, loss = 0.72552298\n",
            "Iteration 27, loss = 0.68370143\n",
            "Iteration 28, loss = 0.64822810\n",
            "Iteration 29, loss = 0.60772503\n",
            "Iteration 30, loss = 0.57278187\n",
            "Iteration 31, loss = 0.53858839\n",
            "Iteration 32, loss = 0.50570417\n",
            "Iteration 33, loss = 0.47394182\n",
            "Iteration 34, loss = 0.44493780\n",
            "Iteration 35, loss = 0.41580395\n",
            "Iteration 36, loss = 0.38645491\n",
            "Iteration 37, loss = 0.36026731\n",
            "Iteration 38, loss = 0.33778340\n",
            "Iteration 39, loss = 0.31564795\n",
            "Iteration 40, loss = 0.29402153\n",
            "Iteration 41, loss = 0.27490098\n",
            "Iteration 42, loss = 0.25722537\n",
            "Iteration 43, loss = 0.24006810\n",
            "Iteration 44, loss = 0.22480124\n",
            "Iteration 45, loss = 0.21044853\n",
            "Iteration 46, loss = 0.19659660\n",
            "Iteration 47, loss = 0.18368854\n",
            "Iteration 48, loss = 0.17192413\n",
            "Iteration 49, loss = 0.16198726\n",
            "Iteration 50, loss = 0.15133328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01675775\n",
            "Iteration 2, loss = 1.71639284\n",
            "Iteration 3, loss = 1.61887254\n",
            "Iteration 4, loss = 1.55855681\n",
            "Iteration 5, loss = 1.52420393\n",
            "Iteration 6, loss = 1.49052613\n",
            "Iteration 7, loss = 1.45682330\n",
            "Iteration 8, loss = 1.41937803\n",
            "Iteration 9, loss = 1.38536542\n",
            "Iteration 10, loss = 1.35339314\n",
            "Iteration 11, loss = 1.32073650\n",
            "Iteration 12, loss = 1.28558716\n",
            "Iteration 13, loss = 1.24969609\n",
            "Iteration 14, loss = 1.21180636\n",
            "Iteration 15, loss = 1.17453608\n",
            "Iteration 16, loss = 1.13529868\n",
            "Iteration 17, loss = 1.09432441\n",
            "Iteration 18, loss = 1.05479898\n",
            "Iteration 19, loss = 1.01187288\n",
            "Iteration 20, loss = 0.96827780\n",
            "Iteration 21, loss = 0.92863090\n",
            "Iteration 22, loss = 0.88421505\n",
            "Iteration 23, loss = 0.84220542\n",
            "Iteration 24, loss = 0.79734634\n",
            "Iteration 25, loss = 0.75867829\n",
            "Iteration 26, loss = 0.71671254\n",
            "Iteration 27, loss = 0.67789855\n",
            "Iteration 28, loss = 0.63910451\n",
            "Iteration 29, loss = 0.60144541\n",
            "Iteration 30, loss = 0.56722815\n",
            "Iteration 31, loss = 0.53113349\n",
            "Iteration 32, loss = 0.49884009\n",
            "Iteration 33, loss = 0.46860084\n",
            "Iteration 34, loss = 0.43842790\n",
            "Iteration 35, loss = 0.40946566\n",
            "Iteration 36, loss = 0.38144477\n",
            "Iteration 37, loss = 0.35809127\n",
            "Iteration 38, loss = 0.33461461\n",
            "Iteration 39, loss = 0.31174546\n",
            "Iteration 40, loss = 0.29153438\n",
            "Iteration 41, loss = 0.27265333\n",
            "Iteration 42, loss = 0.25400166\n",
            "Iteration 43, loss = 0.23720639\n",
            "Iteration 44, loss = 0.22213097\n",
            "Iteration 45, loss = 0.20760112\n",
            "Iteration 46, loss = 0.19416724\n",
            "Iteration 47, loss = 0.18205874\n",
            "Iteration 48, loss = 0.17078597\n",
            "Iteration 49, loss = 0.15941628\n",
            "Iteration 50, loss = 0.14988744\n",
            "#### Outer Iteration 5 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01662698\n",
            "Iteration 2, loss = 1.70927904\n",
            "Iteration 3, loss = 1.62205042\n",
            "Iteration 4, loss = 1.56167387\n",
            "Iteration 5, loss = 1.51768703\n",
            "Iteration 6, loss = 1.48644966\n",
            "Iteration 7, loss = 1.45295411\n",
            "Iteration 8, loss = 1.41696270\n",
            "Iteration 9, loss = 1.38593933\n",
            "Iteration 10, loss = 1.34964177\n",
            "Iteration 11, loss = 1.32300812\n",
            "Iteration 12, loss = 1.28361472\n",
            "Iteration 13, loss = 1.24966250\n",
            "Iteration 14, loss = 1.21264031\n",
            "Iteration 15, loss = 1.17390861\n",
            "Iteration 16, loss = 1.13123944\n",
            "Iteration 17, loss = 1.09205005\n",
            "Iteration 18, loss = 1.05179841\n",
            "Iteration 19, loss = 1.01287228\n",
            "Iteration 20, loss = 0.96873445\n",
            "Iteration 21, loss = 0.92708848\n",
            "Iteration 22, loss = 0.88452932\n",
            "Iteration 23, loss = 0.84135490\n",
            "Iteration 24, loss = 0.80173827\n",
            "Iteration 25, loss = 0.75665495\n",
            "Iteration 26, loss = 0.71660194\n",
            "Iteration 27, loss = 0.67811346\n",
            "Iteration 28, loss = 0.63708958\n",
            "Iteration 29, loss = 0.59961094\n",
            "Iteration 30, loss = 0.56660907\n",
            "Iteration 31, loss = 0.53063743\n",
            "Iteration 32, loss = 0.49940583\n",
            "Iteration 33, loss = 0.46672151\n",
            "Iteration 34, loss = 0.43925757\n",
            "Iteration 35, loss = 0.40718490\n",
            "Iteration 36, loss = 0.38092933\n",
            "Iteration 37, loss = 0.35750260\n",
            "Iteration 38, loss = 0.33244905\n",
            "Iteration 39, loss = 0.31099643\n",
            "Iteration 40, loss = 0.29018186\n",
            "Iteration 41, loss = 0.27142264\n",
            "Iteration 42, loss = 0.25324046\n",
            "Iteration 43, loss = 0.23615609\n",
            "Iteration 44, loss = 0.22084547\n",
            "Iteration 45, loss = 0.20817065\n",
            "Iteration 46, loss = 0.19443910\n",
            "Iteration 47, loss = 0.18203885\n",
            "Iteration 48, loss = 0.17082332\n",
            "Iteration 49, loss = 0.15933199\n",
            "Iteration 50, loss = 0.15098118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00862629\n",
            "Iteration 2, loss = 1.71900782\n",
            "Iteration 3, loss = 1.62221626\n",
            "Iteration 4, loss = 1.56610239\n",
            "Iteration 5, loss = 1.52230190\n",
            "Iteration 6, loss = 1.48933160\n",
            "Iteration 7, loss = 1.45777321\n",
            "Iteration 8, loss = 1.42446154\n",
            "Iteration 9, loss = 1.39309836\n",
            "Iteration 10, loss = 1.36116170\n",
            "Iteration 11, loss = 1.32860345\n",
            "Iteration 12, loss = 1.29318233\n",
            "Iteration 13, loss = 1.25816963\n",
            "Iteration 14, loss = 1.22164723\n",
            "Iteration 15, loss = 1.18245850\n",
            "Iteration 16, loss = 1.14203854\n",
            "Iteration 17, loss = 1.10028082\n",
            "Iteration 18, loss = 1.06210691\n",
            "Iteration 19, loss = 1.01917028\n",
            "Iteration 20, loss = 0.97478805\n",
            "Iteration 21, loss = 0.93321413\n",
            "Iteration 22, loss = 0.88936425\n",
            "Iteration 23, loss = 0.84708631\n",
            "Iteration 24, loss = 0.80441684\n",
            "Iteration 25, loss = 0.76488308\n",
            "Iteration 26, loss = 0.72477437\n",
            "Iteration 27, loss = 0.68462029\n",
            "Iteration 28, loss = 0.64403689\n",
            "Iteration 29, loss = 0.60590638\n",
            "Iteration 30, loss = 0.57200452\n",
            "Iteration 31, loss = 0.53473319\n",
            "Iteration 32, loss = 0.50246420\n",
            "Iteration 33, loss = 0.47000507\n",
            "Iteration 34, loss = 0.44010208\n",
            "Iteration 35, loss = 0.41062589\n",
            "Iteration 36, loss = 0.38494774\n",
            "Iteration 37, loss = 0.35991702\n",
            "Iteration 38, loss = 0.33583443\n",
            "Iteration 39, loss = 0.31406269\n",
            "Iteration 40, loss = 0.29377965\n",
            "Iteration 41, loss = 0.27401596\n",
            "Iteration 42, loss = 0.25644758\n",
            "Iteration 43, loss = 0.23929381\n",
            "Iteration 44, loss = 0.22247657\n",
            "Iteration 45, loss = 0.20813870\n",
            "Iteration 46, loss = 0.19463744\n",
            "Iteration 47, loss = 0.18270542\n",
            "Iteration 48, loss = 0.17119960\n",
            "Iteration 49, loss = 0.16048469\n",
            "Iteration 50, loss = 0.15096786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02552241\n",
            "Iteration 2, loss = 1.71070849\n",
            "Iteration 3, loss = 1.61743425\n",
            "Iteration 4, loss = 1.56173914\n",
            "Iteration 5, loss = 1.52286659\n",
            "Iteration 6, loss = 1.48656791\n",
            "Iteration 7, loss = 1.45380108\n",
            "Iteration 8, loss = 1.42802967\n",
            "Iteration 9, loss = 1.39612615\n",
            "Iteration 10, loss = 1.35822626\n",
            "Iteration 11, loss = 1.32244783\n",
            "Iteration 12, loss = 1.29147393\n",
            "Iteration 13, loss = 1.25719906\n",
            "Iteration 14, loss = 1.21674334\n",
            "Iteration 15, loss = 1.17825087\n",
            "Iteration 16, loss = 1.14062376\n",
            "Iteration 17, loss = 1.10167065\n",
            "Iteration 18, loss = 1.05943888\n",
            "Iteration 19, loss = 1.01888434\n",
            "Iteration 20, loss = 0.97627460\n",
            "Iteration 21, loss = 0.93291334\n",
            "Iteration 22, loss = 0.89367489\n",
            "Iteration 23, loss = 0.84883099\n",
            "Iteration 24, loss = 0.80537902\n",
            "Iteration 25, loss = 0.76243302\n",
            "Iteration 26, loss = 0.72349766\n",
            "Iteration 27, loss = 0.68214302\n",
            "Iteration 28, loss = 0.64390436\n",
            "Iteration 29, loss = 0.60686284\n",
            "Iteration 30, loss = 0.56923241\n",
            "Iteration 31, loss = 0.53633006\n",
            "Iteration 32, loss = 0.50228710\n",
            "Iteration 33, loss = 0.47147806\n",
            "Iteration 34, loss = 0.44197758\n",
            "Iteration 35, loss = 0.41231356\n",
            "Iteration 36, loss = 0.38657417\n",
            "Iteration 37, loss = 0.36067785\n",
            "Iteration 38, loss = 0.33603905\n",
            "Iteration 39, loss = 0.31520108\n",
            "Iteration 40, loss = 0.29414576\n",
            "Iteration 41, loss = 0.27484363\n",
            "Iteration 42, loss = 0.25640217\n",
            "Iteration 43, loss = 0.23951837\n",
            "Iteration 44, loss = 0.22523027\n",
            "Iteration 45, loss = 0.21015068\n",
            "Iteration 46, loss = 0.19592972\n",
            "Iteration 47, loss = 0.18361876\n",
            "Iteration 48, loss = 0.17253041\n",
            "Iteration 49, loss = 0.16194065\n",
            "Iteration 50, loss = 0.15176266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01899363\n",
            "Iteration 2, loss = 1.72110749\n",
            "Iteration 3, loss = 1.62252624\n",
            "Iteration 4, loss = 1.56973218\n",
            "Iteration 5, loss = 1.52351857\n",
            "Iteration 6, loss = 1.49301488\n",
            "Iteration 7, loss = 1.45824170\n",
            "Iteration 8, loss = 1.42713639\n",
            "Iteration 9, loss = 1.39329177\n",
            "Iteration 10, loss = 1.36334068\n",
            "Iteration 11, loss = 1.32772835\n",
            "Iteration 12, loss = 1.29424063\n",
            "Iteration 13, loss = 1.25497855\n",
            "Iteration 14, loss = 1.21596902\n",
            "Iteration 15, loss = 1.18298434\n",
            "Iteration 16, loss = 1.13959389\n",
            "Iteration 17, loss = 1.10202957\n",
            "Iteration 18, loss = 1.05926585\n",
            "Iteration 19, loss = 1.01469365\n",
            "Iteration 20, loss = 0.97210156\n",
            "Iteration 21, loss = 0.93174439\n",
            "Iteration 22, loss = 0.88784635\n",
            "Iteration 23, loss = 0.84363675\n",
            "Iteration 24, loss = 0.80032784\n",
            "Iteration 25, loss = 0.75958142\n",
            "Iteration 26, loss = 0.72263037\n",
            "Iteration 27, loss = 0.67721283\n",
            "Iteration 28, loss = 0.64043811\n",
            "Iteration 29, loss = 0.60222635\n",
            "Iteration 30, loss = 0.56585757\n",
            "Iteration 31, loss = 0.53009658\n",
            "Iteration 32, loss = 0.49614999\n",
            "Iteration 33, loss = 0.46509554\n",
            "Iteration 34, loss = 0.43494196\n",
            "Iteration 35, loss = 0.40622744\n",
            "Iteration 36, loss = 0.37944737\n",
            "Iteration 37, loss = 0.35362201\n",
            "Iteration 38, loss = 0.33166241\n",
            "Iteration 39, loss = 0.30809746\n",
            "Iteration 40, loss = 0.28772530\n",
            "Iteration 41, loss = 0.26821981\n",
            "Iteration 42, loss = 0.25010852\n",
            "Iteration 43, loss = 0.23433271\n",
            "Iteration 44, loss = 0.21868264\n",
            "Iteration 45, loss = 0.20466709\n",
            "Iteration 46, loss = 0.19167372\n",
            "Iteration 47, loss = 0.17943151\n",
            "Iteration 48, loss = 0.16762748\n",
            "Iteration 49, loss = 0.15736232\n",
            "Iteration 50, loss = 0.14786516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03663452\n",
            "Iteration 2, loss = 1.71826648\n",
            "Iteration 3, loss = 1.61911974\n",
            "Iteration 4, loss = 1.56699711\n",
            "Iteration 5, loss = 1.52661290\n",
            "Iteration 6, loss = 1.48791489\n",
            "Iteration 7, loss = 1.45917676\n",
            "Iteration 8, loss = 1.42288979\n",
            "Iteration 9, loss = 1.39759969\n",
            "Iteration 10, loss = 1.36758068\n",
            "Iteration 11, loss = 1.33052355\n",
            "Iteration 12, loss = 1.29652568\n",
            "Iteration 13, loss = 1.26278902\n",
            "Iteration 14, loss = 1.22254928\n",
            "Iteration 15, loss = 1.18416694\n",
            "Iteration 16, loss = 1.14569162\n",
            "Iteration 17, loss = 1.10837198\n",
            "Iteration 18, loss = 1.06579929\n",
            "Iteration 19, loss = 1.02588018\n",
            "Iteration 20, loss = 0.98439782\n",
            "Iteration 21, loss = 0.94077307\n",
            "Iteration 22, loss = 0.90013124\n",
            "Iteration 23, loss = 0.85926929\n",
            "Iteration 24, loss = 0.81564590\n",
            "Iteration 25, loss = 0.77522316\n",
            "Iteration 26, loss = 0.73469544\n",
            "Iteration 27, loss = 0.69278603\n",
            "Iteration 28, loss = 0.65790579\n",
            "Iteration 29, loss = 0.61811899\n",
            "Iteration 30, loss = 0.58291028\n",
            "Iteration 31, loss = 0.54456306\n",
            "Iteration 32, loss = 0.51137243\n",
            "Iteration 33, loss = 0.47910110\n",
            "Iteration 34, loss = 0.45018140\n",
            "Iteration 35, loss = 0.41967196\n",
            "Iteration 36, loss = 0.39218234\n",
            "Iteration 37, loss = 0.36692276\n",
            "Iteration 38, loss = 0.34308137\n",
            "Iteration 39, loss = 0.31945849\n",
            "Iteration 40, loss = 0.29800223\n",
            "Iteration 41, loss = 0.27919761\n",
            "Iteration 42, loss = 0.26009433\n",
            "Iteration 43, loss = 0.24306802\n",
            "Iteration 44, loss = 0.22780733\n",
            "Iteration 45, loss = 0.21349222\n",
            "Iteration 46, loss = 0.19906869\n",
            "Iteration 47, loss = 0.18638399\n",
            "Iteration 48, loss = 0.17485611\n",
            "Iteration 49, loss = 0.16377199\n",
            "Iteration 50, loss = 0.15478318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03871996\n",
            "Iteration 2, loss = 1.71934218\n",
            "Iteration 3, loss = 1.62292167\n",
            "Iteration 4, loss = 1.56668997\n",
            "Iteration 5, loss = 1.52403060\n",
            "Iteration 6, loss = 1.49228232\n",
            "Iteration 7, loss = 1.45894598\n",
            "Iteration 8, loss = 1.42510412\n",
            "Iteration 9, loss = 1.39664466\n",
            "Iteration 10, loss = 1.36177082\n",
            "Iteration 11, loss = 1.32984934\n",
            "Iteration 12, loss = 1.29673090\n",
            "Iteration 13, loss = 1.26238042\n",
            "Iteration 14, loss = 1.21827258\n",
            "Iteration 15, loss = 1.18559962\n",
            "Iteration 16, loss = 1.14704112\n",
            "Iteration 17, loss = 1.10609068\n",
            "Iteration 18, loss = 1.06058355\n",
            "Iteration 19, loss = 1.02189122\n",
            "Iteration 20, loss = 0.97965511\n",
            "Iteration 21, loss = 0.93739851\n",
            "Iteration 22, loss = 0.89265551\n",
            "Iteration 23, loss = 0.84990548\n",
            "Iteration 24, loss = 0.80624541\n",
            "Iteration 25, loss = 0.76739786\n",
            "Iteration 26, loss = 0.72298683\n",
            "Iteration 27, loss = 0.68199776\n",
            "Iteration 28, loss = 0.64525974\n",
            "Iteration 29, loss = 0.60689316\n",
            "Iteration 30, loss = 0.57153642\n",
            "Iteration 31, loss = 0.53504578\n",
            "Iteration 32, loss = 0.50302871\n",
            "Iteration 33, loss = 0.46837277\n",
            "Iteration 34, loss = 0.43900218\n",
            "Iteration 35, loss = 0.40976191\n",
            "Iteration 36, loss = 0.38432437\n",
            "Iteration 37, loss = 0.35804241\n",
            "Iteration 38, loss = 0.33522612\n",
            "Iteration 39, loss = 0.31250231\n",
            "Iteration 40, loss = 0.29258503\n",
            "Iteration 41, loss = 0.27274734\n",
            "Iteration 42, loss = 0.25420397\n",
            "Iteration 43, loss = 0.23712732\n",
            "Iteration 44, loss = 0.22102134\n",
            "Iteration 45, loss = 0.20686099\n",
            "Iteration 46, loss = 0.19384846\n",
            "Iteration 47, loss = 0.18189315\n",
            "Iteration 48, loss = 0.17040066\n",
            "Iteration 49, loss = 0.15916610\n",
            "Iteration 50, loss = 0.14972616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03289752\n",
            "Iteration 2, loss = 1.71557982\n",
            "Iteration 3, loss = 1.62255887\n",
            "Iteration 4, loss = 1.56978363\n",
            "Iteration 5, loss = 1.53089001\n",
            "Iteration 6, loss = 1.49256352\n",
            "Iteration 7, loss = 1.45779606\n",
            "Iteration 8, loss = 1.42345125\n",
            "Iteration 9, loss = 1.39903514\n",
            "Iteration 10, loss = 1.36186665\n",
            "Iteration 11, loss = 1.33171984\n",
            "Iteration 12, loss = 1.29698019\n",
            "Iteration 13, loss = 1.25792818\n",
            "Iteration 14, loss = 1.22260571\n",
            "Iteration 15, loss = 1.18222016\n",
            "Iteration 16, loss = 1.14698826\n",
            "Iteration 17, loss = 1.10166988\n",
            "Iteration 18, loss = 1.06373856\n",
            "Iteration 19, loss = 1.02231515\n",
            "Iteration 20, loss = 0.97780936\n",
            "Iteration 21, loss = 0.93401827\n",
            "Iteration 22, loss = 0.89601409\n",
            "Iteration 23, loss = 0.85128171\n",
            "Iteration 24, loss = 0.80810334\n",
            "Iteration 25, loss = 0.76648247\n",
            "Iteration 26, loss = 0.72492405\n",
            "Iteration 27, loss = 0.68496871\n",
            "Iteration 28, loss = 0.64659451\n",
            "Iteration 29, loss = 0.60879148\n",
            "Iteration 30, loss = 0.57161922\n",
            "Iteration 31, loss = 0.53779439\n",
            "Iteration 32, loss = 0.50406715\n",
            "Iteration 33, loss = 0.47104114\n",
            "Iteration 34, loss = 0.44077017\n",
            "Iteration 35, loss = 0.41263100\n",
            "Iteration 36, loss = 0.38562191\n",
            "Iteration 37, loss = 0.36130392\n",
            "Iteration 38, loss = 0.33750392\n",
            "Iteration 39, loss = 0.31501618\n",
            "Iteration 40, loss = 0.29401575\n",
            "Iteration 41, loss = 0.27376175\n",
            "Iteration 42, loss = 0.25604399\n",
            "Iteration 43, loss = 0.23960192\n",
            "Iteration 44, loss = 0.22349664\n",
            "Iteration 45, loss = 0.20994008\n",
            "Iteration 46, loss = 0.19582676\n",
            "Iteration 47, loss = 0.18347307\n",
            "Iteration 48, loss = 0.17213128\n",
            "Iteration 49, loss = 0.16116378\n",
            "Iteration 50, loss = 0.15138555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02751491\n",
            "Iteration 2, loss = 1.71608407\n",
            "Iteration 3, loss = 1.61512915\n",
            "Iteration 4, loss = 1.56104841\n",
            "Iteration 5, loss = 1.51814021\n",
            "Iteration 6, loss = 1.48318074\n",
            "Iteration 7, loss = 1.45014096\n",
            "Iteration 8, loss = 1.42360603\n",
            "Iteration 9, loss = 1.38676332\n",
            "Iteration 10, loss = 1.35322726\n",
            "Iteration 11, loss = 1.32063449\n",
            "Iteration 12, loss = 1.28842570\n",
            "Iteration 13, loss = 1.24812161\n",
            "Iteration 14, loss = 1.21439883\n",
            "Iteration 15, loss = 1.17327403\n",
            "Iteration 16, loss = 1.13207675\n",
            "Iteration 17, loss = 1.09320082\n",
            "Iteration 18, loss = 1.05376842\n",
            "Iteration 19, loss = 1.01176421\n",
            "Iteration 20, loss = 0.96893103\n",
            "Iteration 21, loss = 0.92738512\n",
            "Iteration 22, loss = 0.88558052\n",
            "Iteration 23, loss = 0.84099305\n",
            "Iteration 24, loss = 0.80127877\n",
            "Iteration 25, loss = 0.75742359\n",
            "Iteration 26, loss = 0.71871734\n",
            "Iteration 27, loss = 0.67797052\n",
            "Iteration 28, loss = 0.63636654\n",
            "Iteration 29, loss = 0.60061134\n",
            "Iteration 30, loss = 0.56571493\n",
            "Iteration 31, loss = 0.52956362\n",
            "Iteration 32, loss = 0.49731837\n",
            "Iteration 33, loss = 0.46454154\n",
            "Iteration 34, loss = 0.43590073\n",
            "Iteration 35, loss = 0.40755392\n",
            "Iteration 36, loss = 0.37967307\n",
            "Iteration 37, loss = 0.35516860\n",
            "Iteration 38, loss = 0.33202345\n",
            "Iteration 39, loss = 0.30961520\n",
            "Iteration 40, loss = 0.28862332\n",
            "Iteration 41, loss = 0.27082536\n",
            "Iteration 42, loss = 0.25279578\n",
            "Iteration 43, loss = 0.23566843\n",
            "Iteration 44, loss = 0.22047295\n",
            "Iteration 45, loss = 0.20596851\n",
            "Iteration 46, loss = 0.19295844\n",
            "Iteration 47, loss = 0.18051440\n",
            "Iteration 48, loss = 0.16917181\n",
            "Iteration 49, loss = 0.15913726\n",
            "Iteration 50, loss = 0.14878407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01438773\n",
            "Iteration 2, loss = 1.71364556\n",
            "Iteration 3, loss = 1.61987825\n",
            "Iteration 4, loss = 1.56219679\n",
            "Iteration 5, loss = 1.52273998\n",
            "Iteration 6, loss = 1.48669923\n",
            "Iteration 7, loss = 1.45407111\n",
            "Iteration 8, loss = 1.42020801\n",
            "Iteration 9, loss = 1.38696368\n",
            "Iteration 10, loss = 1.35299451\n",
            "Iteration 11, loss = 1.31976278\n",
            "Iteration 12, loss = 1.28276244\n",
            "Iteration 13, loss = 1.24712869\n",
            "Iteration 14, loss = 1.21385611\n",
            "Iteration 15, loss = 1.17083781\n",
            "Iteration 16, loss = 1.13102334\n",
            "Iteration 17, loss = 1.08887586\n",
            "Iteration 18, loss = 1.04792487\n",
            "Iteration 19, loss = 1.00564256\n",
            "Iteration 20, loss = 0.96715082\n",
            "Iteration 21, loss = 0.92035568\n",
            "Iteration 22, loss = 0.87763482\n",
            "Iteration 23, loss = 0.83479654\n",
            "Iteration 24, loss = 0.79212891\n",
            "Iteration 25, loss = 0.75156085\n",
            "Iteration 26, loss = 0.71420438\n",
            "Iteration 27, loss = 0.67440914\n",
            "Iteration 28, loss = 0.63191890\n",
            "Iteration 29, loss = 0.59629545\n",
            "Iteration 30, loss = 0.55890561\n",
            "Iteration 31, loss = 0.52510811\n",
            "Iteration 32, loss = 0.49249922\n",
            "Iteration 33, loss = 0.46029154\n",
            "Iteration 34, loss = 0.43070734\n",
            "Iteration 35, loss = 0.40302999\n",
            "Iteration 36, loss = 0.37585519\n",
            "Iteration 37, loss = 0.35083934\n",
            "Iteration 38, loss = 0.32905113\n",
            "Iteration 39, loss = 0.30697018\n",
            "Iteration 40, loss = 0.28673314\n",
            "Iteration 41, loss = 0.26737826\n",
            "Iteration 42, loss = 0.25045420\n",
            "Iteration 43, loss = 0.23384039\n",
            "Iteration 44, loss = 0.22004363\n",
            "Iteration 45, loss = 0.20433085\n",
            "Iteration 46, loss = 0.19160964\n",
            "Iteration 47, loss = 0.17871413\n",
            "Iteration 48, loss = 0.16785584\n",
            "Iteration 49, loss = 0.15697191\n",
            "Iteration 50, loss = 0.14828007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00523212\n",
            "Iteration 2, loss = 1.71367182\n",
            "Iteration 3, loss = 1.61589580\n",
            "Iteration 4, loss = 1.55717528\n",
            "Iteration 5, loss = 1.51598502\n",
            "Iteration 6, loss = 1.48799816\n",
            "Iteration 7, loss = 1.44987512\n",
            "Iteration 8, loss = 1.41766023\n",
            "Iteration 9, loss = 1.38593814\n",
            "Iteration 10, loss = 1.35454529\n",
            "Iteration 11, loss = 1.31882729\n",
            "Iteration 12, loss = 1.28706950\n",
            "Iteration 13, loss = 1.24862944\n",
            "Iteration 14, loss = 1.21411011\n",
            "Iteration 15, loss = 1.17412347\n",
            "Iteration 16, loss = 1.13050506\n",
            "Iteration 17, loss = 1.09000761\n",
            "Iteration 18, loss = 1.05004221\n",
            "Iteration 19, loss = 1.00625272\n",
            "Iteration 20, loss = 0.96582668\n",
            "Iteration 21, loss = 0.92508330\n",
            "Iteration 22, loss = 0.87981477\n",
            "Iteration 23, loss = 0.84005475\n",
            "Iteration 24, loss = 0.79875380\n",
            "Iteration 25, loss = 0.75604692\n",
            "Iteration 26, loss = 0.71231484\n",
            "Iteration 27, loss = 0.67806910\n",
            "Iteration 28, loss = 0.63814863\n",
            "Iteration 29, loss = 0.60213444\n",
            "Iteration 30, loss = 0.56494125\n",
            "Iteration 31, loss = 0.52905812\n",
            "Iteration 32, loss = 0.49907228\n",
            "Iteration 33, loss = 0.47002626\n",
            "Iteration 34, loss = 0.43583423\n",
            "Iteration 35, loss = 0.40824226\n",
            "Iteration 36, loss = 0.38282421\n",
            "Iteration 37, loss = 0.35867850\n",
            "Iteration 38, loss = 0.33440501\n",
            "Iteration 39, loss = 0.31306630\n",
            "Iteration 40, loss = 0.29292694\n",
            "Iteration 41, loss = 0.27332781\n",
            "Iteration 42, loss = 0.25563754\n",
            "Iteration 43, loss = 0.23834963\n",
            "Iteration 44, loss = 0.22311243\n",
            "Iteration 45, loss = 0.20872968\n",
            "Iteration 46, loss = 0.19581248\n",
            "Iteration 47, loss = 0.18286248\n",
            "Iteration 48, loss = 0.17148651\n",
            "Iteration 49, loss = 0.16043885\n",
            "Iteration 50, loss = 0.15115140\n",
            "#### Outer Iteration 6 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03524012\n",
            "Iteration 2, loss = 1.71454328\n",
            "Iteration 3, loss = 1.61795351\n",
            "Iteration 4, loss = 1.56420438\n",
            "Iteration 5, loss = 1.51992980\n",
            "Iteration 6, loss = 1.48320046\n",
            "Iteration 7, loss = 1.45443437\n",
            "Iteration 8, loss = 1.42126525\n",
            "Iteration 9, loss = 1.39238006\n",
            "Iteration 10, loss = 1.36096715\n",
            "Iteration 11, loss = 1.33129034\n",
            "Iteration 12, loss = 1.29175119\n",
            "Iteration 13, loss = 1.25824793\n",
            "Iteration 14, loss = 1.22244501\n",
            "Iteration 15, loss = 1.17835993\n",
            "Iteration 16, loss = 1.14174857\n",
            "Iteration 17, loss = 1.10405339\n",
            "Iteration 18, loss = 1.05968575\n",
            "Iteration 19, loss = 1.01617134\n",
            "Iteration 20, loss = 0.97537328\n",
            "Iteration 21, loss = 0.93476802\n",
            "Iteration 22, loss = 0.89138551\n",
            "Iteration 23, loss = 0.84968195\n",
            "Iteration 24, loss = 0.80518976\n",
            "Iteration 25, loss = 0.76510187\n",
            "Iteration 26, loss = 0.72243227\n",
            "Iteration 27, loss = 0.68470352\n",
            "Iteration 28, loss = 0.64470195\n",
            "Iteration 29, loss = 0.60711938\n",
            "Iteration 30, loss = 0.57074032\n",
            "Iteration 31, loss = 0.53580322\n",
            "Iteration 32, loss = 0.50310716\n",
            "Iteration 33, loss = 0.46892460\n",
            "Iteration 34, loss = 0.43943342\n",
            "Iteration 35, loss = 0.41231468\n",
            "Iteration 36, loss = 0.38503473\n",
            "Iteration 37, loss = 0.36047617\n",
            "Iteration 38, loss = 0.33722470\n",
            "Iteration 39, loss = 0.31409016\n",
            "Iteration 40, loss = 0.29319409\n",
            "Iteration 41, loss = 0.27341883\n",
            "Iteration 42, loss = 0.25481616\n",
            "Iteration 43, loss = 0.23892711\n",
            "Iteration 44, loss = 0.22324775\n",
            "Iteration 45, loss = 0.20796274\n",
            "Iteration 46, loss = 0.19551559\n",
            "Iteration 47, loss = 0.18182857\n",
            "Iteration 48, loss = 0.17115828\n",
            "Iteration 49, loss = 0.15998028\n",
            "Iteration 50, loss = 0.15025494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02079114\n",
            "Iteration 2, loss = 1.71835931\n",
            "Iteration 3, loss = 1.62068311\n",
            "Iteration 4, loss = 1.56604702\n",
            "Iteration 5, loss = 1.52676517\n",
            "Iteration 6, loss = 1.49382264\n",
            "Iteration 7, loss = 1.45740149\n",
            "Iteration 8, loss = 1.42738570\n",
            "Iteration 9, loss = 1.40010336\n",
            "Iteration 10, loss = 1.36192983\n",
            "Iteration 11, loss = 1.33196035\n",
            "Iteration 12, loss = 1.29596036\n",
            "Iteration 13, loss = 1.25928089\n",
            "Iteration 14, loss = 1.22240512\n",
            "Iteration 15, loss = 1.18434866\n",
            "Iteration 16, loss = 1.14624682\n",
            "Iteration 17, loss = 1.10556340\n",
            "Iteration 18, loss = 1.06723504\n",
            "Iteration 19, loss = 1.02641026\n",
            "Iteration 20, loss = 0.98211677\n",
            "Iteration 21, loss = 0.93737382\n",
            "Iteration 22, loss = 0.89596210\n",
            "Iteration 23, loss = 0.85427392\n",
            "Iteration 24, loss = 0.81202085\n",
            "Iteration 25, loss = 0.76927853\n",
            "Iteration 26, loss = 0.72951426\n",
            "Iteration 27, loss = 0.69106275\n",
            "Iteration 28, loss = 0.65139781\n",
            "Iteration 29, loss = 0.61389795\n",
            "Iteration 30, loss = 0.57812178\n",
            "Iteration 31, loss = 0.54187540\n",
            "Iteration 32, loss = 0.51052944\n",
            "Iteration 33, loss = 0.47726348\n",
            "Iteration 34, loss = 0.44973431\n",
            "Iteration 35, loss = 0.41992953\n",
            "Iteration 36, loss = 0.39219377\n",
            "Iteration 37, loss = 0.36788928\n",
            "Iteration 38, loss = 0.34397696\n",
            "Iteration 39, loss = 0.32158142\n",
            "Iteration 40, loss = 0.30015477\n",
            "Iteration 41, loss = 0.28039215\n",
            "Iteration 42, loss = 0.26327670\n",
            "Iteration 43, loss = 0.24590991\n",
            "Iteration 44, loss = 0.22970834\n",
            "Iteration 45, loss = 0.21455812\n",
            "Iteration 46, loss = 0.20268340\n",
            "Iteration 47, loss = 0.18864859\n",
            "Iteration 48, loss = 0.17674681\n",
            "Iteration 49, loss = 0.16599731\n",
            "Iteration 50, loss = 0.15581847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01861654\n",
            "Iteration 2, loss = 1.71476166\n",
            "Iteration 3, loss = 1.61972841\n",
            "Iteration 4, loss = 1.56444360\n",
            "Iteration 5, loss = 1.53028882\n",
            "Iteration 6, loss = 1.49210207\n",
            "Iteration 7, loss = 1.45653201\n",
            "Iteration 8, loss = 1.42541353\n",
            "Iteration 9, loss = 1.39390537\n",
            "Iteration 10, loss = 1.35887339\n",
            "Iteration 11, loss = 1.33032242\n",
            "Iteration 12, loss = 1.29234304\n",
            "Iteration 13, loss = 1.25591137\n",
            "Iteration 14, loss = 1.21996502\n",
            "Iteration 15, loss = 1.17862428\n",
            "Iteration 16, loss = 1.14357376\n",
            "Iteration 17, loss = 1.09804430\n",
            "Iteration 18, loss = 1.05683498\n",
            "Iteration 19, loss = 1.01646612\n",
            "Iteration 20, loss = 0.97409401\n",
            "Iteration 21, loss = 0.92934267\n",
            "Iteration 22, loss = 0.88784148\n",
            "Iteration 23, loss = 0.84910041\n",
            "Iteration 24, loss = 0.80077556\n",
            "Iteration 25, loss = 0.75786725\n",
            "Iteration 26, loss = 0.71593036\n",
            "Iteration 27, loss = 0.67733061\n",
            "Iteration 28, loss = 0.63977300\n",
            "Iteration 29, loss = 0.60006597\n",
            "Iteration 30, loss = 0.56747387\n",
            "Iteration 31, loss = 0.52904173\n",
            "Iteration 32, loss = 0.49554696\n",
            "Iteration 33, loss = 0.46466572\n",
            "Iteration 34, loss = 0.43478663\n",
            "Iteration 35, loss = 0.40629280\n",
            "Iteration 36, loss = 0.37972506\n",
            "Iteration 37, loss = 0.35479311\n",
            "Iteration 38, loss = 0.33078296\n",
            "Iteration 39, loss = 0.30769900\n",
            "Iteration 40, loss = 0.28811780\n",
            "Iteration 41, loss = 0.26874692\n",
            "Iteration 42, loss = 0.25085490\n",
            "Iteration 43, loss = 0.23452786\n",
            "Iteration 44, loss = 0.21948391\n",
            "Iteration 45, loss = 0.20470444\n",
            "Iteration 46, loss = 0.19157874\n",
            "Iteration 47, loss = 0.17974557\n",
            "Iteration 48, loss = 0.16917876\n",
            "Iteration 49, loss = 0.15797679\n",
            "Iteration 50, loss = 0.14783382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01285924\n",
            "Iteration 2, loss = 1.71024467\n",
            "Iteration 3, loss = 1.61160317\n",
            "Iteration 4, loss = 1.55954767\n",
            "Iteration 5, loss = 1.52345851\n",
            "Iteration 6, loss = 1.48508601\n",
            "Iteration 7, loss = 1.44921026\n",
            "Iteration 8, loss = 1.42060579\n",
            "Iteration 9, loss = 1.38385469\n",
            "Iteration 10, loss = 1.35707363\n",
            "Iteration 11, loss = 1.32463766\n",
            "Iteration 12, loss = 1.28458257\n",
            "Iteration 13, loss = 1.25007997\n",
            "Iteration 14, loss = 1.21197802\n",
            "Iteration 15, loss = 1.17407693\n",
            "Iteration 16, loss = 1.13367836\n",
            "Iteration 17, loss = 1.09535398\n",
            "Iteration 18, loss = 1.05746942\n",
            "Iteration 19, loss = 1.01361848\n",
            "Iteration 20, loss = 0.96766473\n",
            "Iteration 21, loss = 0.92714077\n",
            "Iteration 22, loss = 0.88683455\n",
            "Iteration 23, loss = 0.84021235\n",
            "Iteration 24, loss = 0.80295367\n",
            "Iteration 25, loss = 0.75834869\n",
            "Iteration 26, loss = 0.72010678\n",
            "Iteration 27, loss = 0.67975283\n",
            "Iteration 28, loss = 0.63938621\n",
            "Iteration 29, loss = 0.60135890\n",
            "Iteration 30, loss = 0.56592134\n",
            "Iteration 31, loss = 0.52843892\n",
            "Iteration 32, loss = 0.49820908\n",
            "Iteration 33, loss = 0.46579399\n",
            "Iteration 34, loss = 0.43663073\n",
            "Iteration 35, loss = 0.40948708\n",
            "Iteration 36, loss = 0.38154195\n",
            "Iteration 37, loss = 0.35627839\n",
            "Iteration 38, loss = 0.33399849\n",
            "Iteration 39, loss = 0.31181369\n",
            "Iteration 40, loss = 0.29125290\n",
            "Iteration 41, loss = 0.27283064\n",
            "Iteration 42, loss = 0.25400910\n",
            "Iteration 43, loss = 0.23738496\n",
            "Iteration 44, loss = 0.22328926\n",
            "Iteration 45, loss = 0.20922609\n",
            "Iteration 46, loss = 0.19467612\n",
            "Iteration 47, loss = 0.18280594\n",
            "Iteration 48, loss = 0.17074123\n",
            "Iteration 49, loss = 0.16026815\n",
            "Iteration 50, loss = 0.15067824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01571171\n",
            "Iteration 2, loss = 1.71300551\n",
            "Iteration 3, loss = 1.61575940\n",
            "Iteration 4, loss = 1.56244456\n",
            "Iteration 5, loss = 1.51921461\n",
            "Iteration 6, loss = 1.48519404\n",
            "Iteration 7, loss = 1.45190218\n",
            "Iteration 8, loss = 1.41983941\n",
            "Iteration 9, loss = 1.39053652\n",
            "Iteration 10, loss = 1.35591055\n",
            "Iteration 11, loss = 1.32398631\n",
            "Iteration 12, loss = 1.28840304\n",
            "Iteration 13, loss = 1.25073145\n",
            "Iteration 14, loss = 1.21296817\n",
            "Iteration 15, loss = 1.17641299\n",
            "Iteration 16, loss = 1.14187175\n",
            "Iteration 17, loss = 1.09819604\n",
            "Iteration 18, loss = 1.05612927\n",
            "Iteration 19, loss = 1.01179904\n",
            "Iteration 20, loss = 0.97281557\n",
            "Iteration 21, loss = 0.92567515\n",
            "Iteration 22, loss = 0.88667784\n",
            "Iteration 23, loss = 0.84264380\n",
            "Iteration 24, loss = 0.80282548\n",
            "Iteration 25, loss = 0.75863463\n",
            "Iteration 26, loss = 0.71650837\n",
            "Iteration 27, loss = 0.68086337\n",
            "Iteration 28, loss = 0.63766492\n",
            "Iteration 29, loss = 0.60149672\n",
            "Iteration 30, loss = 0.56602658\n",
            "Iteration 31, loss = 0.53020455\n",
            "Iteration 32, loss = 0.49957610\n",
            "Iteration 33, loss = 0.46836016\n",
            "Iteration 34, loss = 0.43797421\n",
            "Iteration 35, loss = 0.40807988\n",
            "Iteration 36, loss = 0.38230574\n",
            "Iteration 37, loss = 0.35891368\n",
            "Iteration 38, loss = 0.33464826\n",
            "Iteration 39, loss = 0.31281029\n",
            "Iteration 40, loss = 0.29207292\n",
            "Iteration 41, loss = 0.27240227\n",
            "Iteration 42, loss = 0.25307064\n",
            "Iteration 43, loss = 0.23719815\n",
            "Iteration 44, loss = 0.22254098\n",
            "Iteration 45, loss = 0.20834803\n",
            "Iteration 46, loss = 0.19434906\n",
            "Iteration 47, loss = 0.18248522\n",
            "Iteration 48, loss = 0.17011509\n",
            "Iteration 49, loss = 0.16014566\n",
            "Iteration 50, loss = 0.15063639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02534021\n",
            "Iteration 2, loss = 1.71404106\n",
            "Iteration 3, loss = 1.62322744\n",
            "Iteration 4, loss = 1.56753035\n",
            "Iteration 5, loss = 1.52765585\n",
            "Iteration 6, loss = 1.49206454\n",
            "Iteration 7, loss = 1.46270825\n",
            "Iteration 8, loss = 1.42953525\n",
            "Iteration 9, loss = 1.39883958\n",
            "Iteration 10, loss = 1.36614078\n",
            "Iteration 11, loss = 1.33254768\n",
            "Iteration 12, loss = 1.30078593\n",
            "Iteration 13, loss = 1.27074689\n",
            "Iteration 14, loss = 1.22779424\n",
            "Iteration 15, loss = 1.18947471\n",
            "Iteration 16, loss = 1.15174342\n",
            "Iteration 17, loss = 1.11054261\n",
            "Iteration 18, loss = 1.07264095\n",
            "Iteration 19, loss = 1.02758116\n",
            "Iteration 20, loss = 0.98773456\n",
            "Iteration 21, loss = 0.94451646\n",
            "Iteration 22, loss = 0.90433183\n",
            "Iteration 23, loss = 0.85992416\n",
            "Iteration 24, loss = 0.81864239\n",
            "Iteration 25, loss = 0.77656996\n",
            "Iteration 26, loss = 0.73763261\n",
            "Iteration 27, loss = 0.69748709\n",
            "Iteration 28, loss = 0.65814889\n",
            "Iteration 29, loss = 0.61842520\n",
            "Iteration 30, loss = 0.58401344\n",
            "Iteration 31, loss = 0.54890900\n",
            "Iteration 32, loss = 0.51401627\n",
            "Iteration 33, loss = 0.48206335\n",
            "Iteration 34, loss = 0.44874241\n",
            "Iteration 35, loss = 0.42171756\n",
            "Iteration 36, loss = 0.39276728\n",
            "Iteration 37, loss = 0.36689693\n",
            "Iteration 38, loss = 0.34228489\n",
            "Iteration 39, loss = 0.31989550\n",
            "Iteration 40, loss = 0.29852922\n",
            "Iteration 41, loss = 0.28022848\n",
            "Iteration 42, loss = 0.26056249\n",
            "Iteration 43, loss = 0.24359587\n",
            "Iteration 44, loss = 0.22739774\n",
            "Iteration 45, loss = 0.21228104\n",
            "Iteration 46, loss = 0.19954668\n",
            "Iteration 47, loss = 0.18579451\n",
            "Iteration 48, loss = 0.17512310\n",
            "Iteration 49, loss = 0.16346215\n",
            "Iteration 50, loss = 0.15360035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00552554\n",
            "Iteration 2, loss = 1.71549331\n",
            "Iteration 3, loss = 1.62004504\n",
            "Iteration 4, loss = 1.56130437\n",
            "Iteration 5, loss = 1.52292167\n",
            "Iteration 6, loss = 1.48106518\n",
            "Iteration 7, loss = 1.45163346\n",
            "Iteration 8, loss = 1.42272531\n",
            "Iteration 9, loss = 1.38770659\n",
            "Iteration 10, loss = 1.35285211\n",
            "Iteration 11, loss = 1.31837560\n",
            "Iteration 12, loss = 1.28821542\n",
            "Iteration 13, loss = 1.25304389\n",
            "Iteration 14, loss = 1.21202250\n",
            "Iteration 15, loss = 1.17624998\n",
            "Iteration 16, loss = 1.13634378\n",
            "Iteration 17, loss = 1.09686447\n",
            "Iteration 18, loss = 1.05779370\n",
            "Iteration 19, loss = 1.01721458\n",
            "Iteration 20, loss = 0.96971626\n",
            "Iteration 21, loss = 0.92830281\n",
            "Iteration 22, loss = 0.88630757\n",
            "Iteration 23, loss = 0.84422770\n",
            "Iteration 24, loss = 0.80063988\n",
            "Iteration 25, loss = 0.75795486\n",
            "Iteration 26, loss = 0.71779141\n",
            "Iteration 27, loss = 0.67985560\n",
            "Iteration 28, loss = 0.63891791\n",
            "Iteration 29, loss = 0.60257822\n",
            "Iteration 30, loss = 0.56549854\n",
            "Iteration 31, loss = 0.53149832\n",
            "Iteration 32, loss = 0.49847498\n",
            "Iteration 33, loss = 0.46692343\n",
            "Iteration 34, loss = 0.43768362\n",
            "Iteration 35, loss = 0.41100571\n",
            "Iteration 36, loss = 0.38228350\n",
            "Iteration 37, loss = 0.35702717\n",
            "Iteration 38, loss = 0.33407971\n",
            "Iteration 39, loss = 0.31276240\n",
            "Iteration 40, loss = 0.29056863\n",
            "Iteration 41, loss = 0.27315331\n",
            "Iteration 42, loss = 0.25484166\n",
            "Iteration 43, loss = 0.23833301\n",
            "Iteration 44, loss = 0.22210997\n",
            "Iteration 45, loss = 0.20843999\n",
            "Iteration 46, loss = 0.19515795\n",
            "Iteration 47, loss = 0.18239805\n",
            "Iteration 48, loss = 0.17065272\n",
            "Iteration 49, loss = 0.16038398\n",
            "Iteration 50, loss = 0.15063616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01711854\n",
            "Iteration 2, loss = 1.71684006\n",
            "Iteration 3, loss = 1.61684884\n",
            "Iteration 4, loss = 1.56466549\n",
            "Iteration 5, loss = 1.52178136\n",
            "Iteration 6, loss = 1.49039935\n",
            "Iteration 7, loss = 1.45387297\n",
            "Iteration 8, loss = 1.42423220\n",
            "Iteration 9, loss = 1.39331278\n",
            "Iteration 10, loss = 1.35778072\n",
            "Iteration 11, loss = 1.32543897\n",
            "Iteration 12, loss = 1.29004404\n",
            "Iteration 13, loss = 1.25493760\n",
            "Iteration 14, loss = 1.21869902\n",
            "Iteration 15, loss = 1.18172072\n",
            "Iteration 16, loss = 1.14039568\n",
            "Iteration 17, loss = 1.09675434\n",
            "Iteration 18, loss = 1.06176509\n",
            "Iteration 19, loss = 1.01810306\n",
            "Iteration 20, loss = 0.97376238\n",
            "Iteration 21, loss = 0.93137121\n",
            "Iteration 22, loss = 0.88937333\n",
            "Iteration 23, loss = 0.84222662\n",
            "Iteration 24, loss = 0.80505849\n",
            "Iteration 25, loss = 0.76048638\n",
            "Iteration 26, loss = 0.71850658\n",
            "Iteration 27, loss = 0.67744768\n",
            "Iteration 28, loss = 0.63972822\n",
            "Iteration 29, loss = 0.60241840\n",
            "Iteration 30, loss = 0.56464280\n",
            "Iteration 31, loss = 0.53233961\n",
            "Iteration 32, loss = 0.49754396\n",
            "Iteration 33, loss = 0.46510513\n",
            "Iteration 34, loss = 0.43434949\n",
            "Iteration 35, loss = 0.40784857\n",
            "Iteration 36, loss = 0.38140295\n",
            "Iteration 37, loss = 0.35515586\n",
            "Iteration 38, loss = 0.33013436\n",
            "Iteration 39, loss = 0.30872471\n",
            "Iteration 40, loss = 0.28874853\n",
            "Iteration 41, loss = 0.26891994\n",
            "Iteration 42, loss = 0.25199237\n",
            "Iteration 43, loss = 0.23505932\n",
            "Iteration 44, loss = 0.21900912\n",
            "Iteration 45, loss = 0.20562198\n",
            "Iteration 46, loss = 0.19219757\n",
            "Iteration 47, loss = 0.17972364\n",
            "Iteration 48, loss = 0.16806491\n",
            "Iteration 49, loss = 0.15738457\n",
            "Iteration 50, loss = 0.14798339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.99203810\n",
            "Iteration 2, loss = 1.70438090\n",
            "Iteration 3, loss = 1.61452524\n",
            "Iteration 4, loss = 1.56281266\n",
            "Iteration 5, loss = 1.52355923\n",
            "Iteration 6, loss = 1.48440059\n",
            "Iteration 7, loss = 1.45376355\n",
            "Iteration 8, loss = 1.42465020\n",
            "Iteration 9, loss = 1.39154952\n",
            "Iteration 10, loss = 1.36024272\n",
            "Iteration 11, loss = 1.32321735\n",
            "Iteration 12, loss = 1.29201409\n",
            "Iteration 13, loss = 1.25817958\n",
            "Iteration 14, loss = 1.21508527\n",
            "Iteration 15, loss = 1.17741785\n",
            "Iteration 16, loss = 1.13814007\n",
            "Iteration 17, loss = 1.09950628\n",
            "Iteration 18, loss = 1.05719798\n",
            "Iteration 19, loss = 1.01597003\n",
            "Iteration 20, loss = 0.97615919\n",
            "Iteration 21, loss = 0.92863752\n",
            "Iteration 22, loss = 0.88766792\n",
            "Iteration 23, loss = 0.84574662\n",
            "Iteration 24, loss = 0.80379573\n",
            "Iteration 25, loss = 0.75942551\n",
            "Iteration 26, loss = 0.72027936\n",
            "Iteration 27, loss = 0.67989021\n",
            "Iteration 28, loss = 0.64081175\n",
            "Iteration 29, loss = 0.60347634\n",
            "Iteration 30, loss = 0.56829468\n",
            "Iteration 31, loss = 0.53148616\n",
            "Iteration 32, loss = 0.49784179\n",
            "Iteration 33, loss = 0.46511805\n",
            "Iteration 34, loss = 0.43551128\n",
            "Iteration 35, loss = 0.40886820\n",
            "Iteration 36, loss = 0.38004923\n",
            "Iteration 37, loss = 0.35444926\n",
            "Iteration 38, loss = 0.33102311\n",
            "Iteration 39, loss = 0.30935996\n",
            "Iteration 40, loss = 0.28922710\n",
            "Iteration 41, loss = 0.27017160\n",
            "Iteration 42, loss = 0.25025027\n",
            "Iteration 43, loss = 0.23422173\n",
            "Iteration 44, loss = 0.21904697\n",
            "Iteration 45, loss = 0.20585683\n",
            "Iteration 46, loss = 0.19135022\n",
            "Iteration 47, loss = 0.17950423\n",
            "Iteration 48, loss = 0.16801782\n",
            "Iteration 49, loss = 0.15745698\n",
            "Iteration 50, loss = 0.14793609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02067219\n",
            "Iteration 2, loss = 1.71698872\n",
            "Iteration 3, loss = 1.61695418\n",
            "Iteration 4, loss = 1.56324359\n",
            "Iteration 5, loss = 1.51568812\n",
            "Iteration 6, loss = 1.48447817\n",
            "Iteration 7, loss = 1.44872336\n",
            "Iteration 8, loss = 1.41764866\n",
            "Iteration 9, loss = 1.38792195\n",
            "Iteration 10, loss = 1.35316609\n",
            "Iteration 11, loss = 1.32210877\n",
            "Iteration 12, loss = 1.28555438\n",
            "Iteration 13, loss = 1.24923858\n",
            "Iteration 14, loss = 1.21648256\n",
            "Iteration 15, loss = 1.17294012\n",
            "Iteration 16, loss = 1.13330934\n",
            "Iteration 17, loss = 1.09562627\n",
            "Iteration 18, loss = 1.05530728\n",
            "Iteration 19, loss = 1.01362430\n",
            "Iteration 20, loss = 0.97095235\n",
            "Iteration 21, loss = 0.93116947\n",
            "Iteration 22, loss = 0.88789266\n",
            "Iteration 23, loss = 0.84587577\n",
            "Iteration 24, loss = 0.80344307\n",
            "Iteration 25, loss = 0.76045153\n",
            "Iteration 26, loss = 0.71871325\n",
            "Iteration 27, loss = 0.67918752\n",
            "Iteration 28, loss = 0.64214138\n",
            "Iteration 29, loss = 0.60306969\n",
            "Iteration 30, loss = 0.56749320\n",
            "Iteration 31, loss = 0.53237517\n",
            "Iteration 32, loss = 0.50017803\n",
            "Iteration 33, loss = 0.46833611\n",
            "Iteration 34, loss = 0.43904492\n",
            "Iteration 35, loss = 0.41060799\n",
            "Iteration 36, loss = 0.38512939\n",
            "Iteration 37, loss = 0.35836010\n",
            "Iteration 38, loss = 0.33559989\n",
            "Iteration 39, loss = 0.31414547\n",
            "Iteration 40, loss = 0.29237777\n",
            "Iteration 41, loss = 0.27360630\n",
            "Iteration 42, loss = 0.25622669\n",
            "Iteration 43, loss = 0.23791037\n",
            "Iteration 44, loss = 0.22329871\n",
            "Iteration 45, loss = 0.21051058\n",
            "Iteration 46, loss = 0.19613309\n",
            "Iteration 47, loss = 0.18346974\n",
            "Iteration 48, loss = 0.17188721\n",
            "Iteration 49, loss = 0.16175778\n",
            "Iteration 50, loss = 0.15133074\n",
            "#### Outer Iteration 7 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01917045\n",
            "Iteration 2, loss = 1.71032458\n",
            "Iteration 3, loss = 1.62026938\n",
            "Iteration 4, loss = 1.56166173\n",
            "Iteration 5, loss = 1.52020717\n",
            "Iteration 6, loss = 1.47898040\n",
            "Iteration 7, loss = 1.45134374\n",
            "Iteration 8, loss = 1.41619138\n",
            "Iteration 9, loss = 1.38803307\n",
            "Iteration 10, loss = 1.35599161\n",
            "Iteration 11, loss = 1.32197480\n",
            "Iteration 12, loss = 1.28900960\n",
            "Iteration 13, loss = 1.24802696\n",
            "Iteration 14, loss = 1.21237444\n",
            "Iteration 15, loss = 1.17541727\n",
            "Iteration 16, loss = 1.13458699\n",
            "Iteration 17, loss = 1.09503672\n",
            "Iteration 18, loss = 1.05485324\n",
            "Iteration 19, loss = 1.01236214\n",
            "Iteration 20, loss = 0.97227244\n",
            "Iteration 21, loss = 0.92685642\n",
            "Iteration 22, loss = 0.88585994\n",
            "Iteration 23, loss = 0.84232318\n",
            "Iteration 24, loss = 0.79982414\n",
            "Iteration 25, loss = 0.75748534\n",
            "Iteration 26, loss = 0.71907068\n",
            "Iteration 27, loss = 0.67687589\n",
            "Iteration 28, loss = 0.63647618\n",
            "Iteration 29, loss = 0.60130894\n",
            "Iteration 30, loss = 0.56405199\n",
            "Iteration 31, loss = 0.53226071\n",
            "Iteration 32, loss = 0.49694928\n",
            "Iteration 33, loss = 0.46595007\n",
            "Iteration 34, loss = 0.43702101\n",
            "Iteration 35, loss = 0.40656201\n",
            "Iteration 36, loss = 0.38137006\n",
            "Iteration 37, loss = 0.35617319\n",
            "Iteration 38, loss = 0.33325064\n",
            "Iteration 39, loss = 0.31061257\n",
            "Iteration 40, loss = 0.29014548\n",
            "Iteration 41, loss = 0.27110965\n",
            "Iteration 42, loss = 0.25274210\n",
            "Iteration 43, loss = 0.23745979\n",
            "Iteration 44, loss = 0.22200622\n",
            "Iteration 45, loss = 0.20698400\n",
            "Iteration 46, loss = 0.19307047\n",
            "Iteration 47, loss = 0.18177326\n",
            "Iteration 48, loss = 0.17032685\n",
            "Iteration 49, loss = 0.15924807\n",
            "Iteration 50, loss = 0.14946182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03540521\n",
            "Iteration 2, loss = 1.72068631\n",
            "Iteration 3, loss = 1.62629954\n",
            "Iteration 4, loss = 1.57033301\n",
            "Iteration 5, loss = 1.52950552\n",
            "Iteration 6, loss = 1.49003658\n",
            "Iteration 7, loss = 1.45774230\n",
            "Iteration 8, loss = 1.42844064\n",
            "Iteration 9, loss = 1.39690427\n",
            "Iteration 10, loss = 1.36697044\n",
            "Iteration 11, loss = 1.33288054\n",
            "Iteration 12, loss = 1.29715478\n",
            "Iteration 13, loss = 1.25980899\n",
            "Iteration 14, loss = 1.22560225\n",
            "Iteration 15, loss = 1.19008865\n",
            "Iteration 16, loss = 1.15201800\n",
            "Iteration 17, loss = 1.10769290\n",
            "Iteration 18, loss = 1.07088640\n",
            "Iteration 19, loss = 1.02567660\n",
            "Iteration 20, loss = 0.98579179\n",
            "Iteration 21, loss = 0.94265296\n",
            "Iteration 22, loss = 0.89929188\n",
            "Iteration 23, loss = 0.85787493\n",
            "Iteration 24, loss = 0.81452265\n",
            "Iteration 25, loss = 0.77074588\n",
            "Iteration 26, loss = 0.73168381\n",
            "Iteration 27, loss = 0.69130361\n",
            "Iteration 28, loss = 0.65061181\n",
            "Iteration 29, loss = 0.61237708\n",
            "Iteration 30, loss = 0.57628379\n",
            "Iteration 31, loss = 0.54193068\n",
            "Iteration 32, loss = 0.50831298\n",
            "Iteration 33, loss = 0.47682657\n",
            "Iteration 34, loss = 0.44538489\n",
            "Iteration 35, loss = 0.41861402\n",
            "Iteration 36, loss = 0.38956550\n",
            "Iteration 37, loss = 0.36621730\n",
            "Iteration 38, loss = 0.34118499\n",
            "Iteration 39, loss = 0.31898513\n",
            "Iteration 40, loss = 0.29807886\n",
            "Iteration 41, loss = 0.27906847\n",
            "Iteration 42, loss = 0.25992669\n",
            "Iteration 43, loss = 0.24238755\n",
            "Iteration 44, loss = 0.22722685\n",
            "Iteration 45, loss = 0.21264429\n",
            "Iteration 46, loss = 0.19888212\n",
            "Iteration 47, loss = 0.18569079\n",
            "Iteration 48, loss = 0.17458376\n",
            "Iteration 49, loss = 0.16371145\n",
            "Iteration 50, loss = 0.15317497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01119045\n",
            "Iteration 2, loss = 1.72063787\n",
            "Iteration 3, loss = 1.62468305\n",
            "Iteration 4, loss = 1.57015088\n",
            "Iteration 5, loss = 1.52593358\n",
            "Iteration 6, loss = 1.49268457\n",
            "Iteration 7, loss = 1.45742705\n",
            "Iteration 8, loss = 1.43053111\n",
            "Iteration 9, loss = 1.39671300\n",
            "Iteration 10, loss = 1.36422442\n",
            "Iteration 11, loss = 1.32973510\n",
            "Iteration 12, loss = 1.29791574\n",
            "Iteration 13, loss = 1.25997673\n",
            "Iteration 14, loss = 1.22586744\n",
            "Iteration 15, loss = 1.19026839\n",
            "Iteration 16, loss = 1.14905601\n",
            "Iteration 17, loss = 1.11038350\n",
            "Iteration 18, loss = 1.06728658\n",
            "Iteration 19, loss = 1.02812047\n",
            "Iteration 20, loss = 0.98297200\n",
            "Iteration 21, loss = 0.94069020\n",
            "Iteration 22, loss = 0.90337627\n",
            "Iteration 23, loss = 0.85728249\n",
            "Iteration 24, loss = 0.81573348\n",
            "Iteration 25, loss = 0.77517765\n",
            "Iteration 26, loss = 0.73046019\n",
            "Iteration 27, loss = 0.69290409\n",
            "Iteration 28, loss = 0.65476896\n",
            "Iteration 29, loss = 0.61304029\n",
            "Iteration 30, loss = 0.57726121\n",
            "Iteration 31, loss = 0.54227527\n",
            "Iteration 32, loss = 0.50967600\n",
            "Iteration 33, loss = 0.47764634\n",
            "Iteration 34, loss = 0.44794712\n",
            "Iteration 35, loss = 0.41867907\n",
            "Iteration 36, loss = 0.39073092\n",
            "Iteration 37, loss = 0.36552671\n",
            "Iteration 38, loss = 0.34159171\n",
            "Iteration 39, loss = 0.31903375\n",
            "Iteration 40, loss = 0.29841780\n",
            "Iteration 41, loss = 0.27904599\n",
            "Iteration 42, loss = 0.26117934\n",
            "Iteration 43, loss = 0.24319016\n",
            "Iteration 44, loss = 0.22791718\n",
            "Iteration 45, loss = 0.21320958\n",
            "Iteration 46, loss = 0.20027776\n",
            "Iteration 47, loss = 0.18762829\n",
            "Iteration 48, loss = 0.17562990\n",
            "Iteration 49, loss = 0.16449102\n",
            "Iteration 50, loss = 0.15480644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00863472\n",
            "Iteration 2, loss = 1.71343590\n",
            "Iteration 3, loss = 1.61477563\n",
            "Iteration 4, loss = 1.56560361\n",
            "Iteration 5, loss = 1.52038158\n",
            "Iteration 6, loss = 1.48662423\n",
            "Iteration 7, loss = 1.46029777\n",
            "Iteration 8, loss = 1.43409574\n",
            "Iteration 9, loss = 1.39221737\n",
            "Iteration 10, loss = 1.36145608\n",
            "Iteration 11, loss = 1.32958988\n",
            "Iteration 12, loss = 1.29790107\n",
            "Iteration 13, loss = 1.26288289\n",
            "Iteration 14, loss = 1.22656252\n",
            "Iteration 15, loss = 1.18678197\n",
            "Iteration 16, loss = 1.14902667\n",
            "Iteration 17, loss = 1.10807960\n",
            "Iteration 18, loss = 1.06622805\n",
            "Iteration 19, loss = 1.02856469\n",
            "Iteration 20, loss = 0.98468635\n",
            "Iteration 21, loss = 0.94595993\n",
            "Iteration 22, loss = 0.89981370\n",
            "Iteration 23, loss = 0.85875310\n",
            "Iteration 24, loss = 0.81451133\n",
            "Iteration 25, loss = 0.77164566\n",
            "Iteration 26, loss = 0.73126217\n",
            "Iteration 27, loss = 0.69227352\n",
            "Iteration 28, loss = 0.65051808\n",
            "Iteration 29, loss = 0.61530462\n",
            "Iteration 30, loss = 0.57864714\n",
            "Iteration 31, loss = 0.54345855\n",
            "Iteration 32, loss = 0.51218139\n",
            "Iteration 33, loss = 0.47920871\n",
            "Iteration 34, loss = 0.45073984\n",
            "Iteration 35, loss = 0.42045538\n",
            "Iteration 36, loss = 0.39283946\n",
            "Iteration 37, loss = 0.36821005\n",
            "Iteration 38, loss = 0.34279200\n",
            "Iteration 39, loss = 0.31995518\n",
            "Iteration 40, loss = 0.29977612\n",
            "Iteration 41, loss = 0.28003317\n",
            "Iteration 42, loss = 0.26189024\n",
            "Iteration 43, loss = 0.24392997\n",
            "Iteration 44, loss = 0.22874891\n",
            "Iteration 45, loss = 0.21260625\n",
            "Iteration 46, loss = 0.19981110\n",
            "Iteration 47, loss = 0.18739383\n",
            "Iteration 48, loss = 0.17517834\n",
            "Iteration 49, loss = 0.16418144\n",
            "Iteration 50, loss = 0.15455158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02545907\n",
            "Iteration 2, loss = 1.72035380\n",
            "Iteration 3, loss = 1.62206742\n",
            "Iteration 4, loss = 1.56218468\n",
            "Iteration 5, loss = 1.52656295\n",
            "Iteration 6, loss = 1.49422087\n",
            "Iteration 7, loss = 1.45593359\n",
            "Iteration 8, loss = 1.42936893\n",
            "Iteration 9, loss = 1.39547958\n",
            "Iteration 10, loss = 1.36177285\n",
            "Iteration 11, loss = 1.33045108\n",
            "Iteration 12, loss = 1.29515842\n",
            "Iteration 13, loss = 1.25628401\n",
            "Iteration 14, loss = 1.22417328\n",
            "Iteration 15, loss = 1.18200231\n",
            "Iteration 16, loss = 1.14633935\n",
            "Iteration 17, loss = 1.10299670\n",
            "Iteration 18, loss = 1.06301975\n",
            "Iteration 19, loss = 1.02437749\n",
            "Iteration 20, loss = 0.97969295\n",
            "Iteration 21, loss = 0.93814952\n",
            "Iteration 22, loss = 0.89725052\n",
            "Iteration 23, loss = 0.85530974\n",
            "Iteration 24, loss = 0.80950696\n",
            "Iteration 25, loss = 0.77401251\n",
            "Iteration 26, loss = 0.72943645\n",
            "Iteration 27, loss = 0.68808097\n",
            "Iteration 28, loss = 0.64941537\n",
            "Iteration 29, loss = 0.61086287\n",
            "Iteration 30, loss = 0.57649511\n",
            "Iteration 31, loss = 0.54399872\n",
            "Iteration 32, loss = 0.50810119\n",
            "Iteration 33, loss = 0.47522753\n",
            "Iteration 34, loss = 0.44639784\n",
            "Iteration 35, loss = 0.41689084\n",
            "Iteration 36, loss = 0.39043307\n",
            "Iteration 37, loss = 0.36430223\n",
            "Iteration 38, loss = 0.34009280\n",
            "Iteration 39, loss = 0.31696180\n",
            "Iteration 40, loss = 0.29700887\n",
            "Iteration 41, loss = 0.27712028\n",
            "Iteration 42, loss = 0.25902606\n",
            "Iteration 43, loss = 0.24231134\n",
            "Iteration 44, loss = 0.22696944\n",
            "Iteration 45, loss = 0.21231257\n",
            "Iteration 46, loss = 0.19828570\n",
            "Iteration 47, loss = 0.18580999\n",
            "Iteration 48, loss = 0.17429424\n",
            "Iteration 49, loss = 0.16359351\n",
            "Iteration 50, loss = 0.15322925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00917771\n",
            "Iteration 2, loss = 1.71005656\n",
            "Iteration 3, loss = 1.60974231\n",
            "Iteration 4, loss = 1.55849340\n",
            "Iteration 5, loss = 1.51525794\n",
            "Iteration 6, loss = 1.48252405\n",
            "Iteration 7, loss = 1.44979220\n",
            "Iteration 8, loss = 1.41607437\n",
            "Iteration 9, loss = 1.38400492\n",
            "Iteration 10, loss = 1.35504015\n",
            "Iteration 11, loss = 1.31698500\n",
            "Iteration 12, loss = 1.28798209\n",
            "Iteration 13, loss = 1.25157502\n",
            "Iteration 14, loss = 1.20994702\n",
            "Iteration 15, loss = 1.17885931\n",
            "Iteration 16, loss = 1.13699134\n",
            "Iteration 17, loss = 1.09577136\n",
            "Iteration 18, loss = 1.05520846\n",
            "Iteration 19, loss = 1.01354723\n",
            "Iteration 20, loss = 0.96830501\n",
            "Iteration 21, loss = 0.92622459\n",
            "Iteration 22, loss = 0.88134333\n",
            "Iteration 23, loss = 0.84193956\n",
            "Iteration 24, loss = 0.79758487\n",
            "Iteration 25, loss = 0.75821463\n",
            "Iteration 26, loss = 0.71491199\n",
            "Iteration 27, loss = 0.67643196\n",
            "Iteration 28, loss = 0.63488585\n",
            "Iteration 29, loss = 0.59724000\n",
            "Iteration 30, loss = 0.55966812\n",
            "Iteration 31, loss = 0.52782260\n",
            "Iteration 32, loss = 0.49545792\n",
            "Iteration 33, loss = 0.46283657\n",
            "Iteration 34, loss = 0.43362098\n",
            "Iteration 35, loss = 0.40517906\n",
            "Iteration 36, loss = 0.37864006\n",
            "Iteration 37, loss = 0.35288309\n",
            "Iteration 38, loss = 0.32956644\n",
            "Iteration 39, loss = 0.30787734\n",
            "Iteration 40, loss = 0.28701389\n",
            "Iteration 41, loss = 0.26869709\n",
            "Iteration 42, loss = 0.25066374\n",
            "Iteration 43, loss = 0.23324102\n",
            "Iteration 44, loss = 0.21883258\n",
            "Iteration 45, loss = 0.20473385\n",
            "Iteration 46, loss = 0.19120333\n",
            "Iteration 47, loss = 0.17911165\n",
            "Iteration 48, loss = 0.16799939\n",
            "Iteration 49, loss = 0.15748729\n",
            "Iteration 50, loss = 0.14813779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01425932\n",
            "Iteration 2, loss = 1.71103245\n",
            "Iteration 3, loss = 1.61628496\n",
            "Iteration 4, loss = 1.56028019\n",
            "Iteration 5, loss = 1.51919383\n",
            "Iteration 6, loss = 1.48585957\n",
            "Iteration 7, loss = 1.44992537\n",
            "Iteration 8, loss = 1.41710772\n",
            "Iteration 9, loss = 1.38386989\n",
            "Iteration 10, loss = 1.35216542\n",
            "Iteration 11, loss = 1.31946438\n",
            "Iteration 12, loss = 1.27948988\n",
            "Iteration 13, loss = 1.24399589\n",
            "Iteration 14, loss = 1.20555648\n",
            "Iteration 15, loss = 1.16865738\n",
            "Iteration 16, loss = 1.12640828\n",
            "Iteration 17, loss = 1.08812913\n",
            "Iteration 18, loss = 1.04273681\n",
            "Iteration 19, loss = 0.99997098\n",
            "Iteration 20, loss = 0.95679946\n",
            "Iteration 21, loss = 0.91732806\n",
            "Iteration 22, loss = 0.87464067\n",
            "Iteration 23, loss = 0.83013813\n",
            "Iteration 24, loss = 0.78590798\n",
            "Iteration 25, loss = 0.74348272\n",
            "Iteration 26, loss = 0.70182511\n",
            "Iteration 27, loss = 0.66227102\n",
            "Iteration 28, loss = 0.62458516\n",
            "Iteration 29, loss = 0.58755471\n",
            "Iteration 30, loss = 0.55112556\n",
            "Iteration 31, loss = 0.51793872\n",
            "Iteration 32, loss = 0.48434808\n",
            "Iteration 33, loss = 0.45429418\n",
            "Iteration 34, loss = 0.42454745\n",
            "Iteration 35, loss = 0.39689174\n",
            "Iteration 36, loss = 0.37016923\n",
            "Iteration 37, loss = 0.34669862\n",
            "Iteration 38, loss = 0.32394569\n",
            "Iteration 39, loss = 0.30144817\n",
            "Iteration 40, loss = 0.28160300\n",
            "Iteration 41, loss = 0.26266633\n",
            "Iteration 42, loss = 0.24586512\n",
            "Iteration 43, loss = 0.23010788\n",
            "Iteration 44, loss = 0.21478331\n",
            "Iteration 45, loss = 0.20124183\n",
            "Iteration 46, loss = 0.18845681\n",
            "Iteration 47, loss = 0.17613562\n",
            "Iteration 48, loss = 0.16531614\n",
            "Iteration 49, loss = 0.15510094\n",
            "Iteration 50, loss = 0.14580578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02568807\n",
            "Iteration 2, loss = 1.72517869\n",
            "Iteration 3, loss = 1.62782964\n",
            "Iteration 4, loss = 1.56550390\n",
            "Iteration 5, loss = 1.52679330\n",
            "Iteration 6, loss = 1.48784516\n",
            "Iteration 7, loss = 1.45429113\n",
            "Iteration 8, loss = 1.42348588\n",
            "Iteration 9, loss = 1.38722704\n",
            "Iteration 10, loss = 1.36508531\n",
            "Iteration 11, loss = 1.32279104\n",
            "Iteration 12, loss = 1.28889388\n",
            "Iteration 13, loss = 1.25029014\n",
            "Iteration 14, loss = 1.21379793\n",
            "Iteration 15, loss = 1.17796115\n",
            "Iteration 16, loss = 1.13602648\n",
            "Iteration 17, loss = 1.09985046\n",
            "Iteration 18, loss = 1.05870165\n",
            "Iteration 19, loss = 1.01384292\n",
            "Iteration 20, loss = 0.97184725\n",
            "Iteration 21, loss = 0.92723697\n",
            "Iteration 22, loss = 0.88557706\n",
            "Iteration 23, loss = 0.84527771\n",
            "Iteration 24, loss = 0.80429408\n",
            "Iteration 25, loss = 0.76034362\n",
            "Iteration 26, loss = 0.72243045\n",
            "Iteration 27, loss = 0.68116995\n",
            "Iteration 28, loss = 0.64270700\n",
            "Iteration 29, loss = 0.60453731\n",
            "Iteration 30, loss = 0.56770675\n",
            "Iteration 31, loss = 0.53393992\n",
            "Iteration 32, loss = 0.50019752\n",
            "Iteration 33, loss = 0.47000284\n",
            "Iteration 34, loss = 0.43776050\n",
            "Iteration 35, loss = 0.40977798\n",
            "Iteration 36, loss = 0.38538887\n",
            "Iteration 37, loss = 0.35908808\n",
            "Iteration 38, loss = 0.33657882\n",
            "Iteration 39, loss = 0.31353966\n",
            "Iteration 40, loss = 0.29303719\n",
            "Iteration 41, loss = 0.27341323\n",
            "Iteration 42, loss = 0.25484802\n",
            "Iteration 43, loss = 0.23956982\n",
            "Iteration 44, loss = 0.22277374\n",
            "Iteration 45, loss = 0.20942571\n",
            "Iteration 46, loss = 0.19513499\n",
            "Iteration 47, loss = 0.18352245\n",
            "Iteration 48, loss = 0.17171778\n",
            "Iteration 49, loss = 0.16085250\n",
            "Iteration 50, loss = 0.15123999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01098912\n",
            "Iteration 2, loss = 1.71364828\n",
            "Iteration 3, loss = 1.62466535\n",
            "Iteration 4, loss = 1.57119517\n",
            "Iteration 5, loss = 1.52896412\n",
            "Iteration 6, loss = 1.48857637\n",
            "Iteration 7, loss = 1.45528536\n",
            "Iteration 8, loss = 1.42551031\n",
            "Iteration 9, loss = 1.39143668\n",
            "Iteration 10, loss = 1.36162080\n",
            "Iteration 11, loss = 1.32541442\n",
            "Iteration 12, loss = 1.29052879\n",
            "Iteration 13, loss = 1.25037466\n",
            "Iteration 14, loss = 1.21665881\n",
            "Iteration 15, loss = 1.17560916\n",
            "Iteration 16, loss = 1.13593163\n",
            "Iteration 17, loss = 1.09746006\n",
            "Iteration 18, loss = 1.05488936\n",
            "Iteration 19, loss = 1.01418548\n",
            "Iteration 20, loss = 0.97022359\n",
            "Iteration 21, loss = 0.92967417\n",
            "Iteration 22, loss = 0.88601016\n",
            "Iteration 23, loss = 0.84218963\n",
            "Iteration 24, loss = 0.80211368\n",
            "Iteration 25, loss = 0.76095677\n",
            "Iteration 26, loss = 0.71821626\n",
            "Iteration 27, loss = 0.67869355\n",
            "Iteration 28, loss = 0.64133216\n",
            "Iteration 29, loss = 0.60354594\n",
            "Iteration 30, loss = 0.56737341\n",
            "Iteration 31, loss = 0.53048041\n",
            "Iteration 32, loss = 0.49720330\n",
            "Iteration 33, loss = 0.46906933\n",
            "Iteration 34, loss = 0.43724694\n",
            "Iteration 35, loss = 0.40855861\n",
            "Iteration 36, loss = 0.38416316\n",
            "Iteration 37, loss = 0.35666328\n",
            "Iteration 38, loss = 0.33318039\n",
            "Iteration 39, loss = 0.31157681\n",
            "Iteration 40, loss = 0.29054518\n",
            "Iteration 41, loss = 0.27172917\n",
            "Iteration 42, loss = 0.25402443\n",
            "Iteration 43, loss = 0.23755591\n",
            "Iteration 44, loss = 0.22185885\n",
            "Iteration 45, loss = 0.20682259\n",
            "Iteration 46, loss = 0.19374851\n",
            "Iteration 47, loss = 0.18122399\n",
            "Iteration 48, loss = 0.17006085\n",
            "Iteration 49, loss = 0.15887041\n",
            "Iteration 50, loss = 0.14952146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01603678\n",
            "Iteration 2, loss = 1.71824958\n",
            "Iteration 3, loss = 1.61973275\n",
            "Iteration 4, loss = 1.56353904\n",
            "Iteration 5, loss = 1.52538871\n",
            "Iteration 6, loss = 1.49214458\n",
            "Iteration 7, loss = 1.45734838\n",
            "Iteration 8, loss = 1.42471605\n",
            "Iteration 9, loss = 1.39638798\n",
            "Iteration 10, loss = 1.36136860\n",
            "Iteration 11, loss = 1.32891708\n",
            "Iteration 12, loss = 1.29785674\n",
            "Iteration 13, loss = 1.26104522\n",
            "Iteration 14, loss = 1.22586858\n",
            "Iteration 15, loss = 1.18643088\n",
            "Iteration 16, loss = 1.14452009\n",
            "Iteration 17, loss = 1.10736055\n",
            "Iteration 18, loss = 1.06620985\n",
            "Iteration 19, loss = 1.02320446\n",
            "Iteration 20, loss = 0.98258109\n",
            "Iteration 21, loss = 0.94371014\n",
            "Iteration 22, loss = 0.90052564\n",
            "Iteration 23, loss = 0.85406202\n",
            "Iteration 24, loss = 0.81178905\n",
            "Iteration 25, loss = 0.77170381\n",
            "Iteration 26, loss = 0.73099378\n",
            "Iteration 27, loss = 0.69052195\n",
            "Iteration 28, loss = 0.65209517\n",
            "Iteration 29, loss = 0.61479826\n",
            "Iteration 30, loss = 0.57670978\n",
            "Iteration 31, loss = 0.54335049\n",
            "Iteration 32, loss = 0.51077605\n",
            "Iteration 33, loss = 0.47708051\n",
            "Iteration 34, loss = 0.44752882\n",
            "Iteration 35, loss = 0.41913230\n",
            "Iteration 36, loss = 0.39262024\n",
            "Iteration 37, loss = 0.36827903\n",
            "Iteration 38, loss = 0.34285531\n",
            "Iteration 39, loss = 0.32114034\n",
            "Iteration 40, loss = 0.29947151\n",
            "Iteration 41, loss = 0.27954853\n",
            "Iteration 42, loss = 0.26230866\n",
            "Iteration 43, loss = 0.24547882\n",
            "Iteration 44, loss = 0.22918308\n",
            "Iteration 45, loss = 0.21283249\n",
            "Iteration 46, loss = 0.19962139\n",
            "Iteration 47, loss = 0.18734259\n",
            "Iteration 48, loss = 0.17566806\n",
            "Iteration 49, loss = 0.16517812\n",
            "Iteration 50, loss = 0.15443981\n",
            "#### Outer Iteration 8 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02808585\n",
            "Iteration 2, loss = 1.71609587\n",
            "Iteration 3, loss = 1.62110512\n",
            "Iteration 4, loss = 1.56890762\n",
            "Iteration 5, loss = 1.52506374\n",
            "Iteration 6, loss = 1.49319351\n",
            "Iteration 7, loss = 1.45852642\n",
            "Iteration 8, loss = 1.42394884\n",
            "Iteration 9, loss = 1.39333867\n",
            "Iteration 10, loss = 1.36147379\n",
            "Iteration 11, loss = 1.32812077\n",
            "Iteration 12, loss = 1.29150379\n",
            "Iteration 13, loss = 1.25852305\n",
            "Iteration 14, loss = 1.22763464\n",
            "Iteration 15, loss = 1.18198564\n",
            "Iteration 16, loss = 1.14393841\n",
            "Iteration 17, loss = 1.10553977\n",
            "Iteration 18, loss = 1.06315839\n",
            "Iteration 19, loss = 1.02594249\n",
            "Iteration 20, loss = 0.98224047\n",
            "Iteration 21, loss = 0.93869721\n",
            "Iteration 22, loss = 0.89558265\n",
            "Iteration 23, loss = 0.85503868\n",
            "Iteration 24, loss = 0.81244274\n",
            "Iteration 25, loss = 0.77133686\n",
            "Iteration 26, loss = 0.72987125\n",
            "Iteration 27, loss = 0.69013256\n",
            "Iteration 28, loss = 0.64966807\n",
            "Iteration 29, loss = 0.61249381\n",
            "Iteration 30, loss = 0.57572731\n",
            "Iteration 31, loss = 0.54311947\n",
            "Iteration 32, loss = 0.50741396\n",
            "Iteration 33, loss = 0.47552812\n",
            "Iteration 34, loss = 0.44504881\n",
            "Iteration 35, loss = 0.41767523\n",
            "Iteration 36, loss = 0.39060177\n",
            "Iteration 37, loss = 0.36489062\n",
            "Iteration 38, loss = 0.34058159\n",
            "Iteration 39, loss = 0.31984641\n",
            "Iteration 40, loss = 0.29799685\n",
            "Iteration 41, loss = 0.27783549\n",
            "Iteration 42, loss = 0.26084410\n",
            "Iteration 43, loss = 0.24175914\n",
            "Iteration 44, loss = 0.22766436\n",
            "Iteration 45, loss = 0.21306417\n",
            "Iteration 46, loss = 0.19950241\n",
            "Iteration 47, loss = 0.18633668\n",
            "Iteration 48, loss = 0.17400343\n",
            "Iteration 49, loss = 0.16356703\n",
            "Iteration 50, loss = 0.15366762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02815030\n",
            "Iteration 2, loss = 1.72336426\n",
            "Iteration 3, loss = 1.62348743\n",
            "Iteration 4, loss = 1.56823381\n",
            "Iteration 5, loss = 1.52908922\n",
            "Iteration 6, loss = 1.48717947\n",
            "Iteration 7, loss = 1.45687807\n",
            "Iteration 8, loss = 1.42531455\n",
            "Iteration 9, loss = 1.39359343\n",
            "Iteration 10, loss = 1.36787391\n",
            "Iteration 11, loss = 1.33096913\n",
            "Iteration 12, loss = 1.29603931\n",
            "Iteration 13, loss = 1.25884598\n",
            "Iteration 14, loss = 1.22142533\n",
            "Iteration 15, loss = 1.18367751\n",
            "Iteration 16, loss = 1.14841256\n",
            "Iteration 17, loss = 1.10466945\n",
            "Iteration 18, loss = 1.06329578\n",
            "Iteration 19, loss = 1.02089416\n",
            "Iteration 20, loss = 0.97997557\n",
            "Iteration 21, loss = 0.93769733\n",
            "Iteration 22, loss = 0.89490089\n",
            "Iteration 23, loss = 0.85126487\n",
            "Iteration 24, loss = 0.81085128\n",
            "Iteration 25, loss = 0.76679158\n",
            "Iteration 26, loss = 0.72453143\n",
            "Iteration 27, loss = 0.68435672\n",
            "Iteration 28, loss = 0.64486174\n",
            "Iteration 29, loss = 0.60686183\n",
            "Iteration 30, loss = 0.56986553\n",
            "Iteration 31, loss = 0.53708781\n",
            "Iteration 32, loss = 0.50097076\n",
            "Iteration 33, loss = 0.46872715\n",
            "Iteration 34, loss = 0.44014587\n",
            "Iteration 35, loss = 0.40991928\n",
            "Iteration 36, loss = 0.38433822\n",
            "Iteration 37, loss = 0.36147492\n",
            "Iteration 38, loss = 0.33599640\n",
            "Iteration 39, loss = 0.31361798\n",
            "Iteration 40, loss = 0.29319091\n",
            "Iteration 41, loss = 0.27372592\n",
            "Iteration 42, loss = 0.25516826\n",
            "Iteration 43, loss = 0.23836106\n",
            "Iteration 44, loss = 0.22261650\n",
            "Iteration 45, loss = 0.20823587\n",
            "Iteration 46, loss = 0.19458919\n",
            "Iteration 47, loss = 0.18214060\n",
            "Iteration 48, loss = 0.17074490\n",
            "Iteration 49, loss = 0.16054832\n",
            "Iteration 50, loss = 0.15017387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02408500\n",
            "Iteration 2, loss = 1.71815626\n",
            "Iteration 3, loss = 1.62075987\n",
            "Iteration 4, loss = 1.56701877\n",
            "Iteration 5, loss = 1.52438819\n",
            "Iteration 6, loss = 1.48876417\n",
            "Iteration 7, loss = 1.45325643\n",
            "Iteration 8, loss = 1.42301503\n",
            "Iteration 9, loss = 1.39095701\n",
            "Iteration 10, loss = 1.36084879\n",
            "Iteration 11, loss = 1.33009487\n",
            "Iteration 12, loss = 1.29218577\n",
            "Iteration 13, loss = 1.25252521\n",
            "Iteration 14, loss = 1.21851464\n",
            "Iteration 15, loss = 1.18152832\n",
            "Iteration 16, loss = 1.14326303\n",
            "Iteration 17, loss = 1.10220264\n",
            "Iteration 18, loss = 1.06573215\n",
            "Iteration 19, loss = 1.01935512\n",
            "Iteration 20, loss = 0.97605033\n",
            "Iteration 21, loss = 0.93268755\n",
            "Iteration 22, loss = 0.89404759\n",
            "Iteration 23, loss = 0.84839433\n",
            "Iteration 24, loss = 0.80734557\n",
            "Iteration 25, loss = 0.76644223\n",
            "Iteration 26, loss = 0.72465494\n",
            "Iteration 27, loss = 0.68822546\n",
            "Iteration 28, loss = 0.64901283\n",
            "Iteration 29, loss = 0.60790445\n",
            "Iteration 30, loss = 0.56960653\n",
            "Iteration 31, loss = 0.53630004\n",
            "Iteration 32, loss = 0.50413076\n",
            "Iteration 33, loss = 0.47198212\n",
            "Iteration 34, loss = 0.44129771\n",
            "Iteration 35, loss = 0.41280401\n",
            "Iteration 36, loss = 0.38621859\n",
            "Iteration 37, loss = 0.36136217\n",
            "Iteration 38, loss = 0.33631123\n",
            "Iteration 39, loss = 0.31433820\n",
            "Iteration 40, loss = 0.29396835\n",
            "Iteration 41, loss = 0.27470318\n",
            "Iteration 42, loss = 0.25649383\n",
            "Iteration 43, loss = 0.24155482\n",
            "Iteration 44, loss = 0.22490531\n",
            "Iteration 45, loss = 0.20965949\n",
            "Iteration 46, loss = 0.19683538\n",
            "Iteration 47, loss = 0.18424960\n",
            "Iteration 48, loss = 0.17253054\n",
            "Iteration 49, loss = 0.16120991\n",
            "Iteration 50, loss = 0.15121116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02196700\n",
            "Iteration 2, loss = 1.71634061\n",
            "Iteration 3, loss = 1.61563688\n",
            "Iteration 4, loss = 1.55944874\n",
            "Iteration 5, loss = 1.51993755\n",
            "Iteration 6, loss = 1.48470090\n",
            "Iteration 7, loss = 1.45287968\n",
            "Iteration 8, loss = 1.41591915\n",
            "Iteration 9, loss = 1.38830000\n",
            "Iteration 10, loss = 1.35447281\n",
            "Iteration 11, loss = 1.32613501\n",
            "Iteration 12, loss = 1.28784523\n",
            "Iteration 13, loss = 1.24898894\n",
            "Iteration 14, loss = 1.21327969\n",
            "Iteration 15, loss = 1.17497251\n",
            "Iteration 16, loss = 1.13686672\n",
            "Iteration 17, loss = 1.09410572\n",
            "Iteration 18, loss = 1.05414091\n",
            "Iteration 19, loss = 1.00988709\n",
            "Iteration 20, loss = 0.96703894\n",
            "Iteration 21, loss = 0.92130755\n",
            "Iteration 22, loss = 0.88043885\n",
            "Iteration 23, loss = 0.84057546\n",
            "Iteration 24, loss = 0.79794975\n",
            "Iteration 25, loss = 0.75450486\n",
            "Iteration 26, loss = 0.71299401\n",
            "Iteration 27, loss = 0.67596568\n",
            "Iteration 28, loss = 0.63317305\n",
            "Iteration 29, loss = 0.59692887\n",
            "Iteration 30, loss = 0.56273485\n",
            "Iteration 31, loss = 0.52619298\n",
            "Iteration 32, loss = 0.49331371\n",
            "Iteration 33, loss = 0.46357924\n",
            "Iteration 34, loss = 0.43445769\n",
            "Iteration 35, loss = 0.40645551\n",
            "Iteration 36, loss = 0.37957571\n",
            "Iteration 37, loss = 0.35643305\n",
            "Iteration 38, loss = 0.33282400\n",
            "Iteration 39, loss = 0.30907820\n",
            "Iteration 40, loss = 0.28980791\n",
            "Iteration 41, loss = 0.27039357\n",
            "Iteration 42, loss = 0.25271103\n",
            "Iteration 43, loss = 0.23713299\n",
            "Iteration 44, loss = 0.22134703\n",
            "Iteration 45, loss = 0.20717219\n",
            "Iteration 46, loss = 0.19399282\n",
            "Iteration 47, loss = 0.18123987\n",
            "Iteration 48, loss = 0.17090001\n",
            "Iteration 49, loss = 0.15959110\n",
            "Iteration 50, loss = 0.14984973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01311772\n",
            "Iteration 2, loss = 1.71011279\n",
            "Iteration 3, loss = 1.61960449\n",
            "Iteration 4, loss = 1.56093452\n",
            "Iteration 5, loss = 1.51689627\n",
            "Iteration 6, loss = 1.48573608\n",
            "Iteration 7, loss = 1.45025964\n",
            "Iteration 8, loss = 1.41773043\n",
            "Iteration 9, loss = 1.38702075\n",
            "Iteration 10, loss = 1.35567821\n",
            "Iteration 11, loss = 1.32362288\n",
            "Iteration 12, loss = 1.28312211\n",
            "Iteration 13, loss = 1.25220862\n",
            "Iteration 14, loss = 1.21302315\n",
            "Iteration 15, loss = 1.17696237\n",
            "Iteration 16, loss = 1.13842786\n",
            "Iteration 17, loss = 1.09671548\n",
            "Iteration 18, loss = 1.05561357\n",
            "Iteration 19, loss = 1.00945409\n",
            "Iteration 20, loss = 0.96985801\n",
            "Iteration 21, loss = 0.92701450\n",
            "Iteration 22, loss = 0.88662416\n",
            "Iteration 23, loss = 0.84165709\n",
            "Iteration 24, loss = 0.80244446\n",
            "Iteration 25, loss = 0.76535418\n",
            "Iteration 26, loss = 0.72210868\n",
            "Iteration 27, loss = 0.67620824\n",
            "Iteration 28, loss = 0.63962380\n",
            "Iteration 29, loss = 0.60214908\n",
            "Iteration 30, loss = 0.56593603\n",
            "Iteration 31, loss = 0.53231280\n",
            "Iteration 32, loss = 0.49758934\n",
            "Iteration 33, loss = 0.46573842\n",
            "Iteration 34, loss = 0.43676446\n",
            "Iteration 35, loss = 0.40937280\n",
            "Iteration 36, loss = 0.38080867\n",
            "Iteration 37, loss = 0.35908946\n",
            "Iteration 38, loss = 0.33379382\n",
            "Iteration 39, loss = 0.31209396\n",
            "Iteration 40, loss = 0.29096640\n",
            "Iteration 41, loss = 0.27168373\n",
            "Iteration 42, loss = 0.25428139\n",
            "Iteration 43, loss = 0.23835959\n",
            "Iteration 44, loss = 0.22224875\n",
            "Iteration 45, loss = 0.20727309\n",
            "Iteration 46, loss = 0.19424547\n",
            "Iteration 47, loss = 0.18202408\n",
            "Iteration 48, loss = 0.17006874\n",
            "Iteration 49, loss = 0.15970615\n",
            "Iteration 50, loss = 0.15038392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01660514\n",
            "Iteration 2, loss = 1.72435197\n",
            "Iteration 3, loss = 1.62535671\n",
            "Iteration 4, loss = 1.57006474\n",
            "Iteration 5, loss = 1.52900398\n",
            "Iteration 6, loss = 1.49153582\n",
            "Iteration 7, loss = 1.45911712\n",
            "Iteration 8, loss = 1.43096276\n",
            "Iteration 9, loss = 1.39723316\n",
            "Iteration 10, loss = 1.36341546\n",
            "Iteration 11, loss = 1.33310608\n",
            "Iteration 12, loss = 1.29581894\n",
            "Iteration 13, loss = 1.25568798\n",
            "Iteration 14, loss = 1.21995431\n",
            "Iteration 15, loss = 1.18040500\n",
            "Iteration 16, loss = 1.14184926\n",
            "Iteration 17, loss = 1.10232315\n",
            "Iteration 18, loss = 1.06117914\n",
            "Iteration 19, loss = 1.02012429\n",
            "Iteration 20, loss = 0.97634886\n",
            "Iteration 21, loss = 0.93510635\n",
            "Iteration 22, loss = 0.88989900\n",
            "Iteration 23, loss = 0.84654653\n",
            "Iteration 24, loss = 0.80730395\n",
            "Iteration 25, loss = 0.76777520\n",
            "Iteration 26, loss = 0.72069034\n",
            "Iteration 27, loss = 0.68051889\n",
            "Iteration 28, loss = 0.64193781\n",
            "Iteration 29, loss = 0.60588347\n",
            "Iteration 30, loss = 0.56842085\n",
            "Iteration 31, loss = 0.53516987\n",
            "Iteration 32, loss = 0.50232519\n",
            "Iteration 33, loss = 0.46940548\n",
            "Iteration 34, loss = 0.43916498\n",
            "Iteration 35, loss = 0.41126846\n",
            "Iteration 36, loss = 0.38555621\n",
            "Iteration 37, loss = 0.35874587\n",
            "Iteration 38, loss = 0.33588706\n",
            "Iteration 39, loss = 0.31278100\n",
            "Iteration 40, loss = 0.29227031\n",
            "Iteration 41, loss = 0.27311269\n",
            "Iteration 42, loss = 0.25450998\n",
            "Iteration 43, loss = 0.23831996\n",
            "Iteration 44, loss = 0.22268698\n",
            "Iteration 45, loss = 0.20924876\n",
            "Iteration 46, loss = 0.19620656\n",
            "Iteration 47, loss = 0.18319062\n",
            "Iteration 48, loss = 0.17205612\n",
            "Iteration 49, loss = 0.16098090\n",
            "Iteration 50, loss = 0.15158919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00861125\n",
            "Iteration 2, loss = 1.70699243\n",
            "Iteration 3, loss = 1.61236393\n",
            "Iteration 4, loss = 1.56002039\n",
            "Iteration 5, loss = 1.51683284\n",
            "Iteration 6, loss = 1.48093784\n",
            "Iteration 7, loss = 1.45205256\n",
            "Iteration 8, loss = 1.41547475\n",
            "Iteration 9, loss = 1.38289846\n",
            "Iteration 10, loss = 1.35456119\n",
            "Iteration 11, loss = 1.31670947\n",
            "Iteration 12, loss = 1.28253902\n",
            "Iteration 13, loss = 1.24784032\n",
            "Iteration 14, loss = 1.21006912\n",
            "Iteration 15, loss = 1.17275174\n",
            "Iteration 16, loss = 1.13418914\n",
            "Iteration 17, loss = 1.09213619\n",
            "Iteration 18, loss = 1.05164587\n",
            "Iteration 19, loss = 1.01130902\n",
            "Iteration 20, loss = 0.96744963\n",
            "Iteration 21, loss = 0.92177407\n",
            "Iteration 22, loss = 0.88013307\n",
            "Iteration 23, loss = 0.83750425\n",
            "Iteration 24, loss = 0.79459894\n",
            "Iteration 25, loss = 0.75421428\n",
            "Iteration 26, loss = 0.71237541\n",
            "Iteration 27, loss = 0.67204285\n",
            "Iteration 28, loss = 0.63369183\n",
            "Iteration 29, loss = 0.59558562\n",
            "Iteration 30, loss = 0.56019479\n",
            "Iteration 31, loss = 0.52320337\n",
            "Iteration 32, loss = 0.49223033\n",
            "Iteration 33, loss = 0.46057758\n",
            "Iteration 34, loss = 0.42946094\n",
            "Iteration 35, loss = 0.40011995\n",
            "Iteration 36, loss = 0.37543158\n",
            "Iteration 37, loss = 0.34950397\n",
            "Iteration 38, loss = 0.32593386\n",
            "Iteration 39, loss = 0.30509591\n",
            "Iteration 40, loss = 0.28453367\n",
            "Iteration 41, loss = 0.26522708\n",
            "Iteration 42, loss = 0.24840571\n",
            "Iteration 43, loss = 0.23146073\n",
            "Iteration 44, loss = 0.21681787\n",
            "Iteration 45, loss = 0.20204701\n",
            "Iteration 46, loss = 0.18940142\n",
            "Iteration 47, loss = 0.17740640\n",
            "Iteration 48, loss = 0.16632621\n",
            "Iteration 49, loss = 0.15591372\n",
            "Iteration 50, loss = 0.14582943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01080821\n",
            "Iteration 2, loss = 1.71342228\n",
            "Iteration 3, loss = 1.62222536\n",
            "Iteration 4, loss = 1.56533975\n",
            "Iteration 5, loss = 1.52155180\n",
            "Iteration 6, loss = 1.48929947\n",
            "Iteration 7, loss = 1.45564719\n",
            "Iteration 8, loss = 1.42452978\n",
            "Iteration 9, loss = 1.39489606\n",
            "Iteration 10, loss = 1.36029906\n",
            "Iteration 11, loss = 1.32318481\n",
            "Iteration 12, loss = 1.29043927\n",
            "Iteration 13, loss = 1.25491780\n",
            "Iteration 14, loss = 1.22199424\n",
            "Iteration 15, loss = 1.18041665\n",
            "Iteration 16, loss = 1.14091343\n",
            "Iteration 17, loss = 1.10181744\n",
            "Iteration 18, loss = 1.06011138\n",
            "Iteration 19, loss = 1.01744874\n",
            "Iteration 20, loss = 0.97659805\n",
            "Iteration 21, loss = 0.93239462\n",
            "Iteration 22, loss = 0.89161867\n",
            "Iteration 23, loss = 0.84811311\n",
            "Iteration 24, loss = 0.80785310\n",
            "Iteration 25, loss = 0.76429166\n",
            "Iteration 26, loss = 0.72136485\n",
            "Iteration 27, loss = 0.68246142\n",
            "Iteration 28, loss = 0.64079687\n",
            "Iteration 29, loss = 0.60548860\n",
            "Iteration 30, loss = 0.56822338\n",
            "Iteration 31, loss = 0.53529847\n",
            "Iteration 32, loss = 0.50158499\n",
            "Iteration 33, loss = 0.46799386\n",
            "Iteration 34, loss = 0.43882950\n",
            "Iteration 35, loss = 0.40893126\n",
            "Iteration 36, loss = 0.38306860\n",
            "Iteration 37, loss = 0.35692307\n",
            "Iteration 38, loss = 0.33288213\n",
            "Iteration 39, loss = 0.31128685\n",
            "Iteration 40, loss = 0.28952051\n",
            "Iteration 41, loss = 0.27040635\n",
            "Iteration 42, loss = 0.25207380\n",
            "Iteration 43, loss = 0.23694639\n",
            "Iteration 44, loss = 0.22117508\n",
            "Iteration 45, loss = 0.20655634\n",
            "Iteration 46, loss = 0.19324867\n",
            "Iteration 47, loss = 0.18178263\n",
            "Iteration 48, loss = 0.16938777\n",
            "Iteration 49, loss = 0.15875411\n",
            "Iteration 50, loss = 0.14969454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01263880\n",
            "Iteration 2, loss = 1.71409622\n",
            "Iteration 3, loss = 1.62118416\n",
            "Iteration 4, loss = 1.56780961\n",
            "Iteration 5, loss = 1.52742073\n",
            "Iteration 6, loss = 1.49097301\n",
            "Iteration 7, loss = 1.45926065\n",
            "Iteration 8, loss = 1.42807474\n",
            "Iteration 9, loss = 1.39994055\n",
            "Iteration 10, loss = 1.36371082\n",
            "Iteration 11, loss = 1.33276616\n",
            "Iteration 12, loss = 1.29816827\n",
            "Iteration 13, loss = 1.26402368\n",
            "Iteration 14, loss = 1.22526163\n",
            "Iteration 15, loss = 1.19081202\n",
            "Iteration 16, loss = 1.15042406\n",
            "Iteration 17, loss = 1.10918600\n",
            "Iteration 18, loss = 1.07050817\n",
            "Iteration 19, loss = 1.03133357\n",
            "Iteration 20, loss = 0.98527877\n",
            "Iteration 21, loss = 0.94104837\n",
            "Iteration 22, loss = 0.89917373\n",
            "Iteration 23, loss = 0.85490499\n",
            "Iteration 24, loss = 0.81430997\n",
            "Iteration 25, loss = 0.77388697\n",
            "Iteration 26, loss = 0.73105279\n",
            "Iteration 27, loss = 0.68936180\n",
            "Iteration 28, loss = 0.65168724\n",
            "Iteration 29, loss = 0.61531817\n",
            "Iteration 30, loss = 0.57501926\n",
            "Iteration 31, loss = 0.53803390\n",
            "Iteration 32, loss = 0.50665731\n",
            "Iteration 33, loss = 0.47459912\n",
            "Iteration 34, loss = 0.44281000\n",
            "Iteration 35, loss = 0.41479719\n",
            "Iteration 36, loss = 0.38605144\n",
            "Iteration 37, loss = 0.36189455\n",
            "Iteration 38, loss = 0.33744437\n",
            "Iteration 39, loss = 0.31519047\n",
            "Iteration 40, loss = 0.29536581\n",
            "Iteration 41, loss = 0.27472638\n",
            "Iteration 42, loss = 0.25681782\n",
            "Iteration 43, loss = 0.24038896\n",
            "Iteration 44, loss = 0.22437744\n",
            "Iteration 45, loss = 0.20963783\n",
            "Iteration 46, loss = 0.19715015\n",
            "Iteration 47, loss = 0.18391042\n",
            "Iteration 48, loss = 0.17176761\n",
            "Iteration 49, loss = 0.16176229\n",
            "Iteration 50, loss = 0.15171809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03631002\n",
            "Iteration 2, loss = 1.71333863\n",
            "Iteration 3, loss = 1.62270275\n",
            "Iteration 4, loss = 1.56246258\n",
            "Iteration 5, loss = 1.52522307\n",
            "Iteration 6, loss = 1.48961067\n",
            "Iteration 7, loss = 1.45514736\n",
            "Iteration 8, loss = 1.42206756\n",
            "Iteration 9, loss = 1.39432842\n",
            "Iteration 10, loss = 1.36514671\n",
            "Iteration 11, loss = 1.32996450\n",
            "Iteration 12, loss = 1.29589535\n",
            "Iteration 13, loss = 1.25883807\n",
            "Iteration 14, loss = 1.22088015\n",
            "Iteration 15, loss = 1.18946968\n",
            "Iteration 16, loss = 1.14781611\n",
            "Iteration 17, loss = 1.10324596\n",
            "Iteration 18, loss = 1.06536336\n",
            "Iteration 19, loss = 1.02136740\n",
            "Iteration 20, loss = 0.98561577\n",
            "Iteration 21, loss = 0.93865383\n",
            "Iteration 22, loss = 0.89744432\n",
            "Iteration 23, loss = 0.85483456\n",
            "Iteration 24, loss = 0.81646853\n",
            "Iteration 25, loss = 0.76982767\n",
            "Iteration 26, loss = 0.72884942\n",
            "Iteration 27, loss = 0.69084232\n",
            "Iteration 28, loss = 0.65191132\n",
            "Iteration 29, loss = 0.61289384\n",
            "Iteration 30, loss = 0.57716271\n",
            "Iteration 31, loss = 0.54247077\n",
            "Iteration 32, loss = 0.50957586\n",
            "Iteration 33, loss = 0.47722997\n",
            "Iteration 34, loss = 0.44588116\n",
            "Iteration 35, loss = 0.41808142\n",
            "Iteration 36, loss = 0.39108281\n",
            "Iteration 37, loss = 0.36449473\n",
            "Iteration 38, loss = 0.34113733\n",
            "Iteration 39, loss = 0.31956245\n",
            "Iteration 40, loss = 0.29769980\n",
            "Iteration 41, loss = 0.27943008\n",
            "Iteration 42, loss = 0.26029097\n",
            "Iteration 43, loss = 0.24317297\n",
            "Iteration 44, loss = 0.22685914\n",
            "Iteration 45, loss = 0.21179000\n",
            "Iteration 46, loss = 0.19867694\n",
            "Iteration 47, loss = 0.18642124\n",
            "Iteration 48, loss = 0.17414630\n",
            "Iteration 49, loss = 0.16341140\n",
            "Iteration 50, loss = 0.15350972\n",
            "#### Outer Iteration 9 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02607627\n",
            "Iteration 2, loss = 1.72410827\n",
            "Iteration 3, loss = 1.63049943\n",
            "Iteration 4, loss = 1.56987116\n",
            "Iteration 5, loss = 1.52939726\n",
            "Iteration 6, loss = 1.49870207\n",
            "Iteration 7, loss = 1.46804716\n",
            "Iteration 8, loss = 1.43729330\n",
            "Iteration 9, loss = 1.40281797\n",
            "Iteration 10, loss = 1.37033329\n",
            "Iteration 11, loss = 1.33746831\n",
            "Iteration 12, loss = 1.30188070\n",
            "Iteration 13, loss = 1.26622917\n",
            "Iteration 14, loss = 1.23144828\n",
            "Iteration 15, loss = 1.19042268\n",
            "Iteration 16, loss = 1.15352794\n",
            "Iteration 17, loss = 1.11406669\n",
            "Iteration 18, loss = 1.07223011\n",
            "Iteration 19, loss = 1.02996987\n",
            "Iteration 20, loss = 0.98649159\n",
            "Iteration 21, loss = 0.94358336\n",
            "Iteration 22, loss = 0.90212987\n",
            "Iteration 23, loss = 0.85895310\n",
            "Iteration 24, loss = 0.81630350\n",
            "Iteration 25, loss = 0.77427988\n",
            "Iteration 26, loss = 0.73465931\n",
            "Iteration 27, loss = 0.69150272\n",
            "Iteration 28, loss = 0.65305694\n",
            "Iteration 29, loss = 0.61760319\n",
            "Iteration 30, loss = 0.57869176\n",
            "Iteration 31, loss = 0.54122469\n",
            "Iteration 32, loss = 0.50841515\n",
            "Iteration 33, loss = 0.47465716\n",
            "Iteration 34, loss = 0.44535448\n",
            "Iteration 35, loss = 0.41681973\n",
            "Iteration 36, loss = 0.38870812\n",
            "Iteration 37, loss = 0.36240536\n",
            "Iteration 38, loss = 0.33896769\n",
            "Iteration 39, loss = 0.31714554\n",
            "Iteration 40, loss = 0.29543011\n",
            "Iteration 41, loss = 0.27554205\n",
            "Iteration 42, loss = 0.25925374\n",
            "Iteration 43, loss = 0.24101931\n",
            "Iteration 44, loss = 0.22472527\n",
            "Iteration 45, loss = 0.21048455\n",
            "Iteration 46, loss = 0.19697771\n",
            "Iteration 47, loss = 0.18470304\n",
            "Iteration 48, loss = 0.17268408\n",
            "Iteration 49, loss = 0.16210556\n",
            "Iteration 50, loss = 0.15197130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02706202\n",
            "Iteration 2, loss = 1.71737910\n",
            "Iteration 3, loss = 1.61860284\n",
            "Iteration 4, loss = 1.56854986\n",
            "Iteration 5, loss = 1.52456813\n",
            "Iteration 6, loss = 1.49378587\n",
            "Iteration 7, loss = 1.45670118\n",
            "Iteration 8, loss = 1.42488083\n",
            "Iteration 9, loss = 1.39326809\n",
            "Iteration 10, loss = 1.35956645\n",
            "Iteration 11, loss = 1.33102328\n",
            "Iteration 12, loss = 1.29158763\n",
            "Iteration 13, loss = 1.25378388\n",
            "Iteration 14, loss = 1.21794008\n",
            "Iteration 15, loss = 1.18146522\n",
            "Iteration 16, loss = 1.14326593\n",
            "Iteration 17, loss = 1.10016030\n",
            "Iteration 18, loss = 1.05951810\n",
            "Iteration 19, loss = 1.01954283\n",
            "Iteration 20, loss = 0.97291169\n",
            "Iteration 21, loss = 0.93344932\n",
            "Iteration 22, loss = 0.89163894\n",
            "Iteration 23, loss = 0.84863424\n",
            "Iteration 24, loss = 0.80760685\n",
            "Iteration 25, loss = 0.76543012\n",
            "Iteration 26, loss = 0.72274584\n",
            "Iteration 27, loss = 0.68322315\n",
            "Iteration 28, loss = 0.64183306\n",
            "Iteration 29, loss = 0.60456352\n",
            "Iteration 30, loss = 0.56854354\n",
            "Iteration 31, loss = 0.53455710\n",
            "Iteration 32, loss = 0.50318090\n",
            "Iteration 33, loss = 0.46852064\n",
            "Iteration 34, loss = 0.43943191\n",
            "Iteration 35, loss = 0.41224970\n",
            "Iteration 36, loss = 0.38276372\n",
            "Iteration 37, loss = 0.35837695\n",
            "Iteration 38, loss = 0.33684945\n",
            "Iteration 39, loss = 0.31296479\n",
            "Iteration 40, loss = 0.29145522\n",
            "Iteration 41, loss = 0.27325604\n",
            "Iteration 42, loss = 0.25609169\n",
            "Iteration 43, loss = 0.23880725\n",
            "Iteration 44, loss = 0.22311003\n",
            "Iteration 45, loss = 0.20821566\n",
            "Iteration 46, loss = 0.19533201\n",
            "Iteration 47, loss = 0.18246823\n",
            "Iteration 48, loss = 0.17172898\n",
            "Iteration 49, loss = 0.16067575\n",
            "Iteration 50, loss = 0.15084843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01198241\n",
            "Iteration 2, loss = 1.71272403\n",
            "Iteration 3, loss = 1.62115632\n",
            "Iteration 4, loss = 1.56288644\n",
            "Iteration 5, loss = 1.52062531\n",
            "Iteration 6, loss = 1.48547497\n",
            "Iteration 7, loss = 1.45377647\n",
            "Iteration 8, loss = 1.42456090\n",
            "Iteration 9, loss = 1.39102582\n",
            "Iteration 10, loss = 1.35750502\n",
            "Iteration 11, loss = 1.32264989\n",
            "Iteration 12, loss = 1.28760493\n",
            "Iteration 13, loss = 1.25310106\n",
            "Iteration 14, loss = 1.21450098\n",
            "Iteration 15, loss = 1.17575925\n",
            "Iteration 16, loss = 1.13924996\n",
            "Iteration 17, loss = 1.09807037\n",
            "Iteration 18, loss = 1.05464755\n",
            "Iteration 19, loss = 1.01133473\n",
            "Iteration 20, loss = 0.96982037\n",
            "Iteration 21, loss = 0.92462378\n",
            "Iteration 22, loss = 0.88350871\n",
            "Iteration 23, loss = 0.83926964\n",
            "Iteration 24, loss = 0.79882509\n",
            "Iteration 25, loss = 0.75585082\n",
            "Iteration 26, loss = 0.71449416\n",
            "Iteration 27, loss = 0.67567343\n",
            "Iteration 28, loss = 0.63781458\n",
            "Iteration 29, loss = 0.59715401\n",
            "Iteration 30, loss = 0.56251994\n",
            "Iteration 31, loss = 0.52702442\n",
            "Iteration 32, loss = 0.49531344\n",
            "Iteration 33, loss = 0.46333838\n",
            "Iteration 34, loss = 0.43519536\n",
            "Iteration 35, loss = 0.40498443\n",
            "Iteration 36, loss = 0.37928898\n",
            "Iteration 37, loss = 0.35358296\n",
            "Iteration 38, loss = 0.33071188\n",
            "Iteration 39, loss = 0.30935283\n",
            "Iteration 40, loss = 0.28957753\n",
            "Iteration 41, loss = 0.27013785\n",
            "Iteration 42, loss = 0.25211493\n",
            "Iteration 43, loss = 0.23532752\n",
            "Iteration 44, loss = 0.21990522\n",
            "Iteration 45, loss = 0.20505804\n",
            "Iteration 46, loss = 0.19305864\n",
            "Iteration 47, loss = 0.18012814\n",
            "Iteration 48, loss = 0.17023190\n",
            "Iteration 49, loss = 0.15910987\n",
            "Iteration 50, loss = 0.14953938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.99725770\n",
            "Iteration 2, loss = 1.70573193\n",
            "Iteration 3, loss = 1.61194303\n",
            "Iteration 4, loss = 1.55396646\n",
            "Iteration 5, loss = 1.52070464\n",
            "Iteration 6, loss = 1.48323719\n",
            "Iteration 7, loss = 1.45161186\n",
            "Iteration 8, loss = 1.42725112\n",
            "Iteration 9, loss = 1.38325631\n",
            "Iteration 10, loss = 1.35643908\n",
            "Iteration 11, loss = 1.31763271\n",
            "Iteration 12, loss = 1.28736378\n",
            "Iteration 13, loss = 1.25141299\n",
            "Iteration 14, loss = 1.21421741\n",
            "Iteration 15, loss = 1.17505599\n",
            "Iteration 16, loss = 1.13441539\n",
            "Iteration 17, loss = 1.10055981\n",
            "Iteration 18, loss = 1.05767805\n",
            "Iteration 19, loss = 1.01375575\n",
            "Iteration 20, loss = 0.97265727\n",
            "Iteration 21, loss = 0.92919715\n",
            "Iteration 22, loss = 0.88914281\n",
            "Iteration 23, loss = 0.84534034\n",
            "Iteration 24, loss = 0.80098135\n",
            "Iteration 25, loss = 0.76277521\n",
            "Iteration 26, loss = 0.72173888\n",
            "Iteration 27, loss = 0.68351626\n",
            "Iteration 28, loss = 0.64316530\n",
            "Iteration 29, loss = 0.60476487\n",
            "Iteration 30, loss = 0.56810170\n",
            "Iteration 31, loss = 0.53609327\n",
            "Iteration 32, loss = 0.50347513\n",
            "Iteration 33, loss = 0.46926937\n",
            "Iteration 34, loss = 0.43984168\n",
            "Iteration 35, loss = 0.41109573\n",
            "Iteration 36, loss = 0.38492940\n",
            "Iteration 37, loss = 0.36094811\n",
            "Iteration 38, loss = 0.33590545\n",
            "Iteration 39, loss = 0.31357974\n",
            "Iteration 40, loss = 0.29239148\n",
            "Iteration 41, loss = 0.27572346\n",
            "Iteration 42, loss = 0.25611069\n",
            "Iteration 43, loss = 0.23935863\n",
            "Iteration 44, loss = 0.22423381\n",
            "Iteration 45, loss = 0.20923803\n",
            "Iteration 46, loss = 0.19529270\n",
            "Iteration 47, loss = 0.18343934\n",
            "Iteration 48, loss = 0.17191475\n",
            "Iteration 49, loss = 0.16202366\n",
            "Iteration 50, loss = 0.15140671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02272437\n",
            "Iteration 2, loss = 1.71697272\n",
            "Iteration 3, loss = 1.62205630\n",
            "Iteration 4, loss = 1.56441364\n",
            "Iteration 5, loss = 1.52783205\n",
            "Iteration 6, loss = 1.49232459\n",
            "Iteration 7, loss = 1.45785688\n",
            "Iteration 8, loss = 1.42478950\n",
            "Iteration 9, loss = 1.39818826\n",
            "Iteration 10, loss = 1.36151602\n",
            "Iteration 11, loss = 1.33199440\n",
            "Iteration 12, loss = 1.29580162\n",
            "Iteration 13, loss = 1.25783233\n",
            "Iteration 14, loss = 1.22120446\n",
            "Iteration 15, loss = 1.18403155\n",
            "Iteration 16, loss = 1.14359376\n",
            "Iteration 17, loss = 1.10048218\n",
            "Iteration 18, loss = 1.06287671\n",
            "Iteration 19, loss = 1.01915800\n",
            "Iteration 20, loss = 0.97677779\n",
            "Iteration 21, loss = 0.93592489\n",
            "Iteration 22, loss = 0.89039031\n",
            "Iteration 23, loss = 0.85050758\n",
            "Iteration 24, loss = 0.80733076\n",
            "Iteration 25, loss = 0.76613737\n",
            "Iteration 26, loss = 0.72348021\n",
            "Iteration 27, loss = 0.68478619\n",
            "Iteration 28, loss = 0.64727082\n",
            "Iteration 29, loss = 0.60658227\n",
            "Iteration 30, loss = 0.57105855\n",
            "Iteration 31, loss = 0.53735118\n",
            "Iteration 32, loss = 0.50387763\n",
            "Iteration 33, loss = 0.47184733\n",
            "Iteration 34, loss = 0.44288163\n",
            "Iteration 35, loss = 0.41434477\n",
            "Iteration 36, loss = 0.38800247\n",
            "Iteration 37, loss = 0.36139878\n",
            "Iteration 38, loss = 0.33823070\n",
            "Iteration 39, loss = 0.31496057\n",
            "Iteration 40, loss = 0.29394050\n",
            "Iteration 41, loss = 0.27539109\n",
            "Iteration 42, loss = 0.25753502\n",
            "Iteration 43, loss = 0.24098503\n",
            "Iteration 44, loss = 0.22477327\n",
            "Iteration 45, loss = 0.21083144\n",
            "Iteration 46, loss = 0.19733463\n",
            "Iteration 47, loss = 0.18362169\n",
            "Iteration 48, loss = 0.17272233\n",
            "Iteration 49, loss = 0.16192841\n",
            "Iteration 50, loss = 0.15245050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03282675\n",
            "Iteration 2, loss = 1.71249091\n",
            "Iteration 3, loss = 1.61257663\n",
            "Iteration 4, loss = 1.55383144\n",
            "Iteration 5, loss = 1.51440523\n",
            "Iteration 6, loss = 1.47636092\n",
            "Iteration 7, loss = 1.44201430\n",
            "Iteration 8, loss = 1.41296303\n",
            "Iteration 9, loss = 1.37739547\n",
            "Iteration 10, loss = 1.34844460\n",
            "Iteration 11, loss = 1.31042006\n",
            "Iteration 12, loss = 1.27537388\n",
            "Iteration 13, loss = 1.24460449\n",
            "Iteration 14, loss = 1.20976316\n",
            "Iteration 15, loss = 1.16943695\n",
            "Iteration 16, loss = 1.12822075\n",
            "Iteration 17, loss = 1.08720081\n",
            "Iteration 18, loss = 1.04887981\n",
            "Iteration 19, loss = 1.00320556\n",
            "Iteration 20, loss = 0.96260412\n",
            "Iteration 21, loss = 0.92751071\n",
            "Iteration 22, loss = 0.88036963\n",
            "Iteration 23, loss = 0.83542755\n",
            "Iteration 24, loss = 0.79378739\n",
            "Iteration 25, loss = 0.75202342\n",
            "Iteration 26, loss = 0.71427492\n",
            "Iteration 27, loss = 0.67147980\n",
            "Iteration 28, loss = 0.63258362\n",
            "Iteration 29, loss = 0.59652720\n",
            "Iteration 30, loss = 0.55962700\n",
            "Iteration 31, loss = 0.52620874\n",
            "Iteration 32, loss = 0.49401091\n",
            "Iteration 33, loss = 0.46239959\n",
            "Iteration 34, loss = 0.43206609\n",
            "Iteration 35, loss = 0.40440250\n",
            "Iteration 36, loss = 0.37688887\n",
            "Iteration 37, loss = 0.35247505\n",
            "Iteration 38, loss = 0.33030075\n",
            "Iteration 39, loss = 0.30755035\n",
            "Iteration 40, loss = 0.28666444\n",
            "Iteration 41, loss = 0.26765454\n",
            "Iteration 42, loss = 0.25039960\n",
            "Iteration 43, loss = 0.23486480\n",
            "Iteration 44, loss = 0.21884646\n",
            "Iteration 45, loss = 0.20593623\n",
            "Iteration 46, loss = 0.19210478\n",
            "Iteration 47, loss = 0.17951680\n",
            "Iteration 48, loss = 0.16835574\n",
            "Iteration 49, loss = 0.15776609\n",
            "Iteration 50, loss = 0.14814164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03763869\n",
            "Iteration 2, loss = 1.72347650\n",
            "Iteration 3, loss = 1.62599885\n",
            "Iteration 4, loss = 1.56605350\n",
            "Iteration 5, loss = 1.52703377\n",
            "Iteration 6, loss = 1.49270484\n",
            "Iteration 7, loss = 1.45548054\n",
            "Iteration 8, loss = 1.42801212\n",
            "Iteration 9, loss = 1.39840956\n",
            "Iteration 10, loss = 1.36521985\n",
            "Iteration 11, loss = 1.33289866\n",
            "Iteration 12, loss = 1.29874006\n",
            "Iteration 13, loss = 1.26174807\n",
            "Iteration 14, loss = 1.22519542\n",
            "Iteration 15, loss = 1.18666709\n",
            "Iteration 16, loss = 1.14832601\n",
            "Iteration 17, loss = 1.10590701\n",
            "Iteration 18, loss = 1.06935069\n",
            "Iteration 19, loss = 1.02475825\n",
            "Iteration 20, loss = 0.98167983\n",
            "Iteration 21, loss = 0.93957060\n",
            "Iteration 22, loss = 0.89418814\n",
            "Iteration 23, loss = 0.85570383\n",
            "Iteration 24, loss = 0.80990806\n",
            "Iteration 25, loss = 0.76576940\n",
            "Iteration 26, loss = 0.72916417\n",
            "Iteration 27, loss = 0.68554167\n",
            "Iteration 28, loss = 0.64771161\n",
            "Iteration 29, loss = 0.60756339\n",
            "Iteration 30, loss = 0.57185698\n",
            "Iteration 31, loss = 0.53749599\n",
            "Iteration 32, loss = 0.50476406\n",
            "Iteration 33, loss = 0.47068829\n",
            "Iteration 34, loss = 0.44305535\n",
            "Iteration 35, loss = 0.41312384\n",
            "Iteration 36, loss = 0.38683963\n",
            "Iteration 37, loss = 0.36046911\n",
            "Iteration 38, loss = 0.33694765\n",
            "Iteration 39, loss = 0.31572288\n",
            "Iteration 40, loss = 0.29454872\n",
            "Iteration 41, loss = 0.27521447\n",
            "Iteration 42, loss = 0.25624460\n",
            "Iteration 43, loss = 0.23999937\n",
            "Iteration 44, loss = 0.22476802\n",
            "Iteration 45, loss = 0.20979449\n",
            "Iteration 46, loss = 0.19596666\n",
            "Iteration 47, loss = 0.18315152\n",
            "Iteration 48, loss = 0.17218479\n",
            "Iteration 49, loss = 0.16074300\n",
            "Iteration 50, loss = 0.15131667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00923072\n",
            "Iteration 2, loss = 1.71318160\n",
            "Iteration 3, loss = 1.61421440\n",
            "Iteration 4, loss = 1.56096593\n",
            "Iteration 5, loss = 1.51981012\n",
            "Iteration 6, loss = 1.48137534\n",
            "Iteration 7, loss = 1.44904749\n",
            "Iteration 8, loss = 1.41611223\n",
            "Iteration 9, loss = 1.38259757\n",
            "Iteration 10, loss = 1.34813963\n",
            "Iteration 11, loss = 1.31751902\n",
            "Iteration 12, loss = 1.28114502\n",
            "Iteration 13, loss = 1.24838068\n",
            "Iteration 14, loss = 1.20848665\n",
            "Iteration 15, loss = 1.16655721\n",
            "Iteration 16, loss = 1.12871425\n",
            "Iteration 17, loss = 1.09011744\n",
            "Iteration 18, loss = 1.04681900\n",
            "Iteration 19, loss = 1.00782174\n",
            "Iteration 20, loss = 0.96132534\n",
            "Iteration 21, loss = 0.92153144\n",
            "Iteration 22, loss = 0.87613518\n",
            "Iteration 23, loss = 0.83373745\n",
            "Iteration 24, loss = 0.79462909\n",
            "Iteration 25, loss = 0.75196518\n",
            "Iteration 26, loss = 0.71213789\n",
            "Iteration 27, loss = 0.67484253\n",
            "Iteration 28, loss = 0.63315048\n",
            "Iteration 29, loss = 0.59562891\n",
            "Iteration 30, loss = 0.55980510\n",
            "Iteration 31, loss = 0.52619259\n",
            "Iteration 32, loss = 0.49293974\n",
            "Iteration 33, loss = 0.46035481\n",
            "Iteration 34, loss = 0.43086411\n",
            "Iteration 35, loss = 0.40358621\n",
            "Iteration 36, loss = 0.37733010\n",
            "Iteration 37, loss = 0.35224450\n",
            "Iteration 38, loss = 0.32935236\n",
            "Iteration 39, loss = 0.30714169\n",
            "Iteration 40, loss = 0.28665881\n",
            "Iteration 41, loss = 0.26807410\n",
            "Iteration 42, loss = 0.24883822\n",
            "Iteration 43, loss = 0.23322164\n",
            "Iteration 44, loss = 0.21793126\n",
            "Iteration 45, loss = 0.20377328\n",
            "Iteration 46, loss = 0.19056425\n",
            "Iteration 47, loss = 0.17816516\n",
            "Iteration 48, loss = 0.16768599\n",
            "Iteration 49, loss = 0.15654473\n",
            "Iteration 50, loss = 0.14755799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01796429\n",
            "Iteration 2, loss = 1.71587365\n",
            "Iteration 3, loss = 1.61599606\n",
            "Iteration 4, loss = 1.56207434\n",
            "Iteration 5, loss = 1.52220048\n",
            "Iteration 6, loss = 1.48750963\n",
            "Iteration 7, loss = 1.45050269\n",
            "Iteration 8, loss = 1.42567209\n",
            "Iteration 9, loss = 1.38829785\n",
            "Iteration 10, loss = 1.35647128\n",
            "Iteration 11, loss = 1.32070869\n",
            "Iteration 12, loss = 1.28544590\n",
            "Iteration 13, loss = 1.24922488\n",
            "Iteration 14, loss = 1.21180637\n",
            "Iteration 15, loss = 1.17515050\n",
            "Iteration 16, loss = 1.13290756\n",
            "Iteration 17, loss = 1.09459966\n",
            "Iteration 18, loss = 1.05005678\n",
            "Iteration 19, loss = 1.00694155\n",
            "Iteration 20, loss = 0.96119471\n",
            "Iteration 21, loss = 0.92121071\n",
            "Iteration 22, loss = 0.87953001\n",
            "Iteration 23, loss = 0.83547859\n",
            "Iteration 24, loss = 0.79271750\n",
            "Iteration 25, loss = 0.75137665\n",
            "Iteration 26, loss = 0.70970132\n",
            "Iteration 27, loss = 0.67231580\n",
            "Iteration 28, loss = 0.63345692\n",
            "Iteration 29, loss = 0.59390154\n",
            "Iteration 30, loss = 0.55906522\n",
            "Iteration 31, loss = 0.52493759\n",
            "Iteration 32, loss = 0.49092247\n",
            "Iteration 33, loss = 0.46011889\n",
            "Iteration 34, loss = 0.43018923\n",
            "Iteration 35, loss = 0.40197901\n",
            "Iteration 36, loss = 0.37708350\n",
            "Iteration 37, loss = 0.35181207\n",
            "Iteration 38, loss = 0.32831424\n",
            "Iteration 39, loss = 0.30779577\n",
            "Iteration 40, loss = 0.28735837\n",
            "Iteration 41, loss = 0.26705479\n",
            "Iteration 42, loss = 0.25060506\n",
            "Iteration 43, loss = 0.23358836\n",
            "Iteration 44, loss = 0.21816679\n",
            "Iteration 45, loss = 0.20467696\n",
            "Iteration 46, loss = 0.19113994\n",
            "Iteration 47, loss = 0.17989821\n",
            "Iteration 48, loss = 0.16837137\n",
            "Iteration 49, loss = 0.15894173\n",
            "Iteration 50, loss = 0.14837014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03572852\n",
            "Iteration 2, loss = 1.71736622\n",
            "Iteration 3, loss = 1.62175535\n",
            "Iteration 4, loss = 1.56327601\n",
            "Iteration 5, loss = 1.52278303\n",
            "Iteration 6, loss = 1.48784901\n",
            "Iteration 7, loss = 1.45783486\n",
            "Iteration 8, loss = 1.42852984\n",
            "Iteration 9, loss = 1.39397014\n",
            "Iteration 10, loss = 1.35811795\n",
            "Iteration 11, loss = 1.33284435\n",
            "Iteration 12, loss = 1.29645135\n",
            "Iteration 13, loss = 1.26333098\n",
            "Iteration 14, loss = 1.22371883\n",
            "Iteration 15, loss = 1.19004815\n",
            "Iteration 16, loss = 1.14786638\n",
            "Iteration 17, loss = 1.10530480\n",
            "Iteration 18, loss = 1.06298031\n",
            "Iteration 19, loss = 1.02133149\n",
            "Iteration 20, loss = 0.98067983\n",
            "Iteration 21, loss = 0.93530546\n",
            "Iteration 22, loss = 0.89616987\n",
            "Iteration 23, loss = 0.85164144\n",
            "Iteration 24, loss = 0.81389912\n",
            "Iteration 25, loss = 0.77257211\n",
            "Iteration 26, loss = 0.72793692\n",
            "Iteration 27, loss = 0.68717482\n",
            "Iteration 28, loss = 0.64870999\n",
            "Iteration 29, loss = 0.61096386\n",
            "Iteration 30, loss = 0.57593131\n",
            "Iteration 31, loss = 0.54114242\n",
            "Iteration 32, loss = 0.50759633\n",
            "Iteration 33, loss = 0.47515595\n",
            "Iteration 34, loss = 0.44406751\n",
            "Iteration 35, loss = 0.41554230\n",
            "Iteration 36, loss = 0.38876877\n",
            "Iteration 37, loss = 0.36338066\n",
            "Iteration 38, loss = 0.33925890\n",
            "Iteration 39, loss = 0.31664387\n",
            "Iteration 40, loss = 0.29578798\n",
            "Iteration 41, loss = 0.27668689\n",
            "Iteration 42, loss = 0.25942326\n",
            "Iteration 43, loss = 0.24235031\n",
            "Iteration 44, loss = 0.22559930\n",
            "Iteration 45, loss = 0.21154865\n",
            "Iteration 46, loss = 0.19724392\n",
            "Iteration 47, loss = 0.18595234\n",
            "Iteration 48, loss = 0.17381305\n",
            "Iteration 49, loss = 0.16287481\n",
            "Iteration 50, loss = 0.15271909\n",
            "#### Outer Iteration 10 of 10\n",
            "***** cross_val_predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02200554\n",
            "Iteration 2, loss = 1.71697990\n",
            "Iteration 3, loss = 1.62757526\n",
            "Iteration 4, loss = 1.57131675\n",
            "Iteration 5, loss = 1.52884044\n",
            "Iteration 6, loss = 1.49817459\n",
            "Iteration 7, loss = 1.45887351\n",
            "Iteration 8, loss = 1.43212646\n",
            "Iteration 9, loss = 1.39768467\n",
            "Iteration 10, loss = 1.36485976\n",
            "Iteration 11, loss = 1.33120562\n",
            "Iteration 12, loss = 1.30043383\n",
            "Iteration 13, loss = 1.26355990\n",
            "Iteration 14, loss = 1.22411343\n",
            "Iteration 15, loss = 1.18240212\n",
            "Iteration 16, loss = 1.14683599\n",
            "Iteration 17, loss = 1.10621972\n",
            "Iteration 18, loss = 1.06354033\n",
            "Iteration 19, loss = 1.02217405\n",
            "Iteration 20, loss = 0.97811325\n",
            "Iteration 21, loss = 0.93621087\n",
            "Iteration 22, loss = 0.89438389\n",
            "Iteration 23, loss = 0.85042144\n",
            "Iteration 24, loss = 0.80700320\n",
            "Iteration 25, loss = 0.76506239\n",
            "Iteration 26, loss = 0.72590442\n",
            "Iteration 27, loss = 0.68631040\n",
            "Iteration 28, loss = 0.64414919\n",
            "Iteration 29, loss = 0.60680665\n",
            "Iteration 30, loss = 0.57260802\n",
            "Iteration 31, loss = 0.53546694\n",
            "Iteration 32, loss = 0.50278981\n",
            "Iteration 33, loss = 0.46940075\n",
            "Iteration 34, loss = 0.43920001\n",
            "Iteration 35, loss = 0.41141355\n",
            "Iteration 36, loss = 0.38537970\n",
            "Iteration 37, loss = 0.35895937\n",
            "Iteration 38, loss = 0.33599392\n",
            "Iteration 39, loss = 0.31333852\n",
            "Iteration 40, loss = 0.29299089\n",
            "Iteration 41, loss = 0.27319279\n",
            "Iteration 42, loss = 0.25475715\n",
            "Iteration 43, loss = 0.23806156\n",
            "Iteration 44, loss = 0.22242677\n",
            "Iteration 45, loss = 0.20878129\n",
            "Iteration 46, loss = 0.19522595\n",
            "Iteration 47, loss = 0.18325628\n",
            "Iteration 48, loss = 0.17145871\n",
            "Iteration 49, loss = 0.16012177\n",
            "Iteration 50, loss = 0.15060735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02727406\n",
            "Iteration 2, loss = 1.71673343\n",
            "Iteration 3, loss = 1.62103914\n",
            "Iteration 4, loss = 1.56430903\n",
            "Iteration 5, loss = 1.51860517\n",
            "Iteration 6, loss = 1.48090686\n",
            "Iteration 7, loss = 1.45296632\n",
            "Iteration 8, loss = 1.42083794\n",
            "Iteration 9, loss = 1.39201711\n",
            "Iteration 10, loss = 1.35545765\n",
            "Iteration 11, loss = 1.32138506\n",
            "Iteration 12, loss = 1.28425955\n",
            "Iteration 13, loss = 1.24976432\n",
            "Iteration 14, loss = 1.21572566\n",
            "Iteration 15, loss = 1.17607998\n",
            "Iteration 16, loss = 1.13701922\n",
            "Iteration 17, loss = 1.09871948\n",
            "Iteration 18, loss = 1.05513071\n",
            "Iteration 19, loss = 1.01726844\n",
            "Iteration 20, loss = 0.97676719\n",
            "Iteration 21, loss = 0.93293032\n",
            "Iteration 22, loss = 0.88956044\n",
            "Iteration 23, loss = 0.84536646\n",
            "Iteration 24, loss = 0.80472224\n",
            "Iteration 25, loss = 0.76371686\n",
            "Iteration 26, loss = 0.72231170\n",
            "Iteration 27, loss = 0.68404928\n",
            "Iteration 28, loss = 0.64387942\n",
            "Iteration 29, loss = 0.60728692\n",
            "Iteration 30, loss = 0.57158687\n",
            "Iteration 31, loss = 0.53561550\n",
            "Iteration 32, loss = 0.50342070\n",
            "Iteration 33, loss = 0.47137810\n",
            "Iteration 34, loss = 0.44189817\n",
            "Iteration 35, loss = 0.41286833\n",
            "Iteration 36, loss = 0.38701901\n",
            "Iteration 37, loss = 0.36304737\n",
            "Iteration 38, loss = 0.33654048\n",
            "Iteration 39, loss = 0.31414452\n",
            "Iteration 40, loss = 0.29465705\n",
            "Iteration 41, loss = 0.27497059\n",
            "Iteration 42, loss = 0.25721779\n",
            "Iteration 43, loss = 0.24010136\n",
            "Iteration 44, loss = 0.22507847\n",
            "Iteration 45, loss = 0.21070049\n",
            "Iteration 46, loss = 0.19712808\n",
            "Iteration 47, loss = 0.18465451\n",
            "Iteration 48, loss = 0.17298172\n",
            "Iteration 49, loss = 0.16173436\n",
            "Iteration 50, loss = 0.15207310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02518333\n",
            "Iteration 2, loss = 1.72634467\n",
            "Iteration 3, loss = 1.62254998\n",
            "Iteration 4, loss = 1.56574330\n",
            "Iteration 5, loss = 1.52423727\n",
            "Iteration 6, loss = 1.49399992\n",
            "Iteration 7, loss = 1.45857649\n",
            "Iteration 8, loss = 1.42216112\n",
            "Iteration 9, loss = 1.39694865\n",
            "Iteration 10, loss = 1.35781022\n",
            "Iteration 11, loss = 1.32502285\n",
            "Iteration 12, loss = 1.28838513\n",
            "Iteration 13, loss = 1.25247199\n",
            "Iteration 14, loss = 1.21915491\n",
            "Iteration 15, loss = 1.18050553\n",
            "Iteration 16, loss = 1.14457330\n",
            "Iteration 17, loss = 1.10135318\n",
            "Iteration 18, loss = 1.05995284\n",
            "Iteration 19, loss = 1.01847155\n",
            "Iteration 20, loss = 0.97506641\n",
            "Iteration 21, loss = 0.93118984\n",
            "Iteration 22, loss = 0.88982729\n",
            "Iteration 23, loss = 0.85031883\n",
            "Iteration 24, loss = 0.80424935\n",
            "Iteration 25, loss = 0.76275869\n",
            "Iteration 26, loss = 0.72237013\n",
            "Iteration 27, loss = 0.68302237\n",
            "Iteration 28, loss = 0.64545053\n",
            "Iteration 29, loss = 0.61057178\n",
            "Iteration 30, loss = 0.57631121\n",
            "Iteration 31, loss = 0.53759725\n",
            "Iteration 32, loss = 0.50284384\n",
            "Iteration 33, loss = 0.46987452\n",
            "Iteration 34, loss = 0.44256653\n",
            "Iteration 35, loss = 0.41374034\n",
            "Iteration 36, loss = 0.38763506\n",
            "Iteration 37, loss = 0.36229519\n",
            "Iteration 38, loss = 0.33866741\n",
            "Iteration 39, loss = 0.31562796\n",
            "Iteration 40, loss = 0.29494342\n",
            "Iteration 41, loss = 0.27617865\n",
            "Iteration 42, loss = 0.25797597\n",
            "Iteration 43, loss = 0.24119511\n",
            "Iteration 44, loss = 0.22527231\n",
            "Iteration 45, loss = 0.21139644\n",
            "Iteration 46, loss = 0.19880059\n",
            "Iteration 47, loss = 0.18641771\n",
            "Iteration 48, loss = 0.17295021\n",
            "Iteration 49, loss = 0.16282290\n",
            "Iteration 50, loss = 0.15313573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02134926\n",
            "Iteration 2, loss = 1.71336665\n",
            "Iteration 3, loss = 1.61739780\n",
            "Iteration 4, loss = 1.56216843\n",
            "Iteration 5, loss = 1.52137993\n",
            "Iteration 6, loss = 1.48696841\n",
            "Iteration 7, loss = 1.45448560\n",
            "Iteration 8, loss = 1.42042560\n",
            "Iteration 9, loss = 1.39145977\n",
            "Iteration 10, loss = 1.35818186\n",
            "Iteration 11, loss = 1.32547996\n",
            "Iteration 12, loss = 1.29498701\n",
            "Iteration 13, loss = 1.25537200\n",
            "Iteration 14, loss = 1.21906272\n",
            "Iteration 15, loss = 1.17810957\n",
            "Iteration 16, loss = 1.13640125\n",
            "Iteration 17, loss = 1.10190076\n",
            "Iteration 18, loss = 1.05937053\n",
            "Iteration 19, loss = 1.01534692\n",
            "Iteration 20, loss = 0.97498480\n",
            "Iteration 21, loss = 0.93328766\n",
            "Iteration 22, loss = 0.88983061\n",
            "Iteration 23, loss = 0.84505253\n",
            "Iteration 24, loss = 0.80725329\n",
            "Iteration 25, loss = 0.76189173\n",
            "Iteration 26, loss = 0.72265390\n",
            "Iteration 27, loss = 0.68074880\n",
            "Iteration 28, loss = 0.64359349\n",
            "Iteration 29, loss = 0.60381417\n",
            "Iteration 30, loss = 0.56959132\n",
            "Iteration 31, loss = 0.53233585\n",
            "Iteration 32, loss = 0.49954816\n",
            "Iteration 33, loss = 0.46936549\n",
            "Iteration 34, loss = 0.43968506\n",
            "Iteration 35, loss = 0.41026376\n",
            "Iteration 36, loss = 0.38187262\n",
            "Iteration 37, loss = 0.35678956\n",
            "Iteration 38, loss = 0.33341311\n",
            "Iteration 39, loss = 0.31190777\n",
            "Iteration 40, loss = 0.29298394\n",
            "Iteration 41, loss = 0.27203856\n",
            "Iteration 42, loss = 0.25424600\n",
            "Iteration 43, loss = 0.23710311\n",
            "Iteration 44, loss = 0.22226353\n",
            "Iteration 45, loss = 0.20725066\n",
            "Iteration 46, loss = 0.19447975\n",
            "Iteration 47, loss = 0.18197822\n",
            "Iteration 48, loss = 0.17037941\n",
            "Iteration 49, loss = 0.16029677\n",
            "Iteration 50, loss = 0.15008527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.00087987\n",
            "Iteration 2, loss = 1.70998788\n",
            "Iteration 3, loss = 1.61562935\n",
            "Iteration 4, loss = 1.55928266\n",
            "Iteration 5, loss = 1.52497521\n",
            "Iteration 6, loss = 1.48669712\n",
            "Iteration 7, loss = 1.45111055\n",
            "Iteration 8, loss = 1.42095462\n",
            "Iteration 9, loss = 1.39258414\n",
            "Iteration 10, loss = 1.35761490\n",
            "Iteration 11, loss = 1.32440716\n",
            "Iteration 12, loss = 1.29290407\n",
            "Iteration 13, loss = 1.25382890\n",
            "Iteration 14, loss = 1.21710778\n",
            "Iteration 15, loss = 1.17846490\n",
            "Iteration 16, loss = 1.13876947\n",
            "Iteration 17, loss = 1.10314216\n",
            "Iteration 18, loss = 1.05816596\n",
            "Iteration 19, loss = 1.01532764\n",
            "Iteration 20, loss = 0.97534007\n",
            "Iteration 21, loss = 0.93018524\n",
            "Iteration 22, loss = 0.88572081\n",
            "Iteration 23, loss = 0.84574279\n",
            "Iteration 24, loss = 0.80379982\n",
            "Iteration 25, loss = 0.76066831\n",
            "Iteration 26, loss = 0.72051638\n",
            "Iteration 27, loss = 0.68146402\n",
            "Iteration 28, loss = 0.63989220\n",
            "Iteration 29, loss = 0.60408897\n",
            "Iteration 30, loss = 0.56646428\n",
            "Iteration 31, loss = 0.53083533\n",
            "Iteration 32, loss = 0.49913451\n",
            "Iteration 33, loss = 0.46727110\n",
            "Iteration 34, loss = 0.43588758\n",
            "Iteration 35, loss = 0.40865777\n",
            "Iteration 36, loss = 0.38197226\n",
            "Iteration 37, loss = 0.35512454\n",
            "Iteration 38, loss = 0.33213098\n",
            "Iteration 39, loss = 0.31105771\n",
            "Iteration 40, loss = 0.28993832\n",
            "Iteration 41, loss = 0.26905522\n",
            "Iteration 42, loss = 0.25244520\n",
            "Iteration 43, loss = 0.23628192\n",
            "Iteration 44, loss = 0.22122537\n",
            "Iteration 45, loss = 0.20619605\n",
            "Iteration 46, loss = 0.19254596\n",
            "Iteration 47, loss = 0.17997541\n",
            "Iteration 48, loss = 0.16891160\n",
            "Iteration 49, loss = 0.15838092\n",
            "Iteration 50, loss = 0.14854595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.02277979\n",
            "Iteration 2, loss = 1.71793908\n",
            "Iteration 3, loss = 1.61976385\n",
            "Iteration 4, loss = 1.56370581\n",
            "Iteration 5, loss = 1.52587157\n",
            "Iteration 6, loss = 1.48887816\n",
            "Iteration 7, loss = 1.46442062\n",
            "Iteration 8, loss = 1.42633259\n",
            "Iteration 9, loss = 1.39378970\n",
            "Iteration 10, loss = 1.36297763\n",
            "Iteration 11, loss = 1.32679186\n",
            "Iteration 12, loss = 1.29411066\n",
            "Iteration 13, loss = 1.25867102\n",
            "Iteration 14, loss = 1.22212059\n",
            "Iteration 15, loss = 1.18283004\n",
            "Iteration 16, loss = 1.14441374\n",
            "Iteration 17, loss = 1.10645769\n",
            "Iteration 18, loss = 1.06499628\n",
            "Iteration 19, loss = 1.02535786\n",
            "Iteration 20, loss = 0.98177069\n",
            "Iteration 21, loss = 0.93720754\n",
            "Iteration 22, loss = 0.89477865\n",
            "Iteration 23, loss = 0.85251918\n",
            "Iteration 24, loss = 0.80830402\n",
            "Iteration 25, loss = 0.76750418\n",
            "Iteration 26, loss = 0.72676326\n",
            "Iteration 27, loss = 0.68669690\n",
            "Iteration 28, loss = 0.64815873\n",
            "Iteration 29, loss = 0.61124820\n",
            "Iteration 30, loss = 0.57494922\n",
            "Iteration 31, loss = 0.53852548\n",
            "Iteration 32, loss = 0.50613131\n",
            "Iteration 33, loss = 0.47223323\n",
            "Iteration 34, loss = 0.44229467\n",
            "Iteration 35, loss = 0.41449646\n",
            "Iteration 36, loss = 0.38734488\n",
            "Iteration 37, loss = 0.36213415\n",
            "Iteration 38, loss = 0.33918624\n",
            "Iteration 39, loss = 0.31586007\n",
            "Iteration 40, loss = 0.29507415\n",
            "Iteration 41, loss = 0.27560835\n",
            "Iteration 42, loss = 0.25771157\n",
            "Iteration 43, loss = 0.24009389\n",
            "Iteration 44, loss = 0.22441851\n",
            "Iteration 45, loss = 0.21015895\n",
            "Iteration 46, loss = 0.19709746\n",
            "Iteration 47, loss = 0.18392798\n",
            "Iteration 48, loss = 0.17291883\n",
            "Iteration 49, loss = 0.16173962\n",
            "Iteration 50, loss = 0.15202576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03089538\n",
            "Iteration 2, loss = 1.72082936\n",
            "Iteration 3, loss = 1.61999773\n",
            "Iteration 4, loss = 1.56438455\n",
            "Iteration 5, loss = 1.52100292\n",
            "Iteration 6, loss = 1.49008547\n",
            "Iteration 7, loss = 1.45752063\n",
            "Iteration 8, loss = 1.42874146\n",
            "Iteration 9, loss = 1.39324062\n",
            "Iteration 10, loss = 1.35681670\n",
            "Iteration 11, loss = 1.32487236\n",
            "Iteration 12, loss = 1.29190410\n",
            "Iteration 13, loss = 1.25460124\n",
            "Iteration 14, loss = 1.21437354\n",
            "Iteration 15, loss = 1.18004121\n",
            "Iteration 16, loss = 1.14285713\n",
            "Iteration 17, loss = 1.09775605\n",
            "Iteration 18, loss = 1.05767918\n",
            "Iteration 19, loss = 1.01633323\n",
            "Iteration 20, loss = 0.97259116\n",
            "Iteration 21, loss = 0.93030269\n",
            "Iteration 22, loss = 0.88797785\n",
            "Iteration 23, loss = 0.84563341\n",
            "Iteration 24, loss = 0.80443019\n",
            "Iteration 25, loss = 0.76001874\n",
            "Iteration 26, loss = 0.71789884\n",
            "Iteration 27, loss = 0.68013171\n",
            "Iteration 28, loss = 0.64080662\n",
            "Iteration 29, loss = 0.60521703\n",
            "Iteration 30, loss = 0.56789683\n",
            "Iteration 31, loss = 0.53210267\n",
            "Iteration 32, loss = 0.50123717\n",
            "Iteration 33, loss = 0.46830123\n",
            "Iteration 34, loss = 0.43882016\n",
            "Iteration 35, loss = 0.41044745\n",
            "Iteration 36, loss = 0.38452622\n",
            "Iteration 37, loss = 0.35848362\n",
            "Iteration 38, loss = 0.33391881\n",
            "Iteration 39, loss = 0.31220185\n",
            "Iteration 40, loss = 0.29192558\n",
            "Iteration 41, loss = 0.27246002\n",
            "Iteration 42, loss = 0.25480355\n",
            "Iteration 43, loss = 0.23790691\n",
            "Iteration 44, loss = 0.22253295\n",
            "Iteration 45, loss = 0.20760192\n",
            "Iteration 46, loss = 0.19491432\n",
            "Iteration 47, loss = 0.18204959\n",
            "Iteration 48, loss = 0.17133350\n",
            "Iteration 49, loss = 0.15976250\n",
            "Iteration 50, loss = 0.15096007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01636850\n",
            "Iteration 2, loss = 1.71446603\n",
            "Iteration 3, loss = 1.61561134\n",
            "Iteration 4, loss = 1.55666836\n",
            "Iteration 5, loss = 1.51808557\n",
            "Iteration 6, loss = 1.47969594\n",
            "Iteration 7, loss = 1.44909394\n",
            "Iteration 8, loss = 1.41995048\n",
            "Iteration 9, loss = 1.38526079\n",
            "Iteration 10, loss = 1.35395594\n",
            "Iteration 11, loss = 1.32221363\n",
            "Iteration 12, loss = 1.28536203\n",
            "Iteration 13, loss = 1.25129957\n",
            "Iteration 14, loss = 1.21857391\n",
            "Iteration 15, loss = 1.17573443\n",
            "Iteration 16, loss = 1.13941070\n",
            "Iteration 17, loss = 1.09858423\n",
            "Iteration 18, loss = 1.05805264\n",
            "Iteration 19, loss = 1.01173034\n",
            "Iteration 20, loss = 0.97366754\n",
            "Iteration 21, loss = 0.93033943\n",
            "Iteration 22, loss = 0.88590643\n",
            "Iteration 23, loss = 0.84506707\n",
            "Iteration 24, loss = 0.80320853\n",
            "Iteration 25, loss = 0.76184426\n",
            "Iteration 26, loss = 0.72145171\n",
            "Iteration 27, loss = 0.68254485\n",
            "Iteration 28, loss = 0.64388075\n",
            "Iteration 29, loss = 0.60507315\n",
            "Iteration 30, loss = 0.56862897\n",
            "Iteration 31, loss = 0.53230846\n",
            "Iteration 32, loss = 0.50032845\n",
            "Iteration 33, loss = 0.46867783\n",
            "Iteration 34, loss = 0.44267539\n",
            "Iteration 35, loss = 0.41087302\n",
            "Iteration 36, loss = 0.38337548\n",
            "Iteration 37, loss = 0.35855810\n",
            "Iteration 38, loss = 0.33491616\n",
            "Iteration 39, loss = 0.31267700\n",
            "Iteration 40, loss = 0.29176915\n",
            "Iteration 41, loss = 0.27237589\n",
            "Iteration 42, loss = 0.25444385\n",
            "Iteration 43, loss = 0.23726066\n",
            "Iteration 44, loss = 0.22171451\n",
            "Iteration 45, loss = 0.20780605\n",
            "Iteration 46, loss = 0.19444935\n",
            "Iteration 47, loss = 0.18155719\n",
            "Iteration 48, loss = 0.17059045\n",
            "Iteration 49, loss = 0.15952665\n",
            "Iteration 50, loss = 0.14988310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.03355446\n",
            "Iteration 2, loss = 1.72344345\n",
            "Iteration 3, loss = 1.63040261\n",
            "Iteration 4, loss = 1.57392080\n",
            "Iteration 5, loss = 1.52912960\n",
            "Iteration 6, loss = 1.49592794\n",
            "Iteration 7, loss = 1.46231933\n",
            "Iteration 8, loss = 1.43252874\n",
            "Iteration 9, loss = 1.40314047\n",
            "Iteration 10, loss = 1.36460109\n",
            "Iteration 11, loss = 1.33330762\n",
            "Iteration 12, loss = 1.29860958\n",
            "Iteration 13, loss = 1.26617736\n",
            "Iteration 14, loss = 1.23070437\n",
            "Iteration 15, loss = 1.19213247\n",
            "Iteration 16, loss = 1.15403404\n",
            "Iteration 17, loss = 1.11359773\n",
            "Iteration 18, loss = 1.06870229\n",
            "Iteration 19, loss = 1.02822323\n",
            "Iteration 20, loss = 0.98507614\n",
            "Iteration 21, loss = 0.94368609\n",
            "Iteration 22, loss = 0.90307220\n",
            "Iteration 23, loss = 0.85706146\n",
            "Iteration 24, loss = 0.81517304\n",
            "Iteration 25, loss = 0.77152849\n",
            "Iteration 26, loss = 0.73074439\n",
            "Iteration 27, loss = 0.69274885\n",
            "Iteration 28, loss = 0.65284357\n",
            "Iteration 29, loss = 0.61437299\n",
            "Iteration 30, loss = 0.57550550\n",
            "Iteration 31, loss = 0.54069329\n",
            "Iteration 32, loss = 0.50770827\n",
            "Iteration 33, loss = 0.47586108\n",
            "Iteration 34, loss = 0.44446282\n",
            "Iteration 35, loss = 0.41666572\n",
            "Iteration 36, loss = 0.38978810\n",
            "Iteration 37, loss = 0.36160790\n",
            "Iteration 38, loss = 0.33709569\n",
            "Iteration 39, loss = 0.31565441\n",
            "Iteration 40, loss = 0.29524194\n",
            "Iteration 41, loss = 0.27472781\n",
            "Iteration 42, loss = 0.25599574\n",
            "Iteration 43, loss = 0.23950869\n",
            "Iteration 44, loss = 0.22451762\n",
            "Iteration 45, loss = 0.21076711\n",
            "Iteration 46, loss = 0.19657936\n",
            "Iteration 47, loss = 0.18367886\n",
            "Iteration 48, loss = 0.17195200\n",
            "Iteration 49, loss = 0.16107866\n",
            "Iteration 50, loss = 0.15101462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.01290481\n",
            "Iteration 2, loss = 1.70853835\n",
            "Iteration 3, loss = 1.61761835\n",
            "Iteration 4, loss = 1.55871982\n",
            "Iteration 5, loss = 1.51913871\n",
            "Iteration 6, loss = 1.48949922\n",
            "Iteration 7, loss = 1.45552485\n",
            "Iteration 8, loss = 1.42143776\n",
            "Iteration 9, loss = 1.39376758\n",
            "Iteration 10, loss = 1.35873723\n",
            "Iteration 11, loss = 1.32513676\n",
            "Iteration 12, loss = 1.29359363\n",
            "Iteration 13, loss = 1.25703324\n",
            "Iteration 14, loss = 1.21845368\n",
            "Iteration 15, loss = 1.18191706\n",
            "Iteration 16, loss = 1.14098323\n",
            "Iteration 17, loss = 1.10396987\n",
            "Iteration 18, loss = 1.06485414\n",
            "Iteration 19, loss = 1.02201161\n",
            "Iteration 20, loss = 0.98005594\n",
            "Iteration 21, loss = 0.94009609\n",
            "Iteration 22, loss = 0.89789640\n",
            "Iteration 23, loss = 0.85474935\n",
            "Iteration 24, loss = 0.81582756\n",
            "Iteration 25, loss = 0.77106814\n",
            "Iteration 26, loss = 0.73199674\n",
            "Iteration 27, loss = 0.69097574\n",
            "Iteration 28, loss = 0.65273291\n",
            "Iteration 29, loss = 0.61278051\n",
            "Iteration 30, loss = 0.57692563\n",
            "Iteration 31, loss = 0.54341976\n",
            "Iteration 32, loss = 0.51057104\n",
            "Iteration 33, loss = 0.47848106\n",
            "Iteration 34, loss = 0.44662053\n",
            "Iteration 35, loss = 0.41828261\n",
            "Iteration 36, loss = 0.39197286\n",
            "Iteration 37, loss = 0.36658568\n",
            "Iteration 38, loss = 0.34239452\n",
            "Iteration 39, loss = 0.32021916\n",
            "Iteration 40, loss = 0.29871677\n",
            "Iteration 41, loss = 0.27884026\n",
            "Iteration 42, loss = 0.26078199\n",
            "Iteration 43, loss = 0.24380425\n",
            "Iteration 44, loss = 0.22803755\n",
            "Iteration 45, loss = 0.21406507\n",
            "Iteration 46, loss = 0.19912538\n",
            "Iteration 47, loss = 0.18679529\n",
            "Iteration 48, loss = 0.17461672\n",
            "Iteration 49, loss = 0.16405068\n",
            "Iteration 50, loss = 0.15384387\n",
            "SVM Outer accuracy M = 40.01, SD = 0.2472\n",
            "SVM Outer F1-Score M = 0.397, SD = 0.0025\n",
            "SVM Outer MCC      M = 0.333, SD = 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "n_outer =  10 # this should be 10 for the \"10\"x 10 CV, you could use a smaller values, say 2, for prototyping\n",
        "n_splits = 10 # this should be 10 for the 10 x \"10\" CV, you could use a smaller values, say 2, for prototyping\n",
        "acc_outer_svm = []\n",
        "f1_outer_svm  = []\n",
        "mcc_outer_svm  = []\n",
        "\n",
        "hidden_layer_sizes = 500\n",
        "activation_fcn = 'logistic'  #change params to test top params\n",
        "max_iter = 50\n",
        "\n",
        "for i_outer in range(0,n_outer):\n",
        "\n",
        "  print('#### Outer Iteration {} of {}'.format(i_outer+1,n_outer))\n",
        "\n",
        "  # shuffle the dataset every time we do the 10 CV (we really want to be random)\n",
        "  X_shuf, y_shuf = shuffle(Xtrain_pca, ytrain_labels)\n",
        "\n",
        "  # create a pipeline classifier model based on the best parameters (USE BEST PARAMS FROM GRID SEARCH)\n",
        "  model = MLPClassifier(hidden_layer_sizes=(hidden_layer_sizes), activation=activation_fcn,\n",
        "                    max_iter=max_iter,\n",
        "                    solver='adam', verbose=1,\n",
        "                    random_state=None,\n",
        "                    tol=0.00001, n_iter_no_change=20)\n",
        "\n",
        "  # stratification is always a must!\n",
        "  skf = StratifiedKFold(n_splits=n_splits,shuffle=True) # inner 10\n",
        "\n",
        "  # cross_val_predict returns the predictions for the folds\n",
        "  print('***** cross_val_predict')\n",
        "  y_pred = cross_val_predict(model, X_shuf, y_shuf, cv=skf, verbose=0)\n",
        "\n",
        "  acc = accuracy_score(y_shuf,y_pred)\n",
        "  f1 = f1_score(y_shuf,y_pred,average='macro')\n",
        "  mcc = matthews_corrcoef(y_shuf,y_pred)\n",
        "  mat = confusion_matrix(y_shuf, y_pred)\n",
        "\n",
        "  acc_outer_svm.append(acc)\n",
        "  f1_outer_svm.append(f1)\n",
        "  mcc_outer_svm.append(mcc)\n",
        "\n",
        "print('SVM Outer accuracy M = {:.2f}, SD = {:.4f}'.format(np.mean(acc_outer_svm)*100,np.std(acc_outer_svm)*100))\n",
        "print('SVM Outer F1-Score M = {:.3f}, SD = {:.4f}'.format(np.mean(f1_outer_svm),np.std(f1_outer_svm)))\n",
        "print('SVM Outer MCC      M = {:.3f}, SD = {:.4f}'.format(np.mean(mcc_outer_svm),np.std(mcc_outer_svm)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziC17omtAV-l"
      },
      "source": [
        "***10X10 Cross Validation SVM Model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D6D77rvAah9",
        "outputId": "03f917b0-d32d-4f4e-c212-22b3e3a3660c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Outer Iteration 1 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 2 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 3 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 4 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 5 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 6 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 7 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 8 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 9 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]#### Outer Iteration 10 of 10\n",
            "***** cross_val_predict\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]SVM Outer accuracy M = 46.04, SD = 0.3041\n",
            "SVM Outer F1-Score M = 0.461, SD = 0.0029\n",
            "SVM Outer MCC      M = 0.401, SD = 0.0034\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "n_outer =  10 # this should be 10 for the \"10\"x 10 CV, you could use a smaller values, say 2, for prototyping\n",
        "n_splits = 10 # this should be 10 for the 10 x \"10\" CV, you could use a smaller values, say 2, for prototyping\n",
        "acc_outer_svm = []\n",
        "f1_outer_svm  = []\n",
        "mcc_outer_svm  = []\n",
        "\n",
        "for i_outer in range(0,n_outer):\n",
        "\n",
        "  print('#### Outer Iteration {} of {}'.format(i_outer+1,n_outer))\n",
        "\n",
        "  # shuffle the dataset every time we do the 10 CV (we really want to be random)\n",
        "  X_shuf, y_shuf = shuffle(Xtrain_pca, ytrain_labels)\n",
        "\n",
        "  # create a pipeline classifier model based on the best parameters (USE BEST PARAMS FROM GRID SEARCH)\n",
        "  model = SVC(kernel='rbf', C=100.0, gamma='scale', verbose=True, random_state=None)\n",
        "\n",
        "  # stratification is always a must!\n",
        "  skf = StratifiedKFold(n_splits=n_splits,shuffle=True) # inner 10\n",
        "\n",
        "  # cross_val_predict returns the predictions for the folds\n",
        "  print('***** cross_val_predict')\n",
        "  y_pred = cross_val_predict(model, X_shuf, y_shuf, cv=skf, verbose=0)\n",
        "\n",
        "  acc = accuracy_score(y_shuf,y_pred)\n",
        "  f1 = f1_score(y_shuf,y_pred,average='macro')\n",
        "  mcc = matthews_corrcoef(y_shuf,y_pred)\n",
        "  mat = confusion_matrix(y_shuf, y_pred)\n",
        "\n",
        "  acc_outer_svm.append(acc)\n",
        "  f1_outer_svm.append(f1)\n",
        "  mcc_outer_svm.append(mcc)\n",
        "\n",
        "print('SVM Outer accuracy M = {:.2f}, SD = {:.4f}'.format(np.mean(acc_outer_svm)*100,np.std(acc_outer_svm)*100))\n",
        "print('SVM Outer F1-Score M = {:.3f}, SD = {:.4f}'.format(np.mean(f1_outer_svm),np.std(f1_outer_svm)))\n",
        "print('SVM Outer MCC      M = {:.3f}, SD = {:.4f}'.format(np.mean(mcc_outer_svm),np.std(mcc_outer_svm)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUnAt_YKPjp"
      },
      "source": [
        "The number of instances/examples for all the different classes.  There are 10 different classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzPW7rHbANj8"
      },
      "source": [
        "***LEFT OVER STARTER CODE THAT WAS SUPPLIED BELOW***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-uX5AZmQG9N"
      },
      "outputs": [],
      "source": [
        "[np.sum(np.argmax(y, axis=1) == i) for i in range(0,10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_HIgldKlsd"
      },
      "source": [
        "The labels for the classes are stored in the `batches.meta` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HKjGtxStmcz"
      },
      "outputs": [],
      "source": [
        "class_labels = load_CIFAR_meta('/content/drive/MyDrive/cifar-10-batches-py/batches.meta')\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNjse_BTLnx"
      },
      "source": [
        "Let's look at some random cat images, because cats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoI3IO7KTjMg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_random(X, y, class_labels, what_target='cat'):\n",
        "\n",
        "  what_label = class_labels.index(what_target)\n",
        "  what_labeli = np.where(np.argmax(y,axis=1) == what_label)[0]\n",
        "  random_what_index = what_labeli[random.choice(range(len(what_labeli)))]\n",
        "\n",
        "  plt.imshow(get_image(X,random_what_index))\n",
        "  plt.title('{}, index: {}'.format(what_target,random_what_index))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AiPII3JUm3R"
      },
      "outputs": [],
      "source": [
        "plot_random(X, y, class_labels, what_target='cat')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v557teUwb50v"
      },
      "source": [
        "## Set up and train MLP (OLD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZk2OEWpb83j"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# split into train and test\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,stratify=y)\n",
        "\n",
        "\n",
        "hidden_layer_sizes = 100\n",
        "activation_fcn = 'relu' # {identity, logistic, tanh, relu}, default='relu'\n",
        "max_iter=200\n",
        "\n",
        "# model initialization\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(hidden_layer_sizes), activation=activation_fcn,\n",
        "                    max_iter=max_iter, #try change hidden layer, or max_iter\n",
        "                    solver='adam', verbose=1,   #try verbose=0 to train with out logging\n",
        "                    random_state=None,\n",
        "                    tol=0.00001,n_iter_no_change=20) # decreasing tol and increasing no_change will train the network 'harder' and usually longer\n",
        "\n",
        "mlp.fit(Xtrain, ytrain)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfDHhSUYA3cw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZI49FpD0vlU"
      },
      "source": [
        "## Evaluate the performance of the classfier\n",
        "\n",
        "\n",
        "\n",
        "Need to remember to use `predict_proba` for the multiclass classification and apply a softmax/argmax to the output (i.e. choose the largest probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJURHGV04kT"
      },
      "source": [
        "### Test it out on a random image from the training data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpnHovVgZWmt"
      },
      "outputs": [],
      "source": [
        "idx = random.choice(range(Xtrain_scaled.shape[0]))\n",
        "print('Image Index: ',idx)\n",
        "\n",
        "# make sure you use predict_proba for the multi-class classification\n",
        "ypreda = mlp.predict_proba(Xtrain_scaled)\n",
        "print('Probability of class: {}'.format((ypreda[idx,:]*100).astype(int)))\n",
        "ypred = np.argmax(ypreda[idx,:], axis=0)\n",
        "ytrue = np.argmax(ytrain[idx,:], axis=0)\n",
        "print('real class     : ',ytrue,'=>',class_labels[ytrue])\n",
        "print('predicted class: ',ypred,'=>',class_labels[ypred])\n",
        "\n",
        "\n",
        "plt.imshow(get_image(Xtrain_scaled,idx))\n",
        "plt.title('Index: {}, R {}, P: {}'.format(idx,class_labels[ytrue],class_labels[ypred]))\n",
        "plt.axis('off');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGIomVQ50cKF"
      },
      "source": [
        "### Evaluate the performance on the whole training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlZcs-1Kem3J"
      },
      "outputs": [],
      "source": [
        "ytrue = np.argmax(ytrain, axis=1)\n",
        "ypreda = mlp.predict_proba(Xtrain_pca)\n",
        "ypred = np.argmax(ypreda, axis=1)\n",
        "report = classification_report(ytrue, ypred)\n",
        "print(report)\n",
        "\n",
        "mat = confusion_matrix(ytrue,ypred)\n",
        "print(mat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miVFoBeX1F_k"
      },
      "source": [
        "### Evaluate on the performance on testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6-UC3c9iIry"
      },
      "outputs": [],
      "source": [
        "ytrue = np.argmax(ytest, axis=1)\n",
        "ypreda = mlp.predict_proba(Xtest_pca)\n",
        "ypred = np.argmax(ypreda, axis=1)\n",
        "report = classification_report(ytrue, ypred)\n",
        "print(report)\n",
        "\n",
        "mat = confusion_matrix(ytrue,ypred)\n",
        "print(mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1glCdfrjwyXD"
      },
      "source": [
        "## Try just classifying two classes\n",
        "\n",
        "Classfiying all 10 classes can be challenging.  Let's try a simplier task of classfiy just two distinct classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZVydf5gA5Bl"
      },
      "outputs": [],
      "source": [
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPoE0JeNm_Lb"
      },
      "outputs": [],
      "source": [
        "one_target = 'frog'\n",
        "one_label = class_labels.index(one_target)\n",
        "print('Choose ', class_labels[one_label],'as the first class')\n",
        "one_labeli = np.where(np.argmax(y,axis=1) == one_label)[0]\n",
        "print('There are {} instances for the label {}'.format(len(one_labeli),one_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXYZS8udyfNp"
      },
      "outputs": [],
      "source": [
        "two_target = 'horse'\n",
        "two_label = class_labels.index(two_target)\n",
        "print('Choose ', class_labels[two_label],'as the first class')\n",
        "two_labeli = np.where(np.argmax(y,axis=1) == two_label)[0]\n",
        "print('There are {} instances for the label {}'.format(len(two_labeli),two_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWyPyJg9zGN8"
      },
      "outputs": [],
      "source": [
        "alli = np.hstack((one_labeli,two_labeli))\n",
        "Xsubset = X[alli,:]\n",
        "\n",
        "# construct a new y with just the one and two label\n",
        "ysubset = y[alli,:]\n",
        "yclass = np.argmax(ysubset,axis=1)\n",
        "yclass[yclass == one_label] = 1\n",
        "yclass[yclass == two_label] = 2\n",
        "print(yclass)\n",
        "ysubset = pd.get_dummies(yclass).values\n",
        "print(ysubset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6bJyAfh-5r4"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYOVtRse02Jd"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# split into train and test\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(Xsubset, ysubset,stratify=ysubset)\n",
        "\n",
        "\n",
        "hidden_layer_sizes = 100\n",
        "activation_fcn = 'relu' # {identity, logistic, tanh, relu}, default='relu'\n",
        "max_iter=200\n",
        "\n",
        "# model initialization\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(hidden_layer_sizes), activation=activation_fcn,\n",
        "                    max_iter=max_iter, #try change hidden layer, or max_iter\n",
        "                    solver='adam', verbose=1,   #try verbose=0 to train with out logging\n",
        "                    random_state=None,\n",
        "                    tol=0.00001,n_iter_no_change=20) # decreasing tol and increasing no_change will train the network 'harder' and usually longer\n",
        "\n",
        "mlp.fit(Xtrain, ytrain)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfLqOod0-33z"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGMQsFPF1QyZ"
      },
      "outputs": [],
      "source": [
        "print('### Training ###')\n",
        "ytrue = np.argmax(ytrain, axis=1)\n",
        "ypred = mlp.predict(Xtrain)\n",
        "ypred = np.argmax(ypred, axis=1)\n",
        "report = classification_report(ytrue, ypred)\n",
        "print(report)\n",
        "\n",
        "mat = confusion_matrix(ytrue,ypred)\n",
        "print(mat)\n",
        "print()\n",
        "print('### Testing ###')\n",
        "ytrue = np.argmax(ytest, axis=1)\n",
        "ypred = mlp.predict(Xtest)\n",
        "ypred = np.argmax(ypred, axis=1)\n",
        "report = classification_report(ytrue, ypred)\n",
        "print(report)\n",
        "mat = confusion_matrix(ytrue,ypred)\n",
        "print(mat)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}