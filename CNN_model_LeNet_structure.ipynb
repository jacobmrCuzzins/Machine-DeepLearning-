{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobmrCuzzins/Machine-DeepLearning-/blob/main/CNN_model_LeNet_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Model based on the LeNet layer structure"
      ],
      "metadata": {
        "id": "DalqN-RjXXiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below notebook shows my implementation of the LeNet structure to see how efficient it may be on image classification when compared to a basic CNN or MLP model"
      ],
      "metadata": {
        "id": "zavB-YxwXmWx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC0Dh4dwQ0Iq"
      },
      "source": [
        "## Accessing Data from Google Drive\n",
        "The dataset for this assignment is the CIFAR-10 dataset that can be found here:\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "The CIFAR-10 and CIFAR-100 are well studied, yet challenging image recognition dataset. The CIFAR-10 has up to 10 classes to classify and contains 60,000 32x32 images. You should read the description of the dataset and download the dataset for Python, that is\n",
        "\n",
        "CIFAR-10 python version: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "\n",
        "Once downloaded you need to then extract and upload the `cifar-10-batches-py` directory your Google Drive so that you can access it from within your Google Colab.\n",
        "\n",
        "You can mount the Google Drive from the menu on the left or uncomment use the code below mount the drive.  See here for documentation on file access in Colab:\n",
        "\n",
        "[External data: Local Files, Drive, Sheets, and Cloud Storage](https://colab.research.google.com/notebooks/io.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqR-k4UDDltb",
        "outputId": "679ea9b0-06b0-4ce3-b625-37d51a5d592a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s7DsaxDI2im"
      },
      "source": [
        "## Functions to work with CIFAR\n",
        "\n",
        "The functions below help with access to the CIFAR-10 data the you have downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUSVhQr5KDv1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def load_CIFAR_batch(filename, flatten=True, categorical=True):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X = datadict[b'data']\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
        "        if (flatten):\n",
        "          X = X.reshape(10000, 3072)\n",
        "        X = X.astype('float32')\n",
        "        X /= 255\n",
        "\n",
        "        y = datadict[b'labels']\n",
        "        y = np.array(y)\n",
        "        if (categorical):\n",
        "          y = pd.get_dummies(y).values\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def load_CIFAR_meta(filename):\n",
        "  with open(filename,'rb') as f:\n",
        "    metadict = pickle.load(f, encoding='bytes')\n",
        "\n",
        "    class_labels = [ val.decode() for val in metadict.get(b'label_names') ]\n",
        "    return class_labels\n",
        "\n",
        "def get_image(X, index, nchans=3, size=32):\n",
        "  xi = X[index,:]\n",
        "  img = xi.reshape(32, 32, 3)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axqceDnNJVss"
      },
      "source": [
        "## Load the CIFAR data\n",
        "\n",
        "The CIFAR data has 5 batches of data and 1 test data set. Each batch is labelled\n",
        "- `data_batch_1`\n",
        "- `data_batch_2`\n",
        "- `data_batch_3`\n",
        "- `data_batch_4`\n",
        "- `data_batch_5`\n",
        "\n",
        "and a test set labelled\n",
        "- `test_batch`\n",
        "\n",
        "each batch has 10,000 images, so 50,000 training and 10,000 test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2X0_Oz_SkHi"
      },
      "source": [
        "Below is example of loading the first batch of training data labelled as `data_batch_1`.  You will need to update the path to match where you have stored your cifar-10 data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SzM-lMGRVDr"
      },
      "source": [
        "LOADING ONLY ONE BATCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sFJMu_JNZaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37811ca0-ac9c-47eb-cfb4-e78c3ff16eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 10000 instances of images\n"
          ]
        }
      ],
      "source": [
        "X, y = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_1', flatten = False)\n",
        "\n",
        "# split into train and test\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)\n",
        "\n",
        "# Create 1d version for testing accuracy\n",
        "ytrain_1d = np.argmax(ytrain, axis=1)\n",
        "ytest_1d = np.argmax(ytest, axis=1)\n",
        "\n",
        "print('We have {} instances of images'.format(y.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_c-D8WgRZQ9"
      },
      "source": [
        "TO LOAD THE FULL BATCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SudeLpyHCd-X",
        "outputId": "a11125a7-a8dd-4f30-8ed1-459af91f9982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 50000 instances of images\n"
          ]
        }
      ],
      "source": [
        "flatten = False\n",
        "categorical = True\n",
        "\n",
        "# load only the first batch\n",
        "#X1, y1 = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_1',flatten=flatten,categorical=categorical)\n",
        "\n",
        "# load only the second batch\n",
        "#X2, y2 = load_CIFAR_batch('/content/drive/My Drive/COMP2712/data/cifar-10-batches-py/data_batch_2',flatten=flatten,categorical=categorical)\n",
        "\n",
        "# Load the first batch from CIFAR-10\n",
        "X, y = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_1',flatten= False ,categorical=categorical)\n",
        "\n",
        "# iterate over 2 to 5\n",
        "for bi in range(2,6):\n",
        "  # load the next data set 'bi'\n",
        "  X2, y2 = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/data_batch_{}'.format(bi),flatten=flatten,categorical=categorical)\n",
        "\n",
        "  # concatenate/stack the dataest together\n",
        "  X = np.vstack([X, X2])\n",
        "  y = np.vstack([y, y2])\n",
        "\n",
        " #Load the test data into test variables\n",
        "Xtest, ytest = load_CIFAR_batch('/content/drive/My Drive/cifar-10-batches-py/test_batch', flatten=False)\n",
        "\n",
        "# Create 1d version for testing accuracy\n",
        "ytrain_1d = np.argmax(y, axis=1)\n",
        "ytest_1d = np.argmax(ytest, axis=1)\n",
        "\n",
        "print('We have {} instances of images'.format(y.shape[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUnAt_YKPjp"
      },
      "source": [
        "The number of instances/examples for all the different classes.  There are 10 different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-uX5AZmQG9N",
        "outputId": "7177d2e4-c4e7-489e-d25b-1dad2dcc2853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "[np.sum(np.argmax(y, axis=1) == i) for i in range(0,10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_HIgldKlsd"
      },
      "source": [
        "The labels for the classes are stored in the `batches.meta` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HKjGtxStmcz",
        "outputId": "1a393891-b713-450a-8588-affcedc5244f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "class_labels = load_CIFAR_meta('/content/drive/My Drive/cifar-10-batches-py/batches.meta')\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-jVltLJGonf"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn evaluation packages\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "9bwk5ub400KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZUEy4WrReuh"
      },
      "source": [
        "**BUILD THE CNN MODEL FROM ASSIGNMENT SHEET**\n",
        "\n",
        "This is the CNN Model built from the given structure in the assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O-WATT2RNkE"
      },
      "outputs": [],
      "source": [
        "X_flatten = X.reshape((50000, -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet Implementation**"
      ],
      "metadata": {
        "id": "NXj5TQ9BPir8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout\n",
        "\n",
        "model_lenet = Sequential()\n",
        "\n",
        "# Layer 1: Convolutional Layer\n",
        "model_lenet.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
        "\n",
        "# Layer 2: Average Pooling\n",
        "model_lenet.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Layer 3: Convolutional Layer\n",
        "model_lenet.add(Conv2D(16, kernel_size=(5, 5), activation='relu', padding='valid'))\n",
        "\n",
        "# Layer 4: Average Pooling\n",
        "model_lenet.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Layer 5: Flatten (Flatten)\n",
        "model_lenet.add(Flatten())\n",
        "\n",
        "# Layer 6: Fully Connected Layer\n",
        "model_lenet.add(Dense(120, activation='relu'))\n",
        "\n",
        "# Layer 8: Fully Connected Layer\n",
        "model_lenet.add(Dense(84, activation='relu'))\n",
        "\n",
        "# Layer 9: Output Layer\n",
        "model_lenet.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_lenet.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=keras.metrics.categorical_crossentropy)\n",
        "\n",
        "model_lenet.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yyxy9lPl-A",
        "outputId": "6d324265-d68a-495c-e194-908adab8a8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " average_pooling2d (Average  (None, 16, 16, 6)         0         \n",
            " Pooling2D)                                                      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Avera  (None, 6, 6, 16)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               69240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83126 (324.71 KB)\n",
            "Trainable params: 83126 (324.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified K-Fold Evaluation of the model**"
      ],
      "metadata": {
        "id": "Sszgh7sEMmKS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-OmFp9DMl34",
        "outputId": "48e5f793-c1fb-48e9-ac27-1670e73cca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with relu for 5 for fold 1 or 5\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 22s 6ms/step - loss: 1.6573 - categorical_crossentropy: 1.6573\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3629 - categorical_crossentropy: 1.3629\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2560 - categorical_crossentropy: 1.2560\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1828 - categorical_crossentropy: 1.1828\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1171 - categorical_crossentropy: 1.1171\n",
            "\n",
            "Final Loss on training set: 1.057\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "accuracy is 57.79%\n",
            "\n",
            "Training with relu for 5 for fold 2 or 5\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0595 - categorical_crossentropy: 1.0595\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0107 - categorical_crossentropy: 1.0107\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9683 - categorical_crossentropy: 0.9683\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9286 - categorical_crossentropy: 0.9286\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8895 - categorical_crossentropy: 0.8895\n",
            "\n",
            "Final Loss on training set: 0.943\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "accuracy is 61.42%\n",
            "\n",
            "Training with relu for 5 for fold 3 or 5\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8485 - categorical_crossentropy: 0.8485\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8212 - categorical_crossentropy: 0.8212\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7887 - categorical_crossentropy: 0.7887\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7601 - categorical_crossentropy: 0.7601\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7291 - categorical_crossentropy: 0.7291\n",
            "\n",
            "Final Loss on training set: 0.854\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "accuracy is 61.33%\n",
            "\n",
            "Training with relu for 5 for fold 4 or 5\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7038 - categorical_crossentropy: 0.7038\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6744 - categorical_crossentropy: 0.6744\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6526 - categorical_crossentropy: 0.6526\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6291 - categorical_crossentropy: 0.6291\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6092 - categorical_crossentropy: 0.6092\n",
            "\n",
            "Final Loss on training set: 0.781\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "accuracy is 61.36%\n",
            "\n",
            "Training with relu for 5 for fold 5 or 5\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5829 - categorical_crossentropy: 0.5829\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5653 - categorical_crossentropy: 0.5653\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5431 - categorical_crossentropy: 0.5431\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5230 - categorical_crossentropy: 0.5230\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5057 - categorical_crossentropy: 0.5057\n",
            "\n",
            "Final Loss on training set: 0.711\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "accuracy is 61.26%\n",
            "\n",
            "Average Accuracy: 60.63%\n",
            "Standard Deviation of Accuracy: 1.42%\n",
            "k-fold complete!\n"
          ]
        }
      ],
      "source": [
        "# sklearn evaluation packages\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "# Stratified K-Fold for evaluation of generalisation performance\n",
        "k = 5 # 10 is the gold standard\n",
        "kf = StratifiedKFold(n_splits=k)\n",
        "foldi = 1\n",
        "ac = [] # accuracy_score\n",
        "cr = [] # classification_report\n",
        "cm = [] # confusion_matrix\n",
        "y_test_max_all = []\n",
        "y_pred_max_all = []\n",
        "\n",
        "activation = 'relu'\n",
        "no_epochs = 5\n",
        "\n",
        "\n",
        "for train_index, test_index in kf.split(X_flatten,ytrain_1d):\n",
        "\n",
        "  print('Training with {0} for {1} for fold {2} or {3}'.format(activation, no_epochs, foldi, k))\n",
        "  history = model_lenet.fit(X, y, epochs=no_epochs, verbose=1)\n",
        "\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  loss_final = np.sqrt(float(hist['loss'].tail(1)))\n",
        "  print()\n",
        "  print('Final Loss on training set: {}'.format(round(loss_final, 3)))\n",
        "\n",
        "  # evaluate the model\n",
        "  y_pred_real = model_lenet.predict(Xtest)\n",
        "  y_pred_max = np.argmax(y_pred_real, axis=-1).astype(int)\n",
        "  y_test_max = ytest.argmax(axis=1).astype(int)\n",
        "\n",
        "  y_pred_max_all.extend(y_pred_max)\n",
        "  y_test_max_all.extend(y_test_max)\n",
        "\n",
        "  ac.append(accuracy_score(y_test_max,y_pred_max))\n",
        "  print('accuracy is {:.2f}%'.format(ac[-1]*100)) # Print accuracy score\n",
        "  print()\n",
        "  cr.append(classification_report(y_test_max,y_pred_max)) # Print summary report\n",
        "  cm.append(confusion_matrix(y_test_max, y_pred_max))\n",
        "\n",
        "  foldi = foldi + 1\n",
        "\n",
        "# Calculate the average accuracy and standard deviation\n",
        "average_accuracy = np.mean(ac) * 100\n",
        "std_dev_accuracy = np.std(ac) * 100\n",
        "\n",
        "# Print the results\n",
        "print(f'Average Accuracy: {average_accuracy:.2f}%')\n",
        "print(f'Standard Deviation of Accuracy: {std_dev_accuracy:.2f}%')\n",
        "\n",
        "print('k-fold complete!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Fold Evaluation**"
      ],
      "metadata": {
        "id": "yMT31HiTMXPX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKhmf6L1FWS8",
        "outputId": "20a389df-3654-4c7d-8735-8080ab4da4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy for 5-CV: 60.63% +/- 1.42% SD\n"
          ]
        }
      ],
      "source": [
        "print('Average Accuracy for {}-CV: {}% +/- {}% SD'.format(k, np.round(np.mean(ac)*100,2), np.round(np.std(ac)*100,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Report**"
      ],
      "metadata": {
        "id": "kwv2n9T8MfPN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7oM3nJqFXp3",
        "outputId": "c393c971-2607-42df-b824-e5c4bab9b68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.63%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.68      0.65      5000\n",
            "           1       0.69      0.73      0.71      5000\n",
            "           2       0.52      0.49      0.50      5000\n",
            "           3       0.42      0.42      0.42      5000\n",
            "           4       0.55      0.52      0.54      5000\n",
            "           5       0.54      0.45      0.49      5000\n",
            "           6       0.65      0.71      0.68      5000\n",
            "           7       0.69      0.66      0.68      5000\n",
            "           8       0.69      0.73      0.71      5000\n",
            "           9       0.65      0.65      0.65      5000\n",
            "\n",
            "    accuracy                           0.61     50000\n",
            "   macro avg       0.60      0.61      0.60     50000\n",
            "weighted avg       0.60      0.61      0.60     50000\n",
            "\n",
            "[[3406  176  222   91  129   22   74   76  565  239]\n",
            " [ 162 3672   53   79   20   23   69   45  247  630]\n",
            " [ 475   67 2435  398  517  289  391  179  143  106]\n",
            " [ 157   85  408 2098  347  894  472  256  114  169]\n",
            " [ 215   65  557  380 2621  170  416  416  108   52]\n",
            " [ 125   33  454 1085  322 2260  259  315   58   89]\n",
            " [  61   84  239  385  259  160 3574   86   61   91]\n",
            " [ 122   69  224  280  389  324   84 3324   41  143]\n",
            " [ 487  320   62   70   64   37   50   32 3653  225]\n",
            " [ 253  724   53  123   56   38   76   99  305 3273]]\n",
            "\n",
            "Matthews Correlation Coefficient: 0.5627541040069408\n"
          ]
        }
      ],
      "source": [
        "acc_all = accuracy_score(y_test_max_all,y_pred_max_all)*100\n",
        "print('Accuracy: {:.2f}%'.format(acc_all))\n",
        "print()\n",
        "print(classification_report(y_test_max_all,y_pred_max_all))\n",
        "print(confusion_matrix(y_test_max_all, y_pred_max_all))\n",
        "\n",
        "mcc_all = matthews_corrcoef(y_test_max_all,y_pred_max_all)\n",
        "print()\n",
        "print('Matthews Correlation Coefficient: {}'.format(mcc_all))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}